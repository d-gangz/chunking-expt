"""
Script to generate ground truth dataset from 5 legal/business transcripts.
Uses a two-step LLM approach: first generates insights, then questions for each insight.

Transcripts are loaded from: 1_transcripts/cleaned-full/
Expected transcripts:
1. Laying the Groundwork - Employee & Early Shareholder Equity Best Practices
2. Prompting with Precision: Leveraging AI Responsibly as In-House Counsel
3. TechGC Virtual Dinner: Level Up Your Board
4. The Art of Professionalism: Navigating Ethical Conduct in Legal Practice
5. The Role of Legal in Building an Effective Diversity & Inclusion Program

Outputs:
- insights.json: Detailed insights generated by the first LLM call
- base_ground_truth.json: Final dataset with questions and answers
"""

import os
import json
from typing import List, Dict
from datetime import datetime
from pathlib import Path

from pydantic import BaseModel, Field, field_validator
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv
from tqdm import tqdm

# Load environment variables
load_dotenv()


# Step 1: Pydantic schemas for insights generation
class InsightQuote(BaseModel):
    """A substantial quote supporting an insight."""

    quoted_text: str = Field(
        description="Verbatim quote from the transcript (50-150 words, capturing complete thoughts)"
    )
    transcript_title: str = Field(
        description="Exact title of the transcript this quote comes from"
    )


class Insight(BaseModel):
    """An insight with supporting quotes from transcripts."""

    insight_id: str = Field(description="Unique identifier (e.g., insight_001)")
    comprehensive_answer: str = Field(
        description="The insight as a complete answer (2-4 sentences revealing deep understanding, patterns, or principles)"
    )
    source_quotes: List[InsightQuote] = Field(
        description="2-4 substantial quotes supporting this insight, preferably from different transcripts",
        min_length=2,
        max_length=4,
    )


class InsightsList(BaseModel):
    """List of insights extracted from transcripts."""

    insights: List[Insight] = Field(
        description="Exactly 30 insights extracted from the transcripts",
        min_length=30,
        max_length=30,
    )


# Step 2: Pydantic schemas for questions generation
class GeneratedQuestion(BaseModel):
    """A question that can be answered by the insight."""

    question: str = Field(description="The question text")
    difficulty: str = Field(
        description="Difficulty based on phrasing: easy (direct), medium (business jargon), hard (indirect/inferential)"
    )

    @field_validator("difficulty")
    @classmethod
    def validate_difficulty(cls, v: str) -> str:
        if v not in ["easy", "medium", "hard"]:
            raise ValueError("Difficulty must be 'easy', 'medium', or 'hard'")
        return v


class QuestionSet(BaseModel):
    """Questions generated for a single insight."""

    questions: List[GeneratedQuestion] = Field(
        description="2-3 questions of varying difficulty that this insight answers",
        min_length=2,
        max_length=3,
    )


def load_transcripts(transcript_dir: str) -> Dict[str, str]:
    """Load all transcript files from the cleaned directory."""
    transcripts = {}
    transcript_path = Path(transcript_dir)

    for file_path in transcript_path.glob("*.md"):
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()
            # Extract clean title from filename
            title = file_path.stem.replace("_", " ").replace("  ", " ")
            transcripts[title] = content

    return transcripts


def format_transcripts_for_prompt(transcripts: Dict[str, str]) -> str:
    """Format transcripts for inclusion in the prompt."""
    formatted = []
    for i, (title, content) in enumerate(transcripts.items(), 1):
        formatted.append(
            f"TRANSCRIPT {i}: {title}\n{'-' * 80}\n{content}\n{'=' * 80}\n"
        )
    return "\n".join(formatted)


def generate_insights(transcripts: Dict[str, str]) -> List[Insight]:
    """Step 1: Generate insights from transcripts."""
    print("\nğŸ¯ Step 1: Generating insights from transcripts...")

    # Initialize LLM
    llm = ChatOpenAI(model="gpt-4.1", temperature=0)

    # Create structured LLM
    structured_llm = llm.with_structured_output(InsightsList)

    # Create prompt
    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """You are an expert at analyzing legal and business transcripts to extract deep insights.

Extract EXACTLY 40 INSIGHTS that serve as COMPREHENSIVE ANSWERS:
- Each insight should be a complete, self-contained comprehensive answer (3-5 sentences)
- Must reveal deep understanding, patterns, or principles
- PRIORITY: Create insights that connect concepts ACROSS DIFFERENT transcripts
- Must be fully supported by quoted text from the transcripts

For each insight:
- Write the complete insight as you would answer a question
- Include 2-4 SUBSTANTIAL quotes (100-200 words each, capturing complete thoughts)
- IMPORTANT: Draw quotes from MULTIPLE transcripts whenever possible
- Quotes must be VERBATIM from the transcripts (no modifications)
- Ensure quotes provide rich context, not just keywords

Cover all 5 transcripts with emphasis on cross-transcript connections""",
            ),
            (
                "human",
                """Analyze these 5 legal/business transcripts and extract 30 high-quality insights:

{transcripts}

Generate insights that reveal deep understanding and patterns across transcripts.""",
            ),
        ]
    )

    # Create chain and invoke
    chain = prompt | structured_llm
    formatted_transcripts = format_transcripts_for_prompt(transcripts)

    result = chain.invoke({"transcripts": formatted_transcripts})

    print(f"âœ… Generated {len(result.insights)} insights")
    return result.insights


def generate_questions_for_insight(insight: Insight) -> List[GeneratedQuestion]:
    """Step 2: Generate questions for a single insight."""
    # Initialize LLM (with lower model for efficiency)
    llm = ChatOpenAI(model="gpt-4.1", temperature=0)

    # Create structured LLM
    structured_llm = llm.with_structured_output(QuestionSet)

    # Create prompt
    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """You are an expert at generating questions that can be answered by a given insight.

Generate 2-3 questions that this comprehensive answer addresses.
The questions should vary by DIFFICULTY (how the user asks):
- Easy: Direct, straightforward phrasing
- Medium: Requires some interpretation or uses business jargon  
- Hard: Indirect phrasing, multi-part, or requires inference

Example:
If the comprehensive answer is about "AI bias risks in legal practice"...
- Easy: "What are the risks of using AI in legal work?"
- Medium: "How should in-house counsel approach AI tool validation?"
- Hard: "What parallels exist between algorithmic decision-making challenges and traditional legal precedent biases?"

All questions should be answerable by the SAME comprehensive answer.
Difficulty reflects question phrasing complexity, not content complexity.""",
            ),
            (
                "human",
                """Generate 2-3 questions of varying difficulty for this insight:

Insight ID: {insight_id}
Comprehensive Answer: {comprehensive_answer}

The questions should all be answerable by the comprehensive answer above.""",
            ),
        ]
    )

    # Create chain and invoke
    chain = prompt | structured_llm

    result = chain.invoke(
        {
            "insight_id": insight.insight_id,
            "comprehensive_answer": insight.comprehensive_answer,
        }
    )

    return result.questions


def validate_quotes_in_transcripts(
    insights: List[Insight], transcripts: Dict[str, str]
) -> List[str]:
    """Validate that all quotes exist verbatim in the transcripts."""
    validation_errors = []

    for insight in insights:
        for quote in insight.source_quotes:
            # Find the transcript
            transcript_content = None
            for title, content in transcripts.items():
                if quote.transcript_title in title or title in quote.transcript_title:
                    transcript_content = content
                    break

            if transcript_content is None:
                validation_errors.append(
                    f"Insight {insight.insight_id}: Could not find transcript '{quote.transcript_title}'"
                )
                continue

            # Check if quote exists verbatim
            if quote.quoted_text not in transcript_content:
                # Try to find a close match
                quote_words = quote.quoted_text.split()[:10]  # First 10 words
                snippet = " ".join(quote_words)
                if snippet in transcript_content:
                    validation_errors.append(
                        f"Insight {insight.insight_id}: Quote partially found but not exact match"
                    )
                else:
                    validation_errors.append(
                        f"Insight {insight.insight_id}: Quote not found in transcript '{quote.transcript_title}'"
                    )

    return validation_errors


def convert_to_final_format(
    insights: List[Insight], all_questions: Dict[str, List[GeneratedQuestion]]
) -> List[Dict]:
    """Convert insights and questions to the final output format."""
    output_entries = []
    question_counter = 1

    for insight in insights:
        questions = all_questions.get(insight.insight_id, [])

        # Create an entry for each question
        for question in questions:
            entry = {
                "question_id": f"q_{question_counter:03d}",
                "question": question.question,
                "comprehensive_answer": insight.comprehensive_answer,
                "source_quotes": [
                    {
                        "quoted_text": quote.quoted_text,
                        "transcript_title": quote.transcript_title,
                    }
                    for quote in insight.source_quotes
                ],
                "difficulty": question.difficulty,
            }
            output_entries.append(entry)
            question_counter += 1

    return output_entries


def main():
    """Main function to generate the ground truth dataset."""
    print("ğŸš€ Starting ground truth dataset generation...")

    # Load transcripts
    print("\nğŸ“„ Loading transcripts...")
    transcript_dir = "/Users/gang/suite-work/chunking-expt/1_transcripts/cleaned-full"
    transcripts = load_transcripts(transcript_dir)
    print(f"âœ… Loaded {len(transcripts)} transcripts")

    # Step 1: Generate insights
    try:
        insights = generate_insights(transcripts)
    except Exception as e:
        print(f"âŒ Error generating insights: {e}")
        return

    # Export insights to JSON
    print("\nğŸ’¾ Saving insights to insights.json...")
    insights_data = {
        "metadata": {
            "generated_at": datetime.now().isoformat(),
            "total_insights": len(insights),
            "transcripts_analyzed": list(transcripts.keys()),
        },
        "insights": [
            {
                "insight_id": insight.insight_id,
                "comprehensive_answer": insight.comprehensive_answer,
                "source_quotes": [
                    {
                        "quoted_text": quote.quoted_text,
                        "transcript_title": quote.transcript_title,
                    }
                    for quote in insight.source_quotes
                ],
            }
            for insight in insights
        ],
    }
    insights_output_path = "/Users/gang/suite-work/chunking-expt/4_labelled_dataset/baseline-questions/insights.json"
    with open(insights_output_path, "w", encoding="utf-8") as f:
        json.dump(insights_data, f, indent=2, ensure_ascii=False)
    print(f"âœ… Insights saved to {insights_output_path}")

    # Validate quotes
    print("\nğŸ” Validating quotes against transcripts...")
    validation_errors = validate_quotes_in_transcripts(insights, transcripts)
    if validation_errors:
        print(f"âš ï¸ Found {len(validation_errors)} validation issues:")
        for error in validation_errors[:5]:  # Show first 5 errors
            print(f"  - {error}")
        if len(validation_errors) > 5:
            print(f"  ... and {len(validation_errors) - 5} more")
    else:
        print("âœ… All quotes validated successfully")

    # Step 2: Generate questions for each insight
    print("\nğŸ¯ Step 2: Generating questions for each insight...")
    all_questions = {}

    for insight in tqdm(insights, desc="Generating questions"):
        try:
            questions = generate_questions_for_insight(insight)
            all_questions[insight.insight_id] = questions
        except Exception as e:
            print(f"\nâš ï¸ Error generating questions for {insight.insight_id}: {e}")
            all_questions[insight.insight_id] = []

    # Convert to final format
    print("\nğŸ“Š Converting to final output format...")
    output_entries = convert_to_final_format(insights, all_questions)
    print(
        f"âœ… Created {len(output_entries)} question entries from {len(insights)} insights"
    )

    # Add metadata
    output_data = {
        "metadata": {
            "generated_at": datetime.now().isoformat(),
            "total_insights": len(insights),
            "total_questions": len(output_entries),
            "transcripts_analyzed": list(transcripts.keys()),
            "validation_errors": len(validation_errors),
        },
        "entries": output_entries,
    }

    # Save to JSON
    output_path = "/Users/gang/suite-work/chunking-expt/4_labelled_dataset/baseline-questions/base_ground_truth.json"
    print(f"\nğŸ’¾ Saving to {output_path}...")
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)

    print("\nâœ… Ground truth dataset generation complete!")
    print(f"ğŸ“ˆ Summary:")
    print(f"  - Total insights: {len(insights)}")
    print(f"  - Total questions: {len(output_entries)}")
    print(
        f"  - Average questions per insight: {len(output_entries) / len(insights):.1f}"
    )
    print(f"  - Validation issues: {len(validation_errors)}")


if __name__ == "__main__":
    main()
