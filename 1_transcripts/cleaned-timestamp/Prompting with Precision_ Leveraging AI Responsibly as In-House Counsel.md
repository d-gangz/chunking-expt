Title: Prompting with Precision: Leveraging AI Responsibly as In-House Counsel

**Total Duration:** 58:02

**Number of Segments:** 1266

**Speakers:** 3

---

**[Speaker 1]**

[4.715 - 5.765] Welcome everybody.

[5.945 - 7.245] Um, my name is Heather Wallinger,

[7.245 - 8.485] event host here at the L Suite.

[8.905 - 11.285] Our panel today will focus on prompting

[11.285 - 13.205] with precision leveraging AI

[13.205 - 14.805] responsibly as in-house counsel.

[15.225 - 17.365] We have a really great set of speakers for here today.

[17.585 - 20.565] I'm pleased to welcome Tommy Tavares Ferrera,

[20.575 - 22.525] chief Strategy Officer at Law Trades.

[23.105 - 24.725] We have, we have Jason Satoma,

[24.725 - 27.245] general Counsel at Tiffin Ag in Access,

[27.745 - 30.685] and we have Alex Rendells, general counsel at Jasper ai,

[31.565 - 33.525] a really big thank you to our sponsor for today's session,

[34.065 - 36.205] uh, law Trades for making this event possible.

[36.825 - 38.285] So that is it for me, Tommy.

[38.485 - 40.085] I will hand it over to you to get us started.

**[Speaker 2]**

[41.145 - 44.575] Thank you. Hi everybody. I am Tommy Avara Spira.

[44.635 - 47.335] I'm the Chief Strategy Officer at Law Trades,

[47.335 - 48.335] as Heather just said.

[48.515 - 51.775] And for those who haven't worked with us yet, law Trades is,

[52.075 - 55.815] uh, a marketplace for on demand legal talent.

[56.305 - 58.215] We're the go-to partner for companies

[58.215 - 61.095] that need vetted high caliber lawyers, legal ops, pros,

[61.335 - 62.895] contract managers or paralegals.

[63.145 - 65.575] Think of this as the legal team behind your legal team.

[66.065 - 68.815] Later on in today's session, we'll launch a call with a,

[68.875 - 70.495] an offer unique to L Suite members.

[70.635 - 72.935] If you're interested in a free legal operation strategy

[72.935 - 75.735] session, followed by a personalized assessment

[75.795 - 77.495] and roadmap customized to your team,

[77.715 - 79.095] you'll have a chance to opt in.

[79.395 - 81.415] And with that, I'd love to pass it to Jason

[81.555 - 82.975] and Alex to introduce themselves.

**[Speaker 3]**

[84.665 - 88.165] Hi, I'm Jason. I am a general counsel of a collection

[88.345 - 91.845] of software startups, predominantly in FinTech ai.

[92.435 - 95.945] Alex, over to you. Yep. I'm Alex.

[96.325 - 99.225] Uh, I'm the general counsel of Jasper ai.

[99.235 - 102.025] We're a marketing AI company for enterprises.

[102.565 - 105.985] Um, so pretty familiar with developing and deploying AI

[105.985 - 107.785] and then using it personally in our

[107.795 - 109.345] legal workflows in-house as well.

**[Speaker 2]**

[110.405 - 111.805] Excellent. Thank you both.

[112.505 - 116.325] So before we dive in, let me set the stage.

[117.185 - 119.485] AI is moving way faster than a lot

[119.485 - 121.045] of legal teams are comfortable with,

[121.265 - 125.365] and prompting is the tip of that very powerful momentum.

[125.985 - 129.365] Um, if you've ever had a sales team ping legal

[129.365 - 132.965] with a question like, can we just use this vendor's paper,

[133.265 - 135.965] um, without context, without details,

[136.105 - 139.605] or maybe even without a link to that contract, then you know

[139.715 - 140.765] that feeling of

[140.765 - 143.285] what it's like when you don't get a good question,

[143.855 - 145.325] every answer feels wrong.

[145.945 - 149.805] And that's kind of what prompting with AI is exactly like,

[150.505 - 154.445] so we wanna get really good at asking the right question

[154.545 - 156.485] and give the right context and details.

[157.065 - 160.165] So now that AI is answering questions at scale,

[160.625 - 161.925] the stakes are really big

[162.385 - 164.165] and that's why today is about

[164.185 - 165.485] how we ask those questions better.

[165.905 - 169.165] So, um, we wanna use these tools, smart and safe.

[169.745 - 171.125] Um, let's get into it.

[171.135 - 174.095] Jason, can you share a case

[174.105 - 178.195] where sharpening a prompt, um, led

[178.195 - 180.805] to a materially better output?

**[Speaker 3]**

[182.715 - 185.685] Yeah, sure. So I guess to preface this,

[185.795 - 187.845] this was early AI days.

[188.045 - 189.885] I was probably using chat GPT

[189.885 - 191.245] and didn't have a ton of practice,

[191.945 - 194.645] but one time I was trying to recall the present consent

[194.645 - 196.365] to future events rules in Delaware.

[196.385 - 200.445] So I asked chat GPT, basically just that

[201.185 - 203.565] the output was predictably awful.

[204.505 - 207.405] Uh, going back I tried to sharpen it up a bit

[207.825 - 211.045] and I asked how many days in advance the prospective action

[211.145 - 212.725] can a board or stockholders'

[212.725 - 214.085] consent to those future actions?

[214.765 - 217.525] I told it to assume Delaware law site to statutes

[217.525 - 218.805] or clarifying case law.

[219.795 - 220.815] It, uh, oh.

[220.835 - 223.495] And I also told it to discuss the full chain

[223.495 - 224.935] of reasoning prior to concluding.

[225.215 - 227.055] 'cause sometimes you can get sharper responses

[227.215 - 230.095] 'cause it's, it's not thinking, it's just reasoning

[230.095 - 231.135] through words in real time.

[231.915 - 234.455] Uh, answer wound up being 60 days in

[234.455 - 235.495] case anyone's interested.

[235.555 - 238.015] And I think the takeaway is that you can get pretty far

[238.045 - 239.335] with even basic context.

[240.285 - 244.175] Also worth mentioning that the cited law was wrong.

[244.395 - 246.855] It gave me a correct quote, but the wrong law.

[246.915 - 248.855] So that just further highlights the need

[248.855 - 251.575] to verify all the odd outputs. And

**[Speaker 2]**

[252.385 - 254.545] Jason, I'll ask a a quick follow up

[254.545 - 256.385] before I go over to Alex.

[256.925 - 260.315] Um, when, when you're in that instance

[260.315 - 263.955] where the citation is wrong, if you don't have expertise,

[264.695 - 265.955] how do, how do you know what's wrong?

**[Speaker 3]**

[267.425 - 270.005] That's somewhat that, that, that's a big problem.

[270.185 - 271.965] If you don't have a bit

[271.965 - 275.365] of a BS meter on the topic in question,

[276.065 - 277.525] you can't really know it's wrong.

[277.625 - 281.565] So you have to view it as sort of a Google something

[281.565 - 283.645] that helps you figure out what you don't know.

[283.665 - 284.845] And if it's important enough

[284.845 - 286.405] or risky enough, you'd then have to

[287.165 - 288.485] escalate it to somebody who does

[289.815 - 292.285] Trust but verify Trust, but verify

**[Speaker 2]**

[292.555 - 293.555] Just to verify.

[293.805 - 297.165] Excellent. And Alex, what criteria are you using to know

[297.395 - 299.125] that a prompt is hitting the mark?

**[Speaker 3]**

[299.715 - 301.845] Yeah, I think the most recent models

[301.845 - 306.205] that have come out from OpenAI, Google philanthropic, um,

[306.555 - 309.245] have become better and better at getting pretty close

[309.985 - 311.405] to a perfect answer.

[312.005 - 316.645] Honestly, like I've found, um, the legal reasoning for most

[317.245 - 320.045] questions I ask are now 85 to 90% accurate.

[320.855 - 325.315] But one thing to be continually conscious of is

[325.315 - 327.275] that if you're asking it to cite sources,

[328.015 - 330.675] it will still at times hallucinate those sources.

[330.705 - 332.835] There's a, there's ways you can improve that,

[333.085 - 335.795] especially if you're using a model from one

[335.795 - 338.075] of the model providers that allows, um,

[338.185 - 340.195] live search grounding using Google

[340.455 - 343.475] or perplexity as like a deep research function.

[343.815 - 345.395] And that gets a little better to the mark in terms

[345.395 - 347.035] of citing accurate sources.

[347.695 - 349.035] You still have to be careful about that,

[349.455 - 352.835] but I still find that it might give you, you know, like

[353.675 - 356.195] accurate elements of breach of contract in Massachusetts

[357.515 - 359.055] and it's, it's dead accurate.

[359.195 - 363.015] And then the sources it cite might not be, um,

[363.235 - 365.855] the best sources to cite or might some might be inaccurate,

[366.235 - 367.575] but that is getting better and better.

**[Speaker 2]**

[368.315 - 370.935] Do you have any sort of methodology to

[371.565 - 374.975] what you do when you do come up with a good prompt

[375.315 - 377.935] and you want to save it or share it?

**[Speaker 3]**

[378.925 - 381.015] Yeah, definitely. So there are plenty of tools

[381.015 - 382.455] that would do this for you nowadays.

[382.555 - 385.295] I'm sure people on the call use them or aware of them.

[385.835 - 389.735] You can also, like, for a long time I just kept a note file

[389.735 - 392.775] with prompts that I would copy and paste into chat GPT.

[393.315 - 394.415] That's pretty good.

[395.075 - 396.335] The framework I think about

[396.595 - 400.655] for creating prompts is entirely stolen from, um, a book

[400.655 - 403.095] that came out last year by Ethan Molik,

[403.095 - 407.095] he's a researcher at, and the book's title co intelligence.

[407.635 - 409.655] Um, and it's pretty short and easy to get your hands on.

[409.735 - 411.255] I think it's less than 200 pages.

[411.955 - 414.015] But one of the things he talks about in terms

[414.015 - 416.015] of crafting good prompts

[416.015 - 419.295] to have the best re responses from AI is

[419.295 - 421.295] to give it first a role to play.

[421.555 - 425.495] So in the legal context, um, having it, telling it to act

[425.495 - 427.255] as an attorney and not just any attorney,

[427.275 - 430.375] but trying to narrow down on the specific expertise

[430.375 - 431.535] you're wanting it to have.

[432.365 - 436.385] Um, and that substantially improves prompts

[436.405 - 438.425] and you can just put that in the beginning of the prompt or,

[438.445 - 441.625] or bury it in the system prompt Once again, there are plenty

[441.625 - 444.185] of tools out there nowadays that will do this for you

[444.185 - 445.345] so you don't have to know what you're doing.

[446.015 - 447.995] Um, but that helps a lot in the get go.

**[Speaker 2]**

[448.335 - 451.955] And before I, I I pivot to Jason a quick follow.

[452.375 - 456.035] Um, it used to be that the order of

[456.035 - 458.155] where you were asking the question was important.

[458.255 - 459.515] For example, if you put it first

[459.535 - 460.795] and then you put context later,

[460.855 - 462.875] or if you put context in the question,

[463.295 - 464.515] do you find there's any magic

[464.615 - 467.195] to whether you're putting the question then loading in the

[467.195 - 470.035] context or not, doesn't matter anymore?

**[Speaker 3]**

[471.625 - 473.205] Um, that's a, that's a great point.

[473.805 - 474.885] I still put it

[474.945 - 478.565] before in chat gt even you, if you have their plus plan,

[478.725 - 481.805] I believe you can create custom GPTs that allow you

[481.805 - 483.365] to bury it in the system prompts so

[483.365 - 485.685] that any question you ask it automatically is

[485.685 - 486.885] incorporating that context.

[486.985 - 488.925] That's helpful. Um,

[489.465 - 491.405] but quite frankly, I think the models are keep,

[491.405 - 492.685] keep getting better and better at this.

[492.685 - 494.525] And you can probably include it anywhere.

[494.985 - 497.845] Uh, you could attach a file, like if you have notes

[497.945 - 499.805] for prompts you want to use in a Word doc,

[499.825 - 500.885] you could just attach that.

[501.465 - 504.245] Um, the, the models themselves are getting very good at

[504.245 - 505.725] understanding user intent.

[506.105 - 507.685] You can have grammatical errors,

[507.705 - 510.685] you can totally misstate the mark on like

[510.685 - 512.205] what even law you're trying to research.

[512.545 - 514.605] And it'll typically do a pretty good job

[514.605 - 515.725] of figuring out what you mean

**[Speaker 2]**

[516.035 - 518.445] Does catch my reads right through my typo.

[518.945 - 520.485] Um, so Jason, what,

[520.795 - 523.125] what tools are you leaning on for prompting,

**[Speaker 3]**

[524.435 - 527.195] I guess, uh, I don't have to think too hard.

[527.205 - 529.955] Thankfully I use GC ai.

[529.955 - 531.715] There's a lot of tools that like it

[531.775 - 533.435] and you ask it what you're thinking,

[533.455 - 535.725] you provide some context, you click the magic,

[536.425 - 537.485] fix my prompt button

[537.505 - 539.765] and it blows it up into this multi-paragraph

[540.395 - 541.845] beautiful wonder prompt.

[542.425 - 544.325] So I don't have to think about it that hard.

[544.435 - 547.045] When I used to, I don't know if this is still the case,

[547.185 - 548.365] but at one point in time,

[548.905 - 551.725] Claude was better at writing like the human,

[551.825 - 554.645] so I would use Claude to create a really good prompt

[554.705 - 558.445] and then I would plug that into chat GPT or another model

[558.585 - 560.925] and go from there with pretty good results.

**[Speaker 2]**

[562.795 - 567.605] Also, I think a pro tip is if you are really not getting

[567.715 - 569.285] outputs that are helpful, and if,

[569.385 - 573.725] and if it keeps missing the mark in the response, um,

[574.545 - 579.045] you can ask, um, for, for whatever tool you're using,

[579.385 - 581.205] can you help me to write a better prompt here?

[581.385 - 584.525] And I think again, like the more context you can add,

[584.585 - 587.565] the better that the, the prompt's going to be, right?

[588.065 - 590.765] Um, but, but as we said, like even even that

[591.675 - 594.205] like relying on the tool to give you that,

[594.545 - 595.885] um, is gonna help you.

[596.785 - 600.085] So Jason, now let's talk about, um,

[600.835 - 602.085] some of the risks, right?

[602.155 - 603.765] Like we're we're talking about prompting,

[603.765 - 605.565] we're talking about giving context, we're talking about

[605.565 - 607.525] how you get better at asking the right question

[608.105 - 609.765] so you get the right outputs,

[610.065 - 613.045] but in reality there are still some risks.

[613.465 - 616.685] And, um, what do you think is most likely

[616.825 - 620.165] to cause something misleading or to cause a risky output?

**[Speaker 3]**

[621.455 - 624.145] Yeah, so there's a couple different answers to that.

[624.175 - 627.695] Some of them are more technical than I'm able to provide

[627.715 - 629.255] and others are more contextual.

[629.475 - 631.455] So I think first off, a lot

[631.455 - 633.375] of people are treating these tools

[633.475 - 635.495] as if they're subject matter experts in

[635.495 - 636.655] areas that they don't understand.

[636.715 - 639.615] And I think that's inherently problematic and dangerous.

[640.255 - 641.375] I feel like a broken record,

[641.435 - 644.335] but I keep going to the, you need to be able, you need

[644.335 - 646.975] to be capable of falsifying the output in order for it

[646.975 - 649.295] to be safe for you to rely on the output

[649.295 - 651.575] with without bringing in other humans.

[652.735 - 656.665] And so I guess you, yeah, that, that's the big one.

[656.845 - 660.625] And then you need to add context and specificity to prompts

[661.205 - 663.745] and you need to specify what your outcome should be,

[664.185 - 667.585] particularly what a lot of people, myself included,

[667.905 - 671.705] occasionally you ask it leading questions such as

[672.265 - 674.985] I think this is the rule, I think this is what happens.

[676.085 - 678.585] Do you agree? And again,

[678.585 - 681.425] because these things aren't really thinking that's,

[681.425 - 682.985] that's a dangerous way to ask a question.

[683.625 - 685.905] I find it helpful to provide a lot of context,

[686.085 - 690.155] but then have the actual executable question be more

[690.155 - 692.595] open-ended to try and avoid influencing the outcome.

[693.625 - 695.445] I'm not sure, did I, did I answer the question?

**[Speaker 2]**

[695.915 - 697.845] Yeah, and, and I'll, I'll add onto

[697.845 - 700.005] that is sometimes when I've been stuck

[700.115 - 704.085] with not loving the outputs, I actually will refresh

[704.145 - 705.485] and start a whole new prompt.

[705.485 - 707.725] Like, 'cause there's something about the memory that helps.

[708.025 - 711.685] And when I do that refresh, sometimes I'll actually start

[711.745 - 715.085] by asking kind of like leading the witness questions, like,

[715.105 - 717.245] Hey, are you familiar with Ontario Canada?

[717.625 - 720.485] And then like, Hey, are you like, are you familiar

[720.485 - 721.845] with the languages that they speak there?

[721.865 - 724.605] And like I I actually start building like, like a world,

[724.665 - 727.965] if you will, and then I get into the, the heart

[727.965 - 729.005] of what I wanna ask.

[729.255 - 731.565] Maybe I wanna ask about restaurants in that town

[731.585 - 734.565] or something, but if I'm really getting frustrated,

[734.765 - 737.005] I might start like world building with it first

[737.305 - 740.845] and then I find it ha it feels like it knows

[741.365 - 743.245] a little bit better 'cause I was leading the witness.

[744.065 - 748.045] Um, Alex, how do you do a critical evaluation of like

[748.955 - 751.445] what, what came out, um, of your prompt?

**[Speaker 3]**

[752.985 - 755.915] Yeah, definitely leading, asking, leading questions is,

[756.095 - 757.755] is tough even if you're using it

[757.755 - 759.595] for personal use cases, not legal.

[759.655 - 762.155] And that's be like the, the system prompts

[762.155 - 765.475] that the model providers use are largely proprietary.

[765.815 - 769.075] But if you, like, if your company is developing AI itself

[769.255 - 772.705] and you go into your, um, your instance

[772.705 - 776.025] of like open AI's playground, you can see

[776.165 - 778.265] how your company's developing prompts

[778.325 - 780.545] and open AI suggests system prompts

[780.565 - 784.265] and they almost always begin with act as a helpful assistant

[784.735 - 788.145] that is friendly and polite and the AI hears that.

[788.285 - 790.105] And when we're just going into chat GBT

[790.105 - 792.305] and asking legal questions, it's really wanting

[792.305 - 793.825] to please us more than anything else.

[794.485 - 797.505] Um, so you have to work your way around that a bit.

[797.565 - 799.865] One of the ways that I do it is force it

[799.865 - 801.065] to show its thinking.

[801.365 - 802.825] So some of the new reasoning models,

[803.125 - 805.945] Gemini 2.5 Pro will do this automatically

[805.945 - 808.265] and it provides a little dropdown box that shows you

[808.885 - 810.425] how the system was thinking itself.

[810.485 - 813.185] But you can also just include in your prompt

[813.195 - 816.785] after you tell it to act like an attorney to, um,

[816.795 - 819.905] write out its reasoning in like Iraq format,

[820.055 - 823.185] like we were taught to do in law school for exams, uh,

[823.185 - 826.305] which seems brutal, but like it gets that immediately.

[826.385 - 828.865] I don't even have to spell out like issue rule analysis,

[828.865 - 830.425] conclusion it know what IRAC is

[830.885 - 834.025] and it'll, it'll structure its response that way

[834.045 - 836.065] and then at least you can go through, you're like,

[836.065 - 837.065] did it catch the question

[837.135 - 839.025] that I was even asking to spot the issue?

[839.455 - 841.905] What rules it actually setting or is it way off the mark?

[842.245 - 844.505] And then from there you can, if it is making mistakes,

[844.525 - 846.985] you can figure out where those mistakes were made

[846.985 - 848.065] and have it then go back

[848.085 - 850.745] and, you know, correct its process there.

[851.005 - 855.865] Um, another easy hack I've found is using models

[856.015 - 860.905] that are fine tuned for coding use cases that seems odd

[861.205 - 863.825] and it might not pro provide the best, um,

[864.215 - 866.265] like written English output itself,

[866.285 - 869.585] but the legal reasoning I found is the strongest not to be.

[869.765 - 872.345] I'm guessing it's because like years ago I read

[872.345 - 875.265] that the highest performers on the LSAT in a bar exam were

[875.415 - 877.785] math majors in college, which seems counterintuitive

[878.445 - 880.505] at first because you would think like English

[880.505 - 882.985] and history majors and philosophy major would be the best,

[883.645 - 886.625] but math is just like pure representational logic.

[887.205 - 888.745] Um, so those people should be able

[888.745 - 890.305] to do logical reasoning in the best

[890.645 - 892.685] and the models kind of bear

[892.685 - 894.485] that out when you're using a math heavy

[895.065 - 898.805] or coding heavy model, it seems to be able to walk through

[899.805 - 903.245] discreet, deductive logical reasoning better than just

[903.245 - 904.725] jumping into chat GBT raw

[904.725 - 906.925] and trying to uh, figure it out from there.

[907.745 - 910.005] Um, but then taking a step back,

[910.005 - 914.505] like Jason mentioned GCA ai, we use GC ai, we also used, uh,

[915.245 - 919.505] um, a tool called White Shoe ai and then we use Ivo AI

[920.085 - 922.745] and all three of those, like for somebody who doesn't want

[922.745 - 925.705] to dig in and learn all of these, uh, annoying

[926.315 - 929.265] geeky nuances, these tools do all that for you.

[929.265 - 931.745] They're selecting, most likely they're selecting the best

[931.745 - 934.865] models for you, um, when to use them and how to prompt them.

[934.865 - 936.745] And it helps a ton. I'll share in the chat

[937.155 - 938.385] those three that we use.

**[Speaker 2]**

[938.965 - 941.265] That's great. And I feel like you touched on this a little

[941.265 - 942.505] bit, but I'll, but I'll ask it anyway

[942.625 - 943.985] 'cause it's one of the questions that we got.

[944.485 - 948.625] Do you find that the, um, the way that you're asking it

[948.625 - 950.065] to take on a persona or,

[950.245 - 953.345] or using logic-based responses, is that

[953.445 - 956.465] how you build confidence, um, in your responses

[956.485 - 958.065] or is there any other methodology?

[958.205 - 961.705] The specific question is like how do you build confidence

[961.725 - 963.305] and certainty in the response?

[963.405 - 965.385] And it sounds like you touched on that a bit,

[965.445 - 966.905] but if you have any, or Jason,

[967.005 - 969.345] if you have any other pro tips on building

[969.345 - 970.785] that confidence in the response?

**[Speaker 3]**

[972.635 - 974.275] I think so going back

[974.275 - 976.515] to Ethan Malik's book co Intelligence, one

[976.515 - 978.275] of the things he says is, um,

[979.305 - 981.925] to begin using AI constantly

[982.145 - 984.405] and you'll, you'll start noticing where it's strong,

[984.405 - 986.965] where it's weak, and that itself will build your confidence.

[987.105 - 988.765] I'm definitely a power user of ai.

[988.765 - 992.775] There's nothing I do now at work that doesn't incorporate

[993.675 - 997.015] ai, um, like literally every single question I'm receiving

[997.035 - 998.695] and responding to, unless it's live on

[998.695 - 999.735] a call like this where I can't.

[1000.115 - 1004.375] And even even then we use transcribing notes, um, notes

[1004.375 - 1006.055] through these tools that, you know, we'll do speech

[1006.055 - 1007.535] to text nowadays, which are pretty good.

[1008.075 - 1010.065] Um, but the more you use it,

[1010.105 - 1012.025] I think the more comfortable you'll get.

[1012.045 - 1014.345] And even if it seems like something that, ah, I don't need

[1014.345 - 1017.545] to use this, I know this, um, like the back of my hand,

[1017.615 - 1019.465] it's useful for you to build up the confidence

[1019.465 - 1021.985] to use the tool so that then when a problem comes along

[1022.225 - 1025.185] that it's like really well suited for, you can use that.

[1025.205 - 1028.265] And then just also keep it in mind that these tools,

[1028.445 - 1031.185] you should treat them as like a junior associate at a law

[1031.375 - 1034.185] firm or like an entry level or they're pretty good

[1034.205 - 1035.705] and that they'll give you a lot of good content,

[1036.525 - 1039.265] but at the end of the day, you're still the actual human

[1039.365 - 1041.625] and the attorney and you should be checking it.

[1042.045 - 1044.425] You shouldn't just be outsourcing this to ai.

[1045.065 - 1046.465] I think those are really good points.

[1046.645 - 1051.565] And then also I think that generally when I can, I try to

[1052.265 - 1056.165] use these tools in a narrow scope using really easily

[1056.675 - 1060.125] falsifiable questions and answers.

[1060.385 - 1063.885] So I'll, even though citations can be wrong, I make it site,

[1064.005 - 1067.165] I make it reason and that makes it easier for me to sort

[1067.165 - 1068.885] of spot check outputs

[1068.985 - 1070.845] and that that gives me greater confidence.

[1071.005 - 1074.605] Although of course when something is partially thinking

[1074.625 - 1076.685] for you, you can, you can never be totally a hundred

[1076.685 - 1077.685] percent, but it helps.

**[Speaker 2]**

[1078.145 - 1081.125] And Alex, really quickly to um, to your,

[1081.345 - 1084.245] to your point about using Ivo GCI

[1084.245 - 1086.685] and then I think there was a third enterprise tool, one

[1086.685 - 1087.925] of the questions is,

[1087.985 - 1089.685] is there a reason why you're

[1089.685 - 1091.045] utilizing three different tools?

**[Speaker 3]**

[1092.035 - 1093.645] Yeah, so I just actually responded

[1093.645 - 1095.525] to someone's question in the chat about

[1095.525 - 1096.765] what the pricing looks like.

[1097.345 - 1100.705] Um, GC ai, uh,

[1100.845 - 1104.585] and Ivo, we both, I have another attorney in house as well,

[1104.885 - 1108.505] we heavily leveraged those tools for contract redlining.

[1109.275 - 1110.555] GCAI actually just came out

[1110.555 - 1112.515] with a word plugin, uh, last week.

[1112.635 - 1114.395] I think it's still in data and it's, it's really good.

[1114.655 - 1119.275] And Ivo was the first, uh, contract redlining tool I found

[1119.275 - 1121.755] that was actually surgical and precise, it's redline

[1121.755 - 1122.835] and wasn't over lawyering.

[1123.455 - 1125.015] Um, and both

[1125.015 - 1128.055] of those tools you can upload you like contract redlining

[1128.335 - 1129.415] playbooks and that helps a ton.

[1130.485 - 1134.465] Um, and I had piloted essentially every single legal AI tool

[1134.565 - 1136.665] on the market and those two were the best

[1136.665 - 1137.705] for contract redlining.

[1138.205 - 1140.665] Uh, but they're kind of expensive, especially for a lot,

[1141.005 - 1142.065] uh, small legal team.

[1142.805 - 1145.465] Uh, we, we were given pretty generous discounts to both

[1145.465 - 1147.185] of them for early adopters,

[1147.565 - 1150.305] but they're still in the orders of five

[1150.305 - 1152.385] to $10,000 a year I believe.

[1152.925 - 1156.705] Um, white Shoe is, it came out this year, it's newer,

[1157.255 - 1159.945] it's kind of taking the cursor for like lawyer,

[1159.965 - 1161.945] if you've heard of Cursor, it's like a vibe coating startup

[1162.145 - 1164.585] that's blown up, but it's taking like the cursor

[1164.585 - 1166.785] for lawyers, uh, business model approach

[1167.045 - 1169.305] and it is absurdly inexpensive.

[1169.585 - 1170.985] I honestly dunno how they're making money.

[1171.055 - 1174.315] It's like the base model's like 20 bucks a month, um,

[1174.695 - 1176.035] and you can pay for more usage

[1176.035 - 1177.155] and more tools on top of that.

[1177.215 - 1179.155] So we honestly leverage that

[1179.675 - 1181.115] probably more than anything nowadays

[1181.115 - 1182.675] because of our limited budget.

[1183.295 - 1186.315] Um, but that's kind of why we mix in those three tools

[1186.315 - 1187.955] and we'll have 'em work against each other too.

[1187.955 - 1190.515] This was another point I was gonna make about having

[1190.515 - 1192.235] confidence in the prompt results.

[1192.775 - 1193.995] Um, if you're getting,

[1193.995 - 1196.715] if you like ask a question from one tool white chew

[1196.715 - 1199.115] or whatever, or just if you're in chat GPT or Anthropic

[1200.015 - 1202.555] and then you just copy and paste the output

[1202.555 - 1204.795] and say like, Hey, another AI gave me this

[1205.325 - 1207.235] argue against it, or does this look right?

[1208.005 - 1210.785] Uh, it does a pretty good job of of doing that.

[1210.885 - 1212.665] Um, so that's useful as well.

**[Speaker 2]**

[1213.275 - 1216.775] That's excellent. So we've taken the audience through

[1217.605 - 1222.175] prompting, getting them comfortable with maybe how to prompt

[1222.315 - 1225.055] and I see the chats going up with a ton of resources

[1225.055 - 1227.055] and there are some takeaways that people will have,

[1227.635 - 1231.215] but I think also one barrier to entry for folks

[1231.355 - 1235.335] and one friction point is naturally like not knowing

[1235.445 - 1237.695] what the best practices or guardrails are.

[1238.115 - 1240.935] So I think that's something we should pivot to now.

[1241.235 - 1244.695] Um, Alex, why don't you kick us off with talking us

[1244.695 - 1245.815] through internal guardrails.

[1245.835 - 1248.205] It sounds like you all are very comfy

[1248.205 - 1249.325] over there with these tools.

[1249.625 - 1251.605] It sounds like you all are

[1252.205 - 1254.685] probably like utilizing them all day long.

[1255.265 - 1257.205] How did you get folks comfy with it

[1257.385 - 1259.805] and what kind of guardrails do you put in?

**[Speaker 3]**

[1261.275 - 1266.105] Definitely, yeah, so it helps that we are a company run

[1266.285 - 1269.865] by, um, executives who are super AI focused.

[1269.985 - 1271.465] I mean, we're an AI company ourselves

[1271.485 - 1274.065] and a lot of it is they want us to, um,

[1275.145 - 1277.635] like eat our own product, like what we're selling.

[1278.455 - 1281.435] And because of that we have like an internal mandate to,

[1281.735 - 1284.115] for everybody across the organization, if you're an engineer

[1284.115 - 1287.435] or lawyer finance, to use AI as much as you can basically

[1287.535 - 1289.515] to increase efficiency, lower costs.

[1290.055 - 1293.395] Um, so in terms of from executive buy-in, it was,

[1293.935 - 1296.675] it was mandated so it was easy to get buy-in there.

[1297.295 - 1300.435] Um, we don't, you might find it ironic,

[1300.455 - 1303.035] but we don't like have a formal AI use policy.

[1303.145 - 1304.595] I've seen those floating around.

[1305.175 - 1308.715] Um, in fact, I find it funny that like, uh, uh,

[1309.305 - 1311.915] default form one on Westlaw itself,

[1311.915 - 1314.275] practical law includes Jasper.

[1314.305 - 1315.595] It's one of the recommended tools.

[1315.755 - 1317.115] I did not have any, um,

[1317.725 - 1319.395] input into having that shoved in there.

[1319.855 - 1321.715] But you know, I think it's good if you're,

[1321.715 - 1323.675] especially if you're a big organization

[1323.775 - 1327.355] or one that regularly handles sensitive data like,

[1327.355 - 1329.475] like FinTech industry or finance industry

[1329.815 - 1332.035] or biotech to implement some type

[1332.035 - 1333.355] of internal company policy.

[1333.975 - 1336.195] But if you're not, um, as long

[1336.195 - 1338.275] as like there's some like general agreement within the

[1338.275 - 1339.515] organization that you're going

[1339.515 - 1341.195] to either have enterprise accounts

[1341.195 - 1343.355] that have agreements in place not to train

[1343.935 - 1347.715] the models on your data that you input into it, um,

[1348.455 - 1350.595] or just in your personal accounts that you have on these,

[1350.595 - 1353.235] most of those include settings now as long as you're paying

[1353.235 - 1354.915] for the, but not just on the free models that allow you

[1354.915 - 1355.915] to go in and talk with that on

[1355.915 - 1359.475] and off from a legal specific standpoint, one

[1359.635 - 1363.915] of the guardrails that my team, uh, is a bare minimum is

[1363.915 - 1366.475] that if we're using a public tool like chat GPT

[1366.495 - 1370.155] or anthropic to always, um,

[1370.815 - 1374.475] obs obfuscate the like client or the company information.

[1374.775 - 1377.395] So use Acme Co instead of Jasper.

[1378.135 - 1380.915] Uh, the tools like White Shoe

[1380.915 - 1383.315] and GC AI do this naturally.

[1383.385 - 1386.115] They like encrypt data in transit at rest

[1386.855 - 1389.035] and white shoe even like hashes it so

[1389.035 - 1391.195] that the LILM isn't even seeing like

[1391.195 - 1392.395] only the user's able to see it.

[1392.935 - 1396.395] Um, so those types of things get me comfortable that one,

[1396.395 - 1398.395] you're not sacrificing attorney-client privilege,

[1398.655 - 1401.635] but then two, like the only person who's ever gonna see the

[1401.635 - 1405.355] actual company information is, um, is yourself.

**[Speaker 2]**

[1406.055 - 1408.555] And will you, um, will you explain

[1408.555 - 1412.195] to the audience why you wouldn't want the the models

[1412.255 - 1413.355] to train on that data?

**[Speaker 3]**

[1413.565 - 1415.755] Definitely, yeah. So this,

[1416.635 - 1419.325] this become is becoming actually more and more of a problem

[1419.325 - 1422.525] because the big model providers, uh, believe it

[1422.525 - 1425.005] or not, are running out of quality information to,

[1425.125 - 1427.365] to train their models on that basically legally

[1427.545 - 1429.365] or illegally, whatever your stance is on that,

[1429.365 - 1431.685] scraped the internet of any good written content

[1431.745 - 1433.405] to train the models from a base case.

[1433.745 - 1436.645] So they're now beginning to rely on continual user

[1437.195 - 1440.445] involvement in the models to determine what types

[1440.465 - 1441.965] of prompts and outputs are good.

[1442.025 - 1444.285] And then they'll ingest that information.

[1444.285 - 1446.285] So if you submit a question about Jasper

[1447.305 - 1449.445] and you're asking it like a bunch of detailed legal

[1449.465 - 1452.485] and financial data and you don't have the setting turned off

[1452.985 - 1455.365] or not to train on your models, um,

[1455.705 - 1457.485] in theory they could be storing

[1457.485 - 1459.805] that information in some database or table

[1460.225 - 1462.605] and in a future iteration che GT five

[1462.625 - 1466.565] or something, it could come out and Jason could then log on

[1466.825 - 1467.925] and be asking it a question

[1467.945 - 1471.685] and unintentionally it could output information about Jasper

[1471.785 - 1473.845] or our finances or anything like that.

[1474.465 - 1476.925] Uh, which is obviously a pretty big red flag.

**[Speaker 2]**

[1477.145 - 1481.005] So the, the chat's going wild, talking about, uh, g gca,

[1481.195 - 1484.485] AI's ability to, um, come up with the prompts.

[1484.665 - 1487.645] And we're gonna do, uh, a little bit of that sort

[1487.645 - 1488.765] of in real time.

[1488.985 - 1492.805] So, um, Jason, do you wanna talk through, uh,

[1492.965 - 1494.285] a super prompt that you created?

**[Speaker 3]**

[1495.295 - 1497.995] Oh yeah, sure. So let me share my screen.

[1498.415 - 1501.195] Uh, super prompt is a bit of a misnomer.

[1501.475 - 1504.795] I created this in preparation for this panel.

[1505.155 - 1507.075] I didn't put the most effort into it.

[1507.615 - 1510.915] So generally speaking, I tried to create a prompt

[1511.065 - 1514.275] that provides as much generally applicable context

[1514.535 - 1518.955] as possible, organizes how the response should be laid out,

[1519.095 - 1522.995] as you can see here, tells it how I want it to think

[1523.875 - 1527.495] and when applicable tells it how to research.

[1527.895 - 1530.615] 'cause sometimes there are, sometimes it executes brief

[1530.815 - 1533.175] searches, but a lot of times with these deeper

[1533.695 - 1535.335] research projects, that is not what you want.

[1535.875 - 1539.175] So you, I don't recommend just using this for everything.

[1539.175 - 1542.015] This is more of just an exercise in thinking how

[1542.015 - 1543.135] to pull these prompts together.

[1543.395 - 1546.735] And, uh, I guess furthermore, this is probably more tailored

[1546.955 - 1550.575] to more basic tools and less deep reasoning models

[1550.575 - 1554.335] because as I understand it a lot, a lot of models now do

[1554.965 - 1556.855] some of these steps by themselves.

[1557.615 - 1561.355] But y this is here, if anyone finds it helpful,

[1561.615 - 1563.755] and I understand this is

[1563.895 - 1566.795] or will be soon circulated to both here.

**[Speaker 2]**

[1568.395 - 1569.735] It it has already been.

[1569.915 - 1574.175] And I guess staying on the, the topic here, Jason, what,

[1574.205 - 1577.655] what does auditing look like, um, for you and your team?

[1578.115 - 1580.295] Do you actually audit what people use for prompts?

[1580.295 - 1581.535] Do you have a library and,

[1581.555 - 1584.295] and do you, do you, uh, do you ever look at what,

[1584.795 - 1586.535] what's being used as prompts?

**[Speaker 3]**

[1588.305 - 1590.405] Uh, so we don't audit.

[1590.725 - 1593.285] I think generally as a team, we like to come together

[1593.385 - 1595.365] and discuss best practices.

[1595.675 - 1597.045] This works, this doesn't,

[1597.145 - 1599.525] but our policies are pretty trust based.

[1599.665 - 1604.285] We do have a usage policy like Alex was mentioning, um,

[1604.555 - 1608.855] that, but that mostly says if you're using a tool,

[1608.995 - 1611.375] you shouldn't be using tools that don't go through InfoSec.

[1611.375 - 1614.655] But if you are, don't give it confidential information.

[1615.315 - 1616.415] No matter what tool you're using,

[1616.435 - 1617.615] you are responsible for outcomes.

[1617.615 - 1621.735] And it's basically just saying treat these vendors like

[1621.875 - 1622.895] any other vendors.

[1623.155 - 1626.335] But no, we're not telling people when they're allowed

[1626.335 - 1627.775] to prompt or how they're allowed to prompt

[1627.775 - 1630.575] because to me that kind of seems like telling somebody how

[1630.575 - 1631.735] to think or how to Google

[1631.995 - 1635.655] or use any other tool that we'd trust them to use.

**[Speaker 2]**

[1637.555 - 1640.735] And I know we, we haven't talked about agents,

[1640.835 - 1642.815] but we did get a question in the chat.

[1643.115 - 1646.575] Um, Jason and, and Alex, please fill in to chime in right

[1646.575 - 1649.295] after, are either of you creating agents?

**[Speaker 3]**

[1650.775 - 1652.555] We are, our our company is doing it.

[1652.555 - 1654.315] Our legal department is, is not.

[1654.415 - 1657.715] So it's not something that has yet entered my workflow.

[1658.195 - 1660.595] I it sounds like Alex has a more useful answer.

[1662.315 - 1664.445] Yeah, I was just gonna say that ironically,

[1664.905 - 1668.205] two weeks ago we made our first agent for internal,

[1668.605 - 1670.205] internal, uh, legal use cases.

[1670.355 - 1672.445] Just we had like a offsite hackathon

[1672.545 - 1674.165] for our legal team and finance team.

[1674.915 - 1677.295] And, um, one of the tools

[1677.435 - 1680.775] or work workflows we used was, uh, through

[1681.335 - 1683.895] Zapier we created a Zap, which it's like a,

[1684.175 - 1687.415] Zapier is like a pretty inexpensive automation platform

[1687.415 - 1688.495] if you're not familiar with it.

[1688.565 - 1690.415] It's, it's pretty user friendly.

[1690.675 - 1693.175] You might have to have some technical experience with it,

[1693.715 - 1696.135] but, uh, it's kind of drag and drop and,

[1696.275 - 1701.095] and using, um, our Slack API keys that we're able

[1701.095 - 1702.815] to link, uh, to it

[1702.955 - 1707.895] and then open AI's models through their API keys and Zapier.

[1708.275 - 1711.135] We created a kind of a triage chat bot

[1711.135 - 1712.655] for our deal desk Slack channel.

[1713.315 - 1715.495] And when new messages come in from the sales team

[1715.495 - 1718.655] or our customer success team, it'll, you know,

[1718.935 - 1721.215] reference a knowledge base that we created and uploaded

[1721.875 - 1724.135] and then accurately route those questions

[1724.135 - 1725.535] to the right internal stakeholder

[1725.595 - 1727.175] for approvals or for review.

[1727.875 - 1730.535] Um, we have not yet allowed it

[1730.535 - 1732.095] to straight up answer legal questions.

[1732.195 - 1734.695] I'm not super comfortable with end users being able

[1734.695 - 1736.935] to receive that without an attorney input.

[1737.515 - 1741.095] But basic like billing finance questions, it does answer

[1741.115 - 1742.455] and it's, it's pretty accurate.

[1742.915 - 1745.255] Um, and one of the things we did to save us time

[1745.275 - 1748.255] as well is we like downloaded, we used the Slack API

[1748.875 - 1751.695] and scanned the last year of messages in this channel

[1752.315 - 1754.095] and directed OpenAI

[1754.795 - 1757.895] or chat JT to figure out like

[1757.895 - 1759.375] what the most common questions were,

[1759.395 - 1761.175] who they were most commonly routed to,

[1761.525 - 1762.695] what the responses were.

[1762.755 - 1766.735] So we grounded the, um, chat bot's responses in

[1766.735 - 1768.815] that knowledge from the last year's context as well.

[1769.435 - 1771.135] And it's been live now

[1771.155 - 1772.975] for a couple weeks and it's pretty great.

[1772.975 - 1775.455] That's the first like agentic use case. We've, we've

**[Speaker 2]**

[1775.455 - 1780.015] Done, we use a lot of Zaps at, uh, at law trades

[1780.155 - 1781.365] and they're pretty awesome.

[1781.505 - 1784.325] But I think, yeah, probably the general consensus is folks

[1784.325 - 1787.525] wanting a human to stay in the loop on, on questions.

[1788.145 - 1791.925] Um, we, we got a question about, uh, being comfortable

[1791.925 - 1795.125] with inputting sensitive client data into, um,

[1795.125 - 1796.125] enterprise accounts.

[1796.225 - 1798.725] Say for example, OpenAI, I think we touched on

[1798.725 - 1802.045] that a little, um, which is about systems

[1802.115 - 1804.605] that encrypt things, you know, and

[1804.665 - 1807.965] or anonymizing, like, like for example, Alex,

[1808.025 - 1810.125] you said making something Acme not your company.

[1810.545 - 1813.885] Um, are those the best practices for, for not, uh,

[1813.885 - 1816.245] putting client data into these models? Yeah,

**[Speaker 3]**

[1816.405 - 1821.285] I think, um, for the general purpose models like open AI

[1821.285 - 1823.885] and philanthropic, it's, if you're wanting

[1823.905 - 1826.365] to be extra cautious, you can always just use

[1826.555 - 1827.805] Acme or something like that.

[1828.425 - 1831.645] Um, that requires a bit more of a manual lift.

[1831.665 - 1833.325] It might be slower and inefficient

[1833.325 - 1834.605] because you're having to do that every time,

[1834.605 - 1836.645] especially if you're uploading documents to it,

[1836.725 - 1838.485] you're having to, you know, find

[1838.485 - 1840.685] and replace any usage of, uh,

[1840.685 - 1842.885] confidential company information to do that.

[1843.755 - 1846.415] Um, but yeah, like honestly,

[1846.415 - 1848.495] the easy answer is you'll probably just want

[1848.495 - 1850.255] to use a tool like White Shoe

[1850.255 - 1852.975] or GCI where it allows you to go in

[1852.975 - 1854.975] and create a company profile

[1855.035 - 1857.135] or client profiles if you need more than one.

[1857.905 - 1859.485] And you enter all this information

[1859.505 - 1862.565] and then the M'S responses throughout the platform

[1862.995 - 1865.085] automatically incorporate that information

[1865.825 - 1868.605] and it's encrypted and like remains secure too,

[1868.605 - 1871.005] which is useful and speeds up processes

[1871.005 - 1873.005] and makes it more accurate, all that stuff.

[1873.675 - 1875.725] Yeah, I guess just to add on to that,

[1876.065 - 1878.125] my view has always been if the,

[1878.385 - 1879.845] if your team has gotten comfortable

[1879.845 - 1881.725] that the InfoSec protections are there

[1882.105 - 1884.965] and you're comfortable that the legal protections are there,

[1884.965 - 1887.605] then I, I treat these things like any other vendor.

[1887.795 - 1890.325] There's of course gonna be incremental risk anytime you

[1890.465 - 1892.835] expand your circle of trust at all.

[1893.135 - 1895.355] But I, I don't think that these things are

[1895.355 - 1898.195] that different from any other vendors is my takeaway.

**[Speaker 2]**

[1898.825 - 1901.035] Okay. So we've been through prompts,

[1901.455 - 1903.435] we touched on agents very quickly.

[1903.575 - 1904.995] We talked about guardrails.

[1905.795 - 1908.345] There are a lot of people trying to discern in the chat,

[1908.595 - 1910.065] which is the right tool for them.

[1910.605 - 1914.265] So let's take them through tool selection

[1915.485 - 1920.255] when it comes to oversight, tool selection,

[1920.765 - 1924.375] what you do, Jason, like what can you take people

[1924.375 - 1927.415] through on, on, on human oversight?

[1927.755 - 1930.655] Um, you know, any advice on like

[1931.605 - 1932.855] what they can do there?

**[Speaker 3]**

[1934.705 - 1936.595] Yeah, I'll just regurgitate some

[1936.595 - 1937.875] of the other things I've said already,

[1938.015 - 1940.635] but I think you need to have, you need, you want

[1940.635 - 1943.635] to have a BS meter on the subjects you're asking it about.

[1943.855 - 1946.795] If you do not, then you should instead be using it to

[1947.535 - 1949.115] figure out what you don't know

[1949.175 - 1953.075] and frame a more intelligent question to somebody who does,

[1953.975 - 1955.995] uh, when you can do that.

[1955.995 - 1958.035] Or I suppose even if you can, you should try

[1958.035 - 1961.885] to ask questions that allow you to spot check the outputs

[1961.905 - 1965.045] as well, and that helps you to falsify responses.

[1965.185 - 1968.955] But I suppose the, the general point is that

[1969.735 - 1974.595] our job as AI augmented attorneys is knowing what

[1974.595 - 1976.555] to ask when and how,

[1976.895 - 1980.875] and that job itself cannot be yet replicated

[1981.015 - 1982.795] by ai. So yeah.

**[Speaker 2]**

[1983.505 - 1987.455] Fantastic. And Alex, um,

[1988.785 - 1991.365] uh, uh, hopefully like you, you know,

[1991.365 - 1992.485] you've touched on this a little bit,

[1992.505 - 1995.125] but do you have any further insight on

[1995.465 - 1999.365] how you decide which AI platform to do for, for which task?

[2000.175 - 2001.395] Any, any magic there?

**[Speaker 3]**

[2002.875 - 2007.765] Yeah, so I would say the default program nowadays we use

[2007.905 - 2010.325] for contract redlining is Ivo

[2011.135 - 2015.015] and essentially everything else, it's uh, white,

[2015.015 - 2017.335] it's been a white shoe ai and that's largely

[2017.335 - 2021.795] because it just like, one, it's super cost effective, um,

[2022.415 - 2025.345] but two, it does a lot

[2025.345 - 2027.745] of this stuff we're talking about on the backend without you

[2027.745 - 2029.665] having to really like know coding

[2029.725 - 2032.185] or how to prompt specifically, it'll enhance your prompts.

[2032.845 - 2036.225] Um, if you go into like their chat bot for instance,

[2036.765 - 2038.785] you can, there's a dropdown of like the

[2039.385 - 2041.105] practice area you want it to be an expert in.

[2041.445 - 2043.545] So I know if I'm asking it about a term sheet

[2043.565 - 2045.265] for some financing, I can go in

[2045.265 - 2048.305] and select the, just like a law firm, the emerging companies

[2048.305 - 2049.585] and venture capital practice group.

[2049.925 - 2051.185] And it's actually like adjusted

[2051.185 - 2052.665] and it's a fine tuned model for that.

[2052.665 - 2055.985] And that's like substantially better responses than if I

[2055.985 - 2058.225] just go into chat GPT and ask a question.

[2058.765 - 2059.865] Um, so there's a bit of that.

[2060.005 - 2063.265] And then I think internally, just like budget wise,

[2063.435 - 2067.185] we're super cost conscious, so we don't want tool creep,

[2067.185 - 2068.705] we don't want a ton of tools that do the same thing.

[2069.485 - 2071.465] Um, quite frankly, by the end of this year,

[2071.475 - 2074.585] we're probably gonna churn from either GCI or Ivo

[2074.585 - 2076.585] because they're both starting to cross paths

[2076.585 - 2079.345] and like do the same thing as the, as each other

[2079.885 - 2082.105] and we're just gonna have to determine which one's the best

[2082.105 - 2084.505] at doing it and save eight grand a year or whatever.

**[Speaker 2]**

[2085.585 - 2088.865] Interesting question. Um, does anyone have

[2090.325 - 2092.625] walled off instances by department?

[2093.005 - 2097.545] For example, HR or legal or any other department?

[2097.655 - 2098.905] I've never heard of that, but that's

[2098.905 - 2099.945] an interesting question we got.

**[Speaker 3]**

[2100.695 - 2103.055] I think I'd probably have to ask a follow-up question

[2103.055 - 2105.535] to ever asked it by what they mean by walled off.

[2105.535 - 2108.975] If it's like a private instance of a, you know,

[2109.345 - 2112.655] cloud hosted model just on your internal workspace at your

[2112.655 - 2115.025] company that only certain lawyers

[2115.125 - 2116.585] or finance people can access.

[2117.085 - 2120.345] If that's the question, we certainly don't, that would be

[2120.875 - 2123.135] really expensive, difficult to implement.

[2123.875 - 2126.485] But with that being said, I'm sure there are

[2127.015 - 2128.165] large legal departments

[2128.305 - 2130.245] and really sophisticated companies,

[2130.845 - 2132.045] probably Fortune 20 companies

[2132.595 - 2134.565] that prioritize that type of use case.

[2134.665 - 2137.565] For most of us on this call though, it's probably

[2138.345 - 2140.405] too cumbersome to implement something like that.

[2141.105 - 2144.365] And tool selection itself probably helps with that.

[2144.365 - 2146.965] Like Jasper is a marketing AI tool

[2146.985 - 2148.845] and like as much as I'd love to say it's great

[2148.845 - 2150.125] for lawyers, it it's horrible.

[2150.345 - 2152.325] Um, so like I don't ever use our own product,

[2152.465 - 2154.925] but like our marketing team uses it like crazy

[2155.585 - 2157.645] and like similarly they're not gonna ever use

[2158.125 - 2159.525] GC AI or White Shoe.

[2159.835 - 2162.325] It's like that kind of helps wall it off itself,

[2162.505 - 2165.885] but they're certainly not like privately hosted models

[2165.955 - 2168.085] that only Jasper has access to.

[2169.605 - 2173.775] Yeah. Uh, I'm likely speaking well over my skis here,

[2173.915 - 2177.745] but I think the only tool that most

[2177.845 - 2180.425] of my company has access to is chat GPT

[2180.485 - 2184.465] and I, I believe that that is relatively segregated by

[2185.145 - 2186.385] specific individual account,

[2186.605 - 2189.565] but if if that's not the case, then I'm just wrong.

[2189.665 - 2191.085] So there's that.

**[Speaker 2]**

[2192.165 - 2195.505] So I am going to bring us, um,

[2196.495 - 2198.635] to perhaps like the most exciting part.

[2199.295 - 2203.595] Uh, let's talk about how utilizing AI

[2204.455 - 2206.435] can actually save us time.

[2207.095 - 2209.675] Um, does anyone, uh, uh, actually,

[2209.675 - 2211.515] sorry Alex, let's start with you.

[2212.375 - 2215.515] Can you talk about how much time you're spending

[2215.695 - 2218.235] and saving by utilizing these tools

[2218.615 - 2222.715] and uh, have you been able to not outsource to someone

[2223.215 - 2225.435] and you can say you have tangible numbers.

**[Speaker 3]**

[2226.105 - 2230.835] Yeah, definitely. So I joined Jasper three years ago, um,

[2231.295 - 2235.435] before chat GBT became publicly available, uh, which

[2235.985 - 2238.915] partially obliterated our downmarket business at

[2238.915 - 2240.275] Jasper, but that's okay.

[2240.375 - 2243.055] Um, we pivoted, but before then,

[2243.275 - 2246.865] and probably for the six months thereafter, chat, GBT

[2246.885 - 2250.025] and the generally available tools were pretty horrendous

[2250.125 - 2251.305] at doing legal work.

[2251.415 - 2253.505] Like I think whenever they test him on the bar,

[2253.935 - 2256.545] they were hardly passing or like not passing.

[2257.435 - 2260.905] Since then, like over the last 18 months to 24 months,

[2261.565 - 2263.745] the general tools have become super useful

[2263.745 - 2266.105] and then there's all these legal AI startups

[2266.105 - 2267.665] that have spr it up with specific tools.

[2268.665 - 2270.665] And beginning about two years ago we started like heavily

[2270.665 - 2273.665] implementing, um, tool usage

[2273.725 - 2276.145] for AI within our legal department.

[2276.685 - 2279.825] And over that two year period, our

[2279.825 - 2282.825] outside counsel spend has decreased 93%.

[2283.485 - 2286.235] So we we're saving like $200,000 a year.

[2287.035 - 2289.535] And that our outside council firms probably aren't real,

[2289.635 - 2292.535] but like we go to AI as like a

[2292.925 - 2294.295] what you would treat like a junior

[2294.475 - 2295.655] or even mid-level associate.

[2295.725 - 2298.575] Some of these firms, which it blows my mind nowadays when

[2298.575 - 2300.255] you get bills for junior associates

[2300.255 - 2301.455] that are seven 50 bucks an hour.

[2302.035 - 2305.445] Um, so like we, we use that largely

[2305.825 - 2307.525] for like high stake stuff, obviously,

[2307.635 - 2309.045] like if it's a financing

[2309.045 - 2311.125] or an acquisition, we're still gonna use

[2311.435 - 2312.565] like real outside firms.

[2312.665 - 2314.165] But for the day-to-day stuff that most

[2314.165 - 2318.445] of us like at L Suite in-house departments, um, we just need

[2318.445 - 2320.725] to like expand our reach and speed as quickly

[2320.785 - 2322.005] and as cheaply as possible.

[2322.545 - 2326.325] And AI has in my mind, revolutionized the practice of law

[2326.545 - 2327.605] by being able to do that.

[2328.025 - 2330.285] So yeah, we've saved 92% over two years.

[2330.865 - 2332.365] And then in terms of like time saved,

[2332.465 - 2334.405] I'm sure I could like get, get an accurate

[2334.545 - 2337.565] or close to accurate hours per week saved.

[2338.225 - 2340.565] But I think the better metric is that

[2341.525 - 2345.005] given our like legal intake volume,

[2345.225 - 2346.765] our sales contract review volume

[2346.825 - 2349.285] and all that, we should be ending this year

[2349.285 - 2351.165] with five or six attorneys.

[2351.185 - 2354.005] We should currently have four, we only have two

[2354.185 - 2356.085] and we're not like crazy overworked

[2356.085 - 2357.165] or not more than anyone else

[2357.585 - 2359.245] and we don't plan on adding head

[2359.245 - 2360.325] count by the end of the year.

[2360.905 - 2362.325] So if you take that for what it's worth,

[2362.395 - 2364.845] it's like essentially one lawyer is doing the work

[2364.845 - 2366.445] of three by using AI Now

**[Speaker 2]**

[2366.795 - 2370.005] That, that is like quite a win.

[2371.205 - 2372.785] Uh, Jason, how about you?

**[Speaker 3]**

[2374.195 - 2377.555] I don't have, uh, specific figures like Alex does,

[2377.615 - 2379.435] but I suppose more anecdotally,

[2380.075 - 2383.395] I recently maybe two months ago closed an m

[2383.395 - 2386.955] and a transaction just by myself using AI tools

[2387.475 - 2389.395] opposite a full Kirkland and Alice bench.

[2389.575 - 2393.515] So that is not something I could do unassisted by ai.

[2393.795 - 2396.155] I probably saved, it wasn't the biggest transaction,

[2396.175 - 2399.115] it might have cost $30,000 through big law

[2399.575 - 2403.595] or $15,000 through medium law service providers,

[2403.615 - 2405.755] but it's really nice to be able

[2405.755 - 2407.675] to just internalize things like that.

[2409.695 - 2410.695] AI assisted,

**[Speaker 2]**

[2411.955 - 2413.455] No, I think, I think you're not

[2413.455 - 2414.495] giving yourself enough credit.

[2414.635 - 2415.935] That's really impressive.

[2416.095 - 2417.535] I mean, if we got to a world

[2417.585 - 2421.495] where this could assist in lobbing off like huge m

[2421.495 - 2424.255] and a expenses, because obviously law firms have been using

[2424.255 - 2425.815] this sort of tooling for a really long

[2425.815 - 2426.975] time to do this, right?

[2427.595 - 2431.655] Um, and so if we're able to do that in-house, um,

[2431.895 - 2433.175] a little bit more independently,

[2433.475 - 2434.855] that's really very impressive.

[2435.595 - 2439.445] There's, there's some, uh, excitement in the chat. Okay.

[2440.185 - 2443.915] Um, before we close Jason,

[2444.305 - 2446.755] what is one piece of advice you would give someone

[2447.135 - 2451.875] who just started looking at these tools, prompting, um,

[2452.025 - 2455.195] getting comfortable, wants to give their team,

[2455.535 - 2457.035] you know, a speech about it.

[2457.305 - 2459.115] What kind of advice do you wanna give to someone?

**[Speaker 3]**

[2460.905 - 2462.845] Uh, pick your tools wisely.

[2463.265 - 2465.805] I'm definitely, I'm probably not the best at that,

[2465.905 - 2468.605] but I, I like what I have and I'd found success with it.

[2469.345 - 2472.165] Uh, be smart about how you ask questions.

[2472.365 - 2475.485] I won't go into the whole spiel I've recycled a few times

[2475.485 - 2477.525] already, but that is very important.

[2477.785 - 2481.125] And don't trust outputs. Verify them,

**[Speaker 2]**

[2483.755 - 2484.865] Trust them, verify.

[2485.135 - 2487.465] Alex, what about you? What advice would you give somebody?

**[Speaker 3]**

[2489.435 - 2493.205] Yeah, I'm once again just gonna rip from Ethan Malik's

[2493.245 - 2495.445] book, which I'd recommend anyone read.

[2495.475 - 2499.285] It's incredible. But I'd say first like, treat AI

[2499.285 - 2500.365] as a co intelligence.

[2500.985 - 2502.605] Um, he projects

[2502.605 - 2506.245] that like within five years humans will become cyborgs,

[2506.245 - 2508.725] meaning like we're almost everything we do in work

[2509.345 - 2512.445] is augmented to some degree by degree an ai.

[2512.705 - 2515.565] Um, and that's certainly been come the case in my own

[2516.315 - 2518.765] work life and I found it incredibly useful.

[2518.785 - 2521.205] So I think treating it as a co co intelligence

[2521.205 - 2523.525] and just helping you think, even if you like,

[2523.785 - 2526.425] are most certain, you know, the answer to something like,

[2526.525 - 2528.865] you know, we all, we all have like implicit biases

[2529.045 - 2531.705] and having it critique those things to um,

[2532.375 - 2535.695] like re refine our reasoning is always useful.

[2536.315 - 2540.105] Um, and then I'd also just be comfortable

[2540.495 - 2543.025] with like good enough responses from ai.

[2543.025 - 2544.105] That's probably my second point.

[2544.615 - 2547.625] It's like, at first I was like, oh, you know,

[2547.625 - 2550.265] it's not passing the bar at a 99% pass rate,

[2550.765 - 2552.985] but most lawyers aren't either.

[2553.445 - 2556.585] Um, most lawyers like I, if I'm hiring someone,

[2556.765 - 2558.745] I'm happy if they're consistently outputting 80

[2558.965 - 2560.545] to 85% results.

[2560.845 - 2563.225] Now I could say human, it's like if the AI's doing that,

[2563.285 - 2566.255] but for 20 bucks a month it's pretty incredible

[2566.475 - 2569.055] and like I can improve the other 20% to make it better.

[2570.175 - 2572.275] And then three, I think like the more

[2572.275 - 2575.635] that you can ingest kind of like the geeky, nerdy AI stuff

[2575.635 - 2578.395] through newsletters or videos or whatever, the better.

[2578.465 - 2581.795] Like, uh, a few weeks ago Sam Altman had like a really

[2582.075 - 2583.475] interesting interview on a panel he was on.

[2584.175 - 2587.565] Um, and uh, the interviewer asked him

[2587.795 - 2591.435] what they've noticed at Open AI about different generations

[2591.455 - 2593.635] and how they use ai

[2593.635 - 2598.035] and he commented how like the older generations are using,

[2598.455 - 2601.435] um, AI as you know, the memes that we used

[2601.435 - 2605.035] to see 20 years ago from our grandparents asking questions

[2605.035 - 2606.875] to Google that like didn't make any sense.

[2607.535 - 2608.915] But like ironically now, like

[2608.915 - 2611.395] that's actually like a pretty ideal way to use AI

[2611.395 - 2612.435] for someone who doesn't need it

[2612.435 - 2613.555] for some specialized use case.

[2613.555 - 2614.795] It's just like treating like another

[2614.795 - 2616.035] human asking it questions.

[2616.185 - 2617.315] They're using it like that.

[2617.775 - 2619.795] The people who are like, you know, in the market

[2620.055 - 2623.075] and have integrated this into their work over the last two

[2623.075 - 2626.755] years are using it largely how it's intended to be using,

[2626.755 - 2630.275] asking it to act in a role, trying to verify outputs, having

[2630.295 - 2632.895] to critique reasoning that that sort

[2632.895 - 2633.895] of stuff refined writing.

[2634.315 - 2637.735] Um, but then he found the most interesting was

[2637.735 - 2639.775] that younger generations, like people in high school

[2639.795 - 2644.575] and college are using AI as like a new operating system.

[2644.805 - 2646.535] Like rather than going to their computer

[2646.715 - 2650.695] or their phone as like their main source of computation

[2650.755 - 2653.175] and operating system, these people are just starting

[2653.175 - 2654.695] to use like ai, um,

[2654.695 - 2656.535] because they've grown up with it, it's intuitive for them.

[2656.915 - 2661.495] So things like keeping like a eternal thread on chat GBT

[2661.495 - 2664.135] and having it store to do tasks and calendaring.

[2664.515 - 2666.535] I'd rather than using like Gmail calendar,

[2667.625 - 2668.635] they just use this now

[2668.635 - 2671.315] and they'll ask like every morning, tell me

[2671.315 - 2672.515] what I need to do today.

[2672.905 - 2674.875] It's like that type of stuff that most

[2674.875 - 2676.195] of us wouldn't intuitively think

[2676.355 - 2677.715] 'cause we're so used to using other tools.

[2678.255 - 2681.595] Um, and I think staying current on like best AI use cases

[2681.695 - 2684.235] and whatnot, even if it's sometimes nerdy

[2684.235 - 2686.395] and even if they get into like the technical jargon,

[2686.665 - 2687.795] it's still interesting to hear

[2687.795 - 2690.515] how like the most cutting edge people are starting to use it

[2690.515 - 2691.955] so that we can try and adapt that

[2691.975 - 2693.195] for like our legal use cases.

**[Speaker 2]**

[2694.285 - 2696.725] I have started to ask chat

[2697.085 - 2698.205] questions that I used to Google.

[2698.745 - 2700.965] Um, like it, it's become, and

[2700.965 - 2704.405] and that's actually a big thing now is like SEO optimization

[2704.585 - 2707.405] inside of the responses that say like,

[2707.405 - 2709.125] chat will give you a cloud we'll give you.

[2709.665 - 2712.125] Um, but yeah, that's been my go-to recently

[2712.225 - 2715.645] and so I've even seen my own, uh, behavior shift.

[2716.225 - 2717.765] Uh, we, I'm very excited.

[2717.785 - 2720.605] We have a lot of really, uh, really great questions.

[2720.945 - 2724.525] Let me ans let me ask one, uh, that just came up Jason.

[2725.465 - 2729.165] Um, specifically what tool did you use for, for that m

[2729.165 - 2731.285] and a um, uh, support?

**[Speaker 3]**

[2731.795 - 2734.085] Yeah, I should have provided some more details.

[2734.225 - 2737.565] So again, I'm not the expert in which tool to pick.

[2737.845 - 2740.005] I use GCAI, it helped

[2740.075 - 2742.045] that I am an m and a attorney by training.

[2742.075 - 2743.485] I've run lots of deals, so

[2744.515 - 2747.445] give me most pretty decent tools

[2747.545 - 2749.765] and I can run with my little robot minions

[2749.765 - 2752.965] and close deals so that, that may not be the best approach,

[2752.985 - 2754.005] but it worked very well

[2754.005 - 2756.525] for me is all I can say from my anecdote.

**[Speaker 2]**

[2757.075 - 2758.965] Well, and I think you're overlaying it

[2758.965 - 2761.165] with what's important, which is you had the expertise

[2761.225 - 2764.325] to be able to see that the outputs like, like

[2764.325 - 2765.485] that domain expertise.

[2765.585 - 2767.325] So someone who maybe doesn't have it,

[2767.475 - 2769.605] that may be like you might have that edge,

[2769.605 - 2772.005] which is I think extremely fair in a lot of

[2772.005 - 2773.325] what we've been talking about today.

**[Speaker 3]**

[2773.355 - 2776.045] Certainly if you don't have the expertise to run

[2776.565 - 2778.085] a certain kind of transaction

[2778.225 - 2781.285] or process, AI won't give you that expertise,

[2781.585 - 2784.405] but if you do, it's a very good resource.

[2784.935 - 2786.635] That's right. And we've all been saying, yeah.

**[Speaker 2]**

[2787.865 - 2791.695] So, um, Alex, this, this goes back to something you said,

[2791.755 - 2794.935] uh, a little bit earlier, like on note taking for example,

[2795.095 - 2798.255] I think we're all sort of running Zoom AI or granola

[2798.255 - 2802.015] or some flavor of, of, uh, an automated note taker.

[2802.235 - 2806.415] Um, when you're utilizing a tool like that, how do both

[2806.435 - 2809.215] of you get comfortable with preserving privilege

[2809.215 - 2810.215] and confidentiality?

**[Speaker 3]**

[2811.025 - 2813.715] Yeah, the easy answer is I don't get comfortable

[2813.735 - 2815.915] and I haven't, we, we've honestly been trying

[2815.915 - 2818.475] to restrict the Zoom recording

[2818.615 - 2821.615] or gran, we use granola internally.

[2821.885 - 2825.335] Granola currently doesn't have a feature to like auto delete

[2826.005 - 2828.255] some period, like a retention timeline basically.

[2828.375 - 2831.665] I wish it did. Um, so we just try

[2831.665 - 2833.185] to coach our people like not to use

[2833.185 - 2835.545] that in a board meeting obviously,

[2835.645 - 2839.265] or like anything even slightly lower stakes than that.

[2839.805 - 2841.645] Um, but with that being said,

[2841.715 - 2844.085] it's like we're certainly not taking a restrictive stance

[2844.085 - 2845.685] saying you can't use this because the fact

[2845.685 - 2848.245] of the matter is it's, it's saving people tons of time.

[2848.835 - 2852.405] It's a more accurate note taker than humans certainly are.

[2852.405 - 2855.565] It allows people to focus on the human being across the

[2855.565 - 2857.245] screen from them in a meeting rather than

[2857.295 - 2858.365] focus on taking notes.

[2858.835 - 2862.485] It's like those things in my mind far outweigh the risks

[2862.585 - 2864.205] as long as you're like being careful.

[2864.355 - 2867.885] Like if, you know, we haven't had a data breach,

[2867.905 - 2869.845] but if I'm on the phone and we're talking about a data

[2869.845 - 2871.165] breach with my ciso,

[2871.705 - 2874.925] I'm not gonna have granola recording, uh, the message there.

[2874.945 - 2877.965] Or if I do, I'm gonna immediately, I'm gonna take the notes,

[2878.015 - 2880.725] maybe print them out or keep them in some physical form

[2881.025 - 2883.365] and delete like the transcript of it from the servers.

[2883.365 - 2887.165] Something like that. Yeah, this is an issue we've discussed,

[2887.395 - 2888.605] perhaps not at length,

[2888.665 - 2890.005] but it's, it's come up

[2890.135 - 2893.885] where there are obvious discovery implications for anything

[2893.995 - 2895.205] that I'll use.

[2895.205 - 2897.845] Zoom AI as an example, just automatically saves

[2897.845 - 2901.685] and emails out to everybody where I master of the universe.

[2901.925 - 2906.525] I would make it so that you can ask it questions based on

[2906.595 - 2908.645] what it's sort of stored.

[2909.145 - 2911.445] You can get the answers and then you use those notes

[2911.725 - 2915.565] yourself rather than just these AI summarized call

[2915.565 - 2917.485] transcripts, which are just there forever,

[2917.705 - 2920.095] but may maybe that'll be a feature one day

[2920.095 - 2921.295] and maybe it already is and I just

[2921.295 - 2922.455] haven't figured out how to use it.

[2922.555 - 2924.215] But that, that's what I would prefer.

**[Speaker 2]**

[2924.695 - 2926.895] I I'm gonna pivot a little bit to CLMs.

[2927.115 - 2931.335] So the question is largely around like AI tools

[2931.555 - 2934.055] and CLMs, um, and it's it

[2934.115 - 2936.895] and it's, is there, is there an easier way

[2936.895 - 2938.895] to redline contracts, for example,

[2939.005 - 2943.695] utilizing like an AI word plugin versus going the full route

[2943.835 - 2945.575] of A CLM implementation?

[2946.855 - 2949.275] And this is probably largely an opinion

[2949.455 - 2951.235] and largely based on the size and scale

[2951.295 - 2952.755] and scope of your organization,

[2953.295 - 2957.635] but if either of you find, um, utilizing an AI tool, uh,

[2957.895 - 2961.195] to be maybe easier than that implementation

[2961.215 - 2962.435] or any insights there?

**[Speaker 3]**

[2963.145 - 2964.715] Yeah, I definitely have an opinion

[2964.815 - 2966.395] and it's not overly positive.

[2966.695 - 2969.555] Um, so we implemented a CLM solution.

[2970.215 - 2972.355] The biggest one probably that you guys are all familiar

[2972.355 - 2975.935] with, um, coming up on two and a half years ago

[2975.935 - 2978.735] and during that time had like a bake off between

[2979.745 - 2980.975] three of the best ones.

[2980.995 - 2984.135] The only one at that time that I found that was good at uh,

[2984.685 - 2986.935] like contract redlining was luminance,

[2987.075 - 2989.535] but they were so early at all the other things

[2989.535 - 2990.935] that we didn't actually end up using them

[2991.035 - 2994.045] and I didn't need a contract red liner at that point in time

[2994.045 - 2995.205] and it wasn't up to speed.

[2995.675 - 2998.085] Like it wasn't as good as the current ones are,

[2998.325 - 2999.685] like Ivo or GC ai.

[3000.225 - 3004.725] Um, but like the large legacy CLM solutions I have found

[3004.825 - 3005.885] to be very weak.

[3006.035 - 3008.325] Like you can, it almost seems like they're just bolting on

[3008.505 - 3010.805] AI so that they can market themselves as AI companies.

[3011.465 - 3013.885] Um, ironclad link squares these people

[3013.985 - 3015.325] and the redline tools aren't good.

[3015.985 - 3017.845] If I was them, I would just acquire one

[3017.845 - 3019.645] of these startups honestly and integrate it.

[3019.985 - 3022.975] Um, but uh, hope hopefully they get there

[3022.975 - 3024.975] because it'd certainly be easier to just have a one-stop

[3024.975 - 3026.855] shop where like all your contracts are

[3026.925 - 3028.165] negotiated and redlined.

[3028.645 - 3031.045] I just haven't found the tools nearly as good

[3031.425 - 3033.165] as the third party products currently are.

[3033.835 - 3037.165] Yeah, we don't dabble much in either of those areas.

[3037.465 - 3040.445] We haven't found, we, we don't,

[3040.445 - 3042.885] we're not scaled in certain areas sufficiently

[3042.885 - 3044.525] to I think need CLM

[3044.525 - 3046.565] and those areas, which it would be super helpful.

[3046.785 - 3050.005] It would be probably better for us to just find a way

[3050.005 - 3053.405] to build the tool or hire contractors to do that for us.

[3053.465 - 3056.605] So we're not in CLM redlining software.

[3056.715 - 3059.645] I've experimented with, it has been eight or so months,

[3059.705 - 3063.165] but when I was sort of dipping my toes in the water there,

[3063.245 - 3065.245] I wasn't very impressed at what I saw.

[3065.765 - 3066.805] I found that I had to,

[3067.145 - 3071.605] at a very granular level review the agreements anyway in a

[3071.605 - 3074.565] way that it didn't really reduce the time

[3074.565 - 3075.645] spent per contract.

[3075.745 - 3078.045] I'm sure that is not always the case for everybody

[3078.045 - 3080.445] and I'm sure the tools have gotten better, so I'll I'll need

[3080.445 - 3082.725] to reevaluate that likely soon.

**[Speaker 2]**

[3084.245 - 3085.695] Yeah, it's an interesting space

[3085.715 - 3089.455] for sure when every product has its own ai, right?

[3089.685 - 3093.095] Like, and also then there's the AI products

[3093.095 - 3095.295] that also are dedicated to that space

[3095.435 - 3098.935] and like trying to navigate through like who, who wins

[3098.935 - 3100.135] that sort of arms race

[3100.155 - 3103.015] and who's giving the best output is gonna be something

[3103.015 - 3104.975] that I think we navigate over the next few years.

[3105.575 - 3109.015] Absolutely. Uh, we got something that's very,

[3109.125 - 3112.095] very highly upvoted, so I have to ask it.

[3112.475 - 3115.815] Do the GCI users find much difference between using

[3115.815 - 3118.815] that platform or just a paid GPT?

[3119.195 - 3121.455] Um, I think we covered a lot of this

[3121.475 - 3123.495] and what's very unique about GPT

[3123.595 - 3127.535] and that it's, it's, you know, giving in, uh, GCI rather in

[3127.535 - 3132.015] that it's giving you, um, prompt, you know, recommendations

[3132.155 - 3135.175] and that it does have like, that we're built on for redline.

[3135.175 - 3137.135] So it sounds like there's a bit of uniqueness there,

[3137.235 - 3139.415] but it was uploaded highly.

[3139.895 - 3142.615] Anything else to overlay on why you might pick a tool

[3142.645 - 3146.415] that is tailor, uh, purpose built for, for legal?

**[Speaker 3]**

[3147.925 - 3150.745] Uh, GC AI is kind of just awesome.

[3151.405 - 3154.905] So the precision and the responses is very impressive.

[3155.385 - 3158.785] Cecilia sort of demoed it to me herself

[3159.085 - 3162.825] and she was explaining to me that the types of, uh,

[3162.855 - 3166.385] like quotes and end quotes even like have to be specific

[3166.445 - 3168.745] or they consider that a miss in their internal testing.

[3169.445 - 3171.465] It also, I'm, I'm speaking

[3171.465 - 3173.065] to the one tool I use the most obviously,

[3173.065 - 3175.865] but it also knows which parts of which prompt to send

[3175.885 - 3179.705] to which underlying models, which is hugely helpful,

[3179.745 - 3184.505] particularly if you're less tech savvy such

[3184.505 - 3187.705] as myself, where I'm, I'm not breaking apart tasks,

[3187.705 - 3190.065] sending them to different machines

[3190.065 - 3191.505] and then aggregating that at the end.

[3191.525 - 3195.265] So it's, it's really, it's a nice one stop shop if you can't

[3195.265 - 3198.025] be bothered to get too much into the AI weeds.

**[Speaker 2]**

[3198.325 - 3199.425] Oh, that's impressive.

[3199.425 - 3201.705] Yeah, and, and for folks who may not know,

[3201.705 - 3205.325] like some certain like AI models are better than others,

[3205.395 - 3208.005] like say at tests or doing contracts, right?

[3208.075 - 3211.405] Like, and so I I, if GCAI is doing

[3211.405 - 3213.565] that all in the background kind of automatically,

[3213.595 - 3216.245] like I think that that is a pretty good value add.

[3216.745 - 3219.165] Wow, that is, that is something I did not know.

[3219.165 - 3221.205] Thank you Jason. All right, I think we're down

[3221.205 - 3223.725] to like the last one or two.

[3224.625 - 3227.535] Um, Alex, uh,

[3228.965 - 3233.625] can you talk us through, um, the like, uh,

[3235.185 - 3237.405] AI replicating legal tasks.

[3237.585 - 3239.965] So how do you think about the future

[3240.105 - 3243.725] of in-house legal work given the increased sophistication

[3243.865 - 3245.645] of legal AI tools, for example,

[3245.755 - 3247.725] what do you see it looking like in one year,

[3247.865 - 3248.885] two years, three years?

**[Speaker 3]**

[3249.715 - 3254.165] Yeah, so I am an ai, uh, optimist.

[3254.505 - 3255.885] You haven't already been able to tell.

[3256.055 - 3258.645] There are, there are the doomers that think it's gonna like

[3259.265 - 3261.005] end all legal practice or whatnot.

[3261.725 - 3264.885] I think it's just gonna really augment our legal practice

[3264.885 - 3266.885] and make us hopefully make our lives better.

[3267.425 - 3271.615] Um, but more likely just make us be able to be

[3272.325 - 3273.335] more efficient, quicker

[3273.915 - 3276.375] and with cheaper services, especially in-house

[3276.375 - 3277.895] that since we're not billing that helps.

[3278.755 - 3282.045] Um, with that being said, like

[3282.645 - 3285.845] G PT five has been on the back burner for a while now

[3286.345 - 3288.605] and the rumors are that like, when that comes out,

[3289.385 - 3292.325] it could like wipe the slight clean of a ton

[3292.325 - 3294.565] of these startups that have started over the last 12

[3294.625 - 3297.615] to 18 months because it could be

[3297.635 - 3300.895] so good at knowing user intent that like,

[3301.155 - 3302.855] you don't remotely have to be good at prompting.

[3302.855 - 3306.295] You don't need any of these hacks or tweaks or models.

[3306.395 - 3308.295] It might just be so good at doing that right off the bat

[3308.295 - 3310.815] that it knows this is a lawyer asking me a

[3310.895 - 3311.975] question, I should act as a lawyer.

[3312.095 - 3313.415] I need to, you know,

[3313.645 - 3315.935] keep all this con information confidential.

[3315.935 - 3318.175] That stuff, who knows what that actually looks like,

[3318.195 - 3320.215] but rumors are that that's the case.

[3320.235 - 3322.775] So yeah, a year from now it could totally revolutionize it,

[3322.995 - 3325.935] but I think like a quick, an even if that doesn't happen,

[3326.095 - 3329.015] a quick anecdote using like existing technology,

[3329.685 - 3333.935] it's like we two months ago faced, um, you know,

[3333.935 - 3336.935] like a pretty regular claim from a departing of employee

[3337.805 - 3341.695] that, uh, was like workplace discrimination type stuff

[3341.695 - 3343.935] basically to keep it as general as possible.

[3344.635 - 3347.815] And it was going through the EEOC resolution process

[3348.635 - 3350.455] and as part of that, we would've typically

[3350.455 - 3351.695] before had like, you know,

[3351.695 - 3354.655] either either leveraged panel counsel provided by an insure

[3354.995 - 3356.335] or just regular outside counsel

[3356.565 - 3359.055] because I'm certainly not like an employment law expert,

[3360.255 - 3363.675] but like using a workflow process, mixing some

[3363.675 - 3366.435] of these different models, uh, allowed me

[3366.455 - 3369.075] to essentially like entirely redraft

[3369.075 - 3373.035] and draft a, a very, very good responsive brief to the EOC

[3373.795 - 3376.735] in three hours, which like I had calculated would probably

[3376.735 - 3380.655] have taken one, one worth before.

[3383.155 - 3386.525] Like I went to perplexity deep research function

[3386.525 - 3388.685] and had it like drum up all the law in Texas

[3388.865 - 3391.645] for this specific claim and I quickly site checked it

[3391.645 - 3394.165] and it was accurate and then I like exported that

[3394.505 - 3397.965] as like a PDF and uploaded that to, uh, white Shoe

[3397.985 - 3399.245] and also chat GPT

[3399.245 - 3402.525] and had like two drafts of a brief telling it to like act

[3402.525 - 3405.805] as an employment law attorney in this area of law, law and o

[3405.805 - 3408.885] and like telling it only to reference this case law so

[3408.885 - 3410.285] that it's not going out making up sites.

[3410.315 - 3413.515] It's like this is the, this is the base of knowledge I have

[3413.515 - 3415.155] to reference in order to craft this brief

[3415.735 - 3417.915] and then told it to like, you know, use Iraq

[3418.015 - 3419.595] and structure it like that.

[3419.945 - 3422.635] Essentially within three hours I had like a pretty

[3422.635 - 3425.865] incredible brief that would've taken a week to a week

[3425.865 - 3428.505] and a half and probably thousands of dollars of

[3428.505 - 3429.545] outside counsel spent.

[3430.385 - 3432.965] Um, so like that is currently possible

[3433.025 - 3434.325] and these tools are only gonna get better.

[3435.265 - 3436.745] I think that's good news for lawyers.

**[Speaker 2]**

[3437.715 - 3439.365] That is so impressive.

[3439.705 - 3440.765] Um, I wanna say

[3440.765 - 3443.965] that this conversation today has made it abundantly clear

[3444.075 - 3445.845] that these tools are here to stay.

[3446.425 - 3448.965] Uh, prompting is no longer a niche skill.

[3449.625 - 3452.925] All of these, uh, you know, concept tools, um,

[3452.925 - 3454.645] skills are becoming table stakes.

[3454.745 - 3458.205] And so I wanna give a huge thank you to Alex

[3458.425 - 3460.885] and Jason for giving us their expertise.

[3460.885 - 3463.165] There's a lot of takeaways for everyone to have.

[3463.585 - 3465.685] We hope you're leaving, feeling inspired

[3465.985 - 3468.445] and maybe you'll even try out a few new prompts.

[3468.735 - 3469.735] Thank you everybody.

**[Speaker 1]**

[3470.995 - 3474.615] Thanks Tommy, Jason, and Alex for, um, sharing your time

[3474.615 - 3476.095] and your expertise with our group today

[3476.355 - 3479.175] and, uh, to launch rates for making this event possible.

[3479.175 - 3481.255] Alright, with that everyone, thanks so much for joining

[3481.435 - 3482.615] and we hope to see you next time.
