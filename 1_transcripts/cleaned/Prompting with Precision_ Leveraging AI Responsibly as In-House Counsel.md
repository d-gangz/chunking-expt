# Prompting with Precision: Leveraging AI Responsibly as In-House Counsel

**Total Duration:** 58:02

**Number of Segments:** 1266

**Speakers:** 3


---


**[Speaker 1]**


[00:04 - 00:05] Welcome everybody.

[00:05 - 00:07] Um, my name is Heather Wallinger,

[00:07 - 00:08] event host here at the L Suite.

[00:08 - 00:11] Our panel today will focus on prompting

[00:11 - 00:13] with precision leveraging AI

[00:13 - 00:14] responsibly as in-house counsel.

[00:15 - 00:17] We have a really great set of speakers for here today.

[00:17 - 00:20] I'm pleased to welcome Tommy Tavares Ferrera,

[00:20 - 00:22] chief Strategy Officer at Law Trades.

[00:23 - 00:24] We have, we have Jason Satoma,

[00:24 - 00:27] general Counsel at Tiffin Ag in Access,

[00:27 - 00:30] and we have Alex Rendells, general counsel at Jasper ai,

[00:31 - 00:33] a really big thank you to our sponsor for today's session,

[00:34 - 00:36] uh, law Trades for making this event possible.

[00:36 - 00:38] So that is it for me, Tommy.

[00:38 - 00:40] I will hand it over to you to get us started.

**[Speaker 2]**


[00:41 - 00:44] Thank you. Hi everybody. I am Tommy Avara Spira.

[00:44 - 00:47] I'm the Chief Strategy Officer at Law Trades,

[00:47 - 00:48] as Heather just said.

[00:48 - 00:51] And for those who haven't worked with us yet, law Trades is,

[00:52 - 00:55] uh, a marketplace for on demand legal talent.

[00:56 - 00:58] We're the go-to partner for companies

[00:58 - 01:01] that need vetted high caliber lawyers, legal ops, pros,

[01:01 - 01:02] contract managers or paralegals.

[01:03 - 01:05] Think of this as the legal team behind your legal team.

[01:06 - 01:08] Later on in today's session, we'll launch a call with a,

[01:08 - 01:10] an offer unique to L Suite members.

[01:10 - 01:12] If you're interested in a free legal operation strategy

[01:12 - 01:15] session, followed by a personalized assessment

[01:15 - 01:17] and roadmap customized to your team,

[01:17 - 01:19] you'll have a chance to opt in.

[01:19 - 01:21] And with that, I'd love to pass it to Jason

[01:21 - 01:22] and Alex to introduce themselves.

**[Speaker 3]**


[01:24 - 01:28] Hi, I'm Jason. I am a general counsel of a collection

[01:28 - 01:31] of software startups, predominantly in FinTech ai.

[01:32 - 01:35] Alex, over to you. Yep. I'm Alex.

[01:36 - 01:39] Uh, I'm the general counsel of Jasper ai.

[01:39 - 01:42] We're a marketing AI company for enterprises.

[01:42 - 01:45] Um, so pretty familiar with developing and deploying AI

[01:45 - 01:47] and then using it personally in our

[01:47 - 01:49] legal workflows in-house as well.

**[Speaker 2]**


[01:50 - 01:51] Excellent. Thank you both.

[01:52 - 01:56] So before we dive in, let me set the stage.

[01:57 - 01:59] AI is moving way faster than a lot

[01:59 - 02:01] of legal teams are comfortable with,

[02:01 - 02:05] and prompting is the tip of that very powerful momentum.

[02:05 - 02:09] Um, if you've ever had a sales team ping legal

[02:09 - 02:12] with a question like, can we just use this vendor's paper,

[02:13 - 02:15] um, without context, without details,

[02:16 - 02:19] or maybe even without a link to that contract, then you know

[02:19 - 02:20] that feeling of

[02:20 - 02:23] what it's like when you don't get a good question,

[02:23 - 02:25] every answer feels wrong.

[02:25 - 02:29] And that's kind of what prompting with AI is exactly like,

[02:30 - 02:34] so we wanna get really good at asking the right question

[02:34 - 02:36] and give the right context and details.

[02:37 - 02:40] So now that AI is answering questions at scale,

[02:40 - 02:41] the stakes are really big

[02:42 - 02:44] and that's why today is about

[02:44 - 02:45] how we ask those questions better.

[02:45 - 02:49] So, um, we wanna use these tools, smart and safe.

[02:49 - 02:51] Um, let's get into it.

[02:51 - 02:54] Jason, can you share a case

[02:54 - 02:58] where sharpening a prompt, um, led

[02:58 - 03:00] to a materially better output?

**[Speaker 3]**


[03:02 - 03:05] Yeah, sure. So I guess to preface this,

[03:05 - 03:07] this was early AI days.

[03:08 - 03:09] I was probably using chat GPT

[03:09 - 03:11] and didn't have a ton of practice,

[03:11 - 03:14] but one time I was trying to recall the present consent

[03:14 - 03:16] to future events rules in Delaware.

[03:16 - 03:20] So I asked chat GPT, basically just that

[03:21 - 03:23] the output was predictably awful.

[03:24 - 03:27] Uh, going back I tried to sharpen it up a bit

[03:27 - 03:31] and I asked how many days in advance the prospective action

[03:31 - 03:32] can a board or stockholders'

[03:32 - 03:34] consent to those future actions?

[03:34 - 03:37] I told it to assume Delaware law site to statutes

[03:37 - 03:38] or clarifying case law.

[03:39 - 03:40] It, uh, oh.

[03:40 - 03:43] And I also told it to discuss the full chain

[03:43 - 03:44] of reasoning prior to concluding.

[03:45 - 03:47] 'cause sometimes you can get sharper responses

[03:47 - 03:50] 'cause it's, it's not thinking, it's just reasoning

[03:50 - 03:51] through words in real time.

[03:51 - 03:54] Uh, answer wound up being 60 days in

[03:54 - 03:55] case anyone's interested.

[03:55 - 03:58] And I think the takeaway is that you can get pretty far

[03:58 - 03:59] with even basic context.

[04:00 - 04:04] Also worth mentioning that the cited law was wrong.

[04:04 - 04:06] It gave me a correct quote, but the wrong law.

[04:06 - 04:08] So that just further highlights the need

[04:08 - 04:11] to verify all the odd outputs. And

**[Speaker 2]**


[04:12 - 04:14] Jason, I'll ask a a quick follow up

[04:14 - 04:16] before I go over to Alex.

[04:16 - 04:20] Um, when, when you're in that instance

[04:20 - 04:23] where the citation is wrong, if you don't have expertise,

[04:24 - 04:25] how do, how do you know what's wrong?

**[Speaker 3]**


[04:27 - 04:30] That's somewhat that, that, that's a big problem.

[04:30 - 04:31] If you don't have a bit

[04:31 - 04:35] of a BS meter on the topic in question,

[04:36 - 04:37] you can't really know it's wrong.

[04:37 - 04:41] So you have to view it as sort of a Google something

[04:41 - 04:43] that helps you figure out what you don't know.

[04:43 - 04:44] And if it's important enough

[04:44 - 04:46] or risky enough, you'd then have to

[04:47 - 04:48] escalate it to somebody who does

[04:49 - 04:52] Trust but verify Trust, but verify

**[Speaker 2]**


[04:52 - 04:53] Just to verify.

[04:53 - 04:57] Excellent. And Alex, what criteria are you using to know

[04:57 - 04:59] that a prompt is hitting the mark?

**[Speaker 3]**


[04:59 - 05:01] Yeah, I think the most recent models

[05:01 - 05:06] that have come out from OpenAI, Google philanthropic, um,

[05:06 - 05:09] have become better and better at getting pretty close

[05:09 - 05:11] to a perfect answer.

[05:12 - 05:16] Honestly, like I've found, um, the legal reasoning for most

[05:17 - 05:20] questions I ask are now 85 to 90% accurate.

[05:20 - 05:25] But one thing to be continually conscious of is

[05:25 - 05:27] that if you're asking it to cite sources,

[05:28 - 05:30] it will still at times hallucinate those sources.

[05:30 - 05:32] There's a, there's ways you can improve that,

[05:33 - 05:35] especially if you're using a model from one

[05:35 - 05:38] of the model providers that allows, um,

[05:38 - 05:40] live search grounding using Google

[05:40 - 05:43] or perplexity as like a deep research function.

[05:43 - 05:45] And that gets a little better to the mark in terms

[05:45 - 05:47] of citing accurate sources.

[05:47 - 05:49] You still have to be careful about that,

[05:49 - 05:52] but I still find that it might give you, you know, like

[05:53 - 05:56] accurate elements of breach of contract in Massachusetts

[05:57 - 05:59] and it's, it's dead accurate.

[05:59 - 06:03] And then the sources it cite might not be, um,

[06:03 - 06:05] the best sources to cite or might some might be inaccurate,

[06:06 - 06:07] but that is getting better and better.

**[Speaker 2]**


[06:08 - 06:10] Do you have any sort of methodology to

[06:11 - 06:14] what you do when you do come up with a good prompt

[06:15 - 06:17] and you want to save it or share it?

**[Speaker 3]**


[06:18 - 06:21] Yeah, definitely. So there are plenty of tools

[06:21 - 06:22] that would do this for you nowadays.

[06:22 - 06:25] I'm sure people on the call use them or aware of them.

[06:25 - 06:29] You can also, like, for a long time I just kept a note file

[06:29 - 06:32] with prompts that I would copy and paste into chat GPT.

[06:33 - 06:34] That's pretty good.

[06:35 - 06:36] The framework I think about

[06:36 - 06:40] for creating prompts is entirely stolen from, um, a book

[06:40 - 06:43] that came out last year by Ethan Molik,

[06:43 - 06:47] he's a researcher at, and the book's title co intelligence.

[06:47 - 06:49] Um, and it's pretty short and easy to get your hands on.

[06:49 - 06:51] I think it's less than 200 pages.

[06:51 - 06:54] But one of the things he talks about in terms

[06:54 - 06:56] of crafting good prompts

[06:56 - 06:59] to have the best re responses from AI is

[06:59 - 07:01] to give it first a role to play.

[07:01 - 07:05] So in the legal context, um, having it, telling it to act

[07:05 - 07:07] as an attorney and not just any attorney,

[07:07 - 07:10] but trying to narrow down on the specific expertise

[07:10 - 07:11] you're wanting it to have.

[07:12 - 07:16] Um, and that substantially improves prompts

[07:16 - 07:18] and you can just put that in the beginning of the prompt or,

[07:18 - 07:21] or bury it in the system prompt Once again, there are plenty

[07:21 - 07:24] of tools out there nowadays that will do this for you

[07:24 - 07:25] so you don't have to know what you're doing.

[07:26 - 07:27] Um, but that helps a lot in the get go.

**[Speaker 2]**


[07:28 - 07:31] And before I, I I pivot to Jason a quick follow.

[07:32 - 07:36] Um, it used to be that the order of

[07:36 - 07:38] where you were asking the question was important.

[07:38 - 07:39] For example, if you put it first

[07:39 - 07:40] and then you put context later,

[07:40 - 07:42] or if you put context in the question,

[07:43 - 07:44] do you find there's any magic

[07:44 - 07:47] to whether you're putting the question then loading in the

[07:47 - 07:50] context or not, doesn't matter anymore?

**[Speaker 3]**


[07:51 - 07:53] Um, that's a, that's a great point.

[07:53 - 07:54] I still put it

[07:54 - 07:58] before in chat gt even you, if you have their plus plan,

[07:58 - 08:01] I believe you can create custom GPTs that allow you

[08:01 - 08:03] to bury it in the system prompts so

[08:03 - 08:05] that any question you ask it automatically is

[08:05 - 08:06] incorporating that context.

[08:06 - 08:08] That's helpful. Um,

[08:09 - 08:11] but quite frankly, I think the models are keep,

[08:11 - 08:12] keep getting better and better at this.

[08:12 - 08:14] And you can probably include it anywhere.

[08:14 - 08:17] Uh, you could attach a file, like if you have notes

[08:17 - 08:19] for prompts you want to use in a Word doc,

[08:19 - 08:20] you could just attach that.

[08:21 - 08:24] Um, the, the models themselves are getting very good at

[08:24 - 08:25] understanding user intent.

[08:26 - 08:27] You can have grammatical errors,

[08:27 - 08:30] you can totally misstate the mark on like

[08:30 - 08:32] what even law you're trying to research.

[08:32 - 08:34] And it'll typically do a pretty good job

[08:34 - 08:35] of figuring out what you mean

**[Speaker 2]**


[08:36 - 08:38] Does catch my reads right through my typo.

[08:38 - 08:40] Um, so Jason, what,

[08:40 - 08:43] what tools are you leaning on for prompting,

**[Speaker 3]**


[08:44 - 08:47] I guess, uh, I don't have to think too hard.

[08:47 - 08:49] Thankfully I use GC ai.

[08:49 - 08:51] There's a lot of tools that like it

[08:51 - 08:53] and you ask it what you're thinking,

[08:53 - 08:55] you provide some context, you click the magic,

[08:56 - 08:57] fix my prompt button

[08:57 - 08:59] and it blows it up into this multi-paragraph

[09:00 - 09:01] beautiful wonder prompt.

[09:02 - 09:04] So I don't have to think about it that hard.

[09:04 - 09:07] When I used to, I don't know if this is still the case,

[09:07 - 09:08] but at one point in time,

[09:08 - 09:11] Claude was better at writing like the human,

[09:11 - 09:14] so I would use Claude to create a really good prompt

[09:14 - 09:18] and then I would plug that into chat GPT or another model

[09:18 - 09:20] and go from there with pretty good results.

**[Speaker 2]**


[09:22 - 09:27] Also, I think a pro tip is if you are really not getting

[09:27 - 09:29] outputs that are helpful, and if,

[09:29 - 09:33] and if it keeps missing the mark in the response, um,

[09:34 - 09:39] you can ask, um, for, for whatever tool you're using,

[09:39 - 09:41] can you help me to write a better prompt here?

[09:41 - 09:44] And I think again, like the more context you can add,

[09:44 - 09:47] the better that the, the prompt's going to be, right?

[09:48 - 09:50] Um, but, but as we said, like even even that

[09:51 - 09:54] like relying on the tool to give you that,

[09:54 - 09:55] um, is gonna help you.

[09:56 - 10:00] So Jason, now let's talk about, um,

[10:00 - 10:02] some of the risks, right?

[10:02 - 10:03] Like we're we're talking about prompting,

[10:03 - 10:05] we're talking about giving context, we're talking about

[10:05 - 10:07] how you get better at asking the right question

[10:08 - 10:09] so you get the right outputs,

[10:10 - 10:13] but in reality there are still some risks.

[10:13 - 10:16] And, um, what do you think is most likely

[10:16 - 10:20] to cause something misleading or to cause a risky output?

**[Speaker 3]**


[10:21 - 10:24] Yeah, so there's a couple different answers to that.

[10:24 - 10:27] Some of them are more technical than I'm able to provide

[10:27 - 10:29] and others are more contextual.

[10:29 - 10:31] So I think first off, a lot

[10:31 - 10:33] of people are treating these tools

[10:33 - 10:35] as if they're subject matter experts in

[10:35 - 10:36] areas that they don't understand.

[10:36 - 10:39] And I think that's inherently problematic and dangerous.

[10:40 - 10:41] I feel like a broken record,

[10:41 - 10:44] but I keep going to the, you need to be able, you need

[10:44 - 10:46] to be capable of falsifying the output in order for it

[10:46 - 10:49] to be safe for you to rely on the output

[10:49 - 10:51] with without bringing in other humans.

[10:52 - 10:56] And so I guess you, yeah, that, that's the big one.

[10:56 - 11:00] And then you need to add context and specificity to prompts

[11:01 - 11:03] and you need to specify what your outcome should be,

[11:04 - 11:07] particularly what a lot of people, myself included,

[11:07 - 11:11] occasionally you ask it leading questions such as

[11:12 - 11:14] I think this is the rule, I think this is what happens.

[11:16 - 11:18] Do you agree? And again,

[11:18 - 11:21] because these things aren't really thinking that's,

[11:21 - 11:22] that's a dangerous way to ask a question.

[11:23 - 11:25] I find it helpful to provide a lot of context,

[11:26 - 11:30] but then have the actual executable question be more

[11:30 - 11:32] open-ended to try and avoid influencing the outcome.

[11:33 - 11:35] I'm not sure, did I, did I answer the question?

**[Speaker 2]**


[11:35 - 11:37] Yeah, and, and I'll, I'll add onto

[11:37 - 11:40] that is sometimes when I've been stuck

[11:40 - 11:44] with not loving the outputs, I actually will refresh

[11:44 - 11:45] and start a whole new prompt.

[11:45 - 11:47] Like, 'cause there's something about the memory that helps.

[11:48 - 11:51] And when I do that refresh, sometimes I'll actually start

[11:51 - 11:55] by asking kind of like leading the witness questions, like,

[11:55 - 11:57] Hey, are you familiar with Ontario Canada?

[11:57 - 12:00] And then like, Hey, are you like, are you familiar

[12:00 - 12:01] with the languages that they speak there?

[12:01 - 12:04] And like I I actually start building like, like a world,

[12:04 - 12:07] if you will, and then I get into the, the heart

[12:07 - 12:09] of what I wanna ask.

[12:09 - 12:11] Maybe I wanna ask about restaurants in that town

[12:11 - 12:14] or something, but if I'm really getting frustrated,

[12:14 - 12:17] I might start like world building with it first

[12:17 - 12:20] and then I find it ha it feels like it knows

[12:21 - 12:23] a little bit better 'cause I was leading the witness.

[12:24 - 12:28] Um, Alex, how do you do a critical evaluation of like

[12:28 - 12:31] what, what came out, um, of your prompt?

**[Speaker 3]**


[12:32 - 12:35] Yeah, definitely leading, asking, leading questions is,

[12:36 - 12:37] is tough even if you're using it

[12:37 - 12:39] for personal use cases, not legal.

[12:39 - 12:42] And that's be like the, the system prompts

[12:42 - 12:45] that the model providers use are largely proprietary.

[12:45 - 12:49] But if you, like, if your company is developing AI itself

[12:49 - 12:52] and you go into your, um, your instance

[12:52 - 12:56] of like open AI's playground, you can see

[12:56 - 12:58] how your company's developing prompts

[12:58 - 13:00] and open AI suggests system prompts

[13:00 - 13:04] and they almost always begin with act as a helpful assistant

[13:04 - 13:08] that is friendly and polite and the AI hears that.

[13:08 - 13:10] And when we're just going into chat GBT

[13:10 - 13:12] and asking legal questions, it's really wanting

[13:12 - 13:13] to please us more than anything else.

[13:14 - 13:17] Um, so you have to work your way around that a bit.

[13:17 - 13:19] One of the ways that I do it is force it

[13:19 - 13:21] to show its thinking.

[13:21 - 13:22] So some of the new reasoning models,

[13:23 - 13:25] Gemini 2.5 Pro will do this automatically

[13:25 - 13:28] and it provides a little dropdown box that shows you

[13:28 - 13:30] how the system was thinking itself.

[13:30 - 13:33] But you can also just include in your prompt

[13:33 - 13:36] after you tell it to act like an attorney to, um,

[13:36 - 13:39] write out its reasoning in like Iraq format,

[13:40 - 13:43] like we were taught to do in law school for exams, uh,

[13:43 - 13:46] which seems brutal, but like it gets that immediately.

[13:46 - 13:48] I don't even have to spell out like issue rule analysis,

[13:48 - 13:50] conclusion it know what IRAC is

[13:50 - 13:54] and it'll, it'll structure its response that way

[13:54 - 13:56] and then at least you can go through, you're like,

[13:56 - 13:57] did it catch the question

[13:57 - 13:59] that I was even asking to spot the issue?

[13:59 - 14:01] What rules it actually setting or is it way off the mark?

[14:02 - 14:04] And then from there you can, if it is making mistakes,

[14:04 - 14:06] you can figure out where those mistakes were made

[14:06 - 14:08] and have it then go back

[14:08 - 14:10] and, you know, correct its process there.

[14:11 - 14:15] Um, another easy hack I've found is using models

[14:16 - 14:20] that are fine tuned for coding use cases that seems odd

[14:21 - 14:23] and it might not pro provide the best, um,

[14:24 - 14:26] like written English output itself,

[14:26 - 14:29] but the legal reasoning I found is the strongest not to be.

[14:29 - 14:32] I'm guessing it's because like years ago I read

[14:32 - 14:35] that the highest performers on the LSAT in a bar exam were

[14:35 - 14:37] math majors in college, which seems counterintuitive

[14:38 - 14:40] at first because you would think like English

[14:40 - 14:42] and history majors and philosophy major would be the best,

[14:43 - 14:46] but math is just like pure representational logic.

[14:47 - 14:48] Um, so those people should be able

[14:48 - 14:50] to do logical reasoning in the best

[14:50 - 14:52] and the models kind of bear

[14:52 - 14:54] that out when you're using a math heavy

[14:55 - 14:58] or coding heavy model, it seems to be able to walk through

[14:59 - 15:03] discreet, deductive logical reasoning better than just

[15:03 - 15:04] jumping into chat GBT raw

[15:04 - 15:06] and trying to uh, figure it out from there.

[15:07 - 15:10] Um, but then taking a step back,

[15:10 - 15:14] like Jason mentioned GCA ai, we use GC ai, we also used, uh,

[15:15 - 15:19] um, a tool called White Shoe ai and then we use Ivo AI

[15:20 - 15:22] and all three of those, like for somebody who doesn't want

[15:22 - 15:25] to dig in and learn all of these, uh, annoying

[15:26 - 15:29] geeky nuances, these tools do all that for you.

[15:29 - 15:31] They're selecting, most likely they're selecting the best

[15:31 - 15:34] models for you, um, when to use them and how to prompt them.

[15:34 - 15:36] And it helps a ton. I'll share in the chat

[15:37 - 15:38] those three that we use.

**[Speaker 2]**


[15:38 - 15:41] That's great. And I feel like you touched on this a little

[15:41 - 15:42] bit, but I'll, but I'll ask it anyway

[15:42 - 15:43] 'cause it's one of the questions that we got.

[15:44 - 15:48] Do you find that the, um, the way that you're asking it

[15:48 - 15:50] to take on a persona or,

[15:50 - 15:53] or using logic-based responses, is that

[15:53 - 15:56] how you build confidence, um, in your responses

[15:56 - 15:58] or is there any other methodology?

[15:58 - 16:01] The specific question is like how do you build confidence

[16:01 - 16:03] and certainty in the response?

[16:03 - 16:05] And it sounds like you touched on that a bit,

[16:05 - 16:06] but if you have any, or Jason,

[16:07 - 16:09] if you have any other pro tips on building

[16:09 - 16:10] that confidence in the response?

**[Speaker 3]**


[16:12 - 16:14] I think so going back

[16:14 - 16:16] to Ethan Malik's book co Intelligence, one

[16:16 - 16:18] of the things he says is, um,

[16:19 - 16:21] to begin using AI constantly

[16:22 - 16:24] and you'll, you'll start noticing where it's strong,

[16:24 - 16:26] where it's weak, and that itself will build your confidence.

[16:27 - 16:28] I'm definitely a power user of ai.

[16:28 - 16:32] There's nothing I do now at work that doesn't incorporate

[16:33 - 16:37] ai, um, like literally every single question I'm receiving

[16:37 - 16:38] and responding to, unless it's live on

[16:38 - 16:39] a call like this where I can't.

[16:40 - 16:44] And even even then we use transcribing notes, um, notes

[16:44 - 16:46] through these tools that, you know, we'll do speech

[16:46 - 16:47] to text nowadays, which are pretty good.

[16:48 - 16:50] Um, but the more you use it,

[16:50 - 16:52] I think the more comfortable you'll get.

[16:52 - 16:54] And even if it seems like something that, ah, I don't need

[16:54 - 16:57] to use this, I know this, um, like the back of my hand,

[16:57 - 16:59] it's useful for you to build up the confidence

[16:59 - 17:01] to use the tool so that then when a problem comes along

[17:02 - 17:05] that it's like really well suited for, you can use that.

[17:05 - 17:08] And then just also keep it in mind that these tools,

[17:08 - 17:11] you should treat them as like a junior associate at a law

[17:11 - 17:14] firm or like an entry level or they're pretty good

[17:14 - 17:15] and that they'll give you a lot of good content,

[17:16 - 17:19] but at the end of the day, you're still the actual human

[17:19 - 17:21] and the attorney and you should be checking it.

[17:22 - 17:24] You shouldn't just be outsourcing this to ai.

[17:25 - 17:26] I think those are really good points.

[17:26 - 17:31] And then also I think that generally when I can, I try to

[17:32 - 17:36] use these tools in a narrow scope using really easily

[17:36 - 17:40] falsifiable questions and answers.

[17:40 - 17:43] So I'll, even though citations can be wrong, I make it site,

[17:44 - 17:47] I make it reason and that makes it easier for me to sort

[17:47 - 17:48] of spot check outputs

[17:48 - 17:50] and that that gives me greater confidence.

[17:51 - 17:54] Although of course when something is partially thinking

[17:54 - 17:56] for you, you can, you can never be totally a hundred

[17:56 - 17:57] percent, but it helps.

**[Speaker 2]**


[17:58 - 18:01] And Alex, really quickly to um, to your,

[18:01 - 18:04] to your point about using Ivo GCI

[18:04 - 18:06] and then I think there was a third enterprise tool, one

[18:06 - 18:07] of the questions is,

[18:07 - 18:09] is there a reason why you're

[18:09 - 18:11] utilizing three different tools?

**[Speaker 3]**


[18:12 - 18:13] Yeah, so I just actually responded

[18:13 - 18:15] to someone's question in the chat about

[18:15 - 18:16] what the pricing looks like.

[18:17 - 18:20] Um, GC ai, uh,

[18:20 - 18:24] and Ivo, we both, I have another attorney in house as well,

[18:24 - 18:28] we heavily leveraged those tools for contract redlining.

[18:29 - 18:30] GCAI actually just came out

[18:30 - 18:32] with a word plugin, uh, last week.

[18:32 - 18:34] I think it's still in data and it's, it's really good.

[18:34 - 18:39] And Ivo was the first, uh, contract redlining tool I found

[18:39 - 18:41] that was actually surgical and precise, it's redline

[18:41 - 18:42] and wasn't over lawyering.

[18:43 - 18:45] Um, and both

[18:45 - 18:48] of those tools you can upload you like contract redlining

[18:48 - 18:49] playbooks and that helps a ton.

[18:50 - 18:54] Um, and I had piloted essentially every single legal AI tool

[18:54 - 18:56] on the market and those two were the best

[18:56 - 18:57] for contract redlining.

[18:58 - 19:00] Uh, but they're kind of expensive, especially for a lot,

[19:01 - 19:02] uh, small legal team.

[19:02 - 19:05] Uh, we, we were given pretty generous discounts to both

[19:05 - 19:07] of them for early adopters,

[19:07 - 19:10] but they're still in the orders of five

[19:10 - 19:12] to $10,000 a year I believe.

[19:12 - 19:16] Um, white Shoe is, it came out this year, it's newer,

[19:17 - 19:19] it's kind of taking the cursor for like lawyer,

[19:19 - 19:21] if you've heard of Cursor, it's like a vibe coating startup

[19:22 - 19:24] that's blown up, but it's taking like the cursor

[19:24 - 19:26] for lawyers, uh, business model approach

[19:27 - 19:29] and it is absurdly inexpensive.

[19:29 - 19:30] I honestly dunno how they're making money.

[19:31 - 19:34] It's like the base model's like 20 bucks a month, um,

[19:34 - 19:36] and you can pay for more usage

[19:36 - 19:37] and more tools on top of that.

[19:37 - 19:39] So we honestly leverage that

[19:39 - 19:41] probably more than anything nowadays

[19:41 - 19:42] because of our limited budget.

[19:43 - 19:46] Um, but that's kind of why we mix in those three tools

[19:46 - 19:47] and we'll have 'em work against each other too.

[19:47 - 19:50] This was another point I was gonna make about having

[19:50 - 19:52] confidence in the prompt results.

[19:52 - 19:53] Um, if you're getting,

[19:53 - 19:56] if you like ask a question from one tool white chew

[19:56 - 19:59] or whatever, or just if you're in chat GPT or Anthropic

[20:00 - 20:02] and then you just copy and paste the output

[20:02 - 20:04] and say like, Hey, another AI gave me this

[20:05 - 20:07] argue against it, or does this look right?

[20:08 - 20:10] Uh, it does a pretty good job of of doing that.

[20:10 - 20:12] Um, so that's useful as well.

**[Speaker 2]**


[20:13 - 20:16] That's excellent. So we've taken the audience through

[20:17 - 20:22] prompting, getting them comfortable with maybe how to prompt

[20:22 - 20:25] and I see the chats going up with a ton of resources

[20:25 - 20:27] and there are some takeaways that people will have,

[20:27 - 20:31] but I think also one barrier to entry for folks

[20:31 - 20:35] and one friction point is naturally like not knowing

[20:35 - 20:37] what the best practices or guardrails are.

[20:38 - 20:40] So I think that's something we should pivot to now.

[20:41 - 20:44] Um, Alex, why don't you kick us off with talking us

[20:44 - 20:45] through internal guardrails.

[20:45 - 20:48] It sounds like you all are very comfy

[20:48 - 20:49] over there with these tools.

[20:49 - 20:51] It sounds like you all are

[20:52 - 20:54] probably like utilizing them all day long.

[20:55 - 20:57] How did you get folks comfy with it

[20:57 - 20:59] and what kind of guardrails do you put in?

**[Speaker 3]**


[21:01 - 21:06] Definitely, yeah, so it helps that we are a company run

[21:06 - 21:09] by, um, executives who are super AI focused.

[21:09 - 21:11] I mean, we're an AI company ourselves

[21:11 - 21:14] and a lot of it is they want us to, um,

[21:15 - 21:17] like eat our own product, like what we're selling.

[21:18 - 21:21] And because of that we have like an internal mandate to,

[21:21 - 21:24] for everybody across the organization, if you're an engineer

[21:24 - 21:27] or lawyer finance, to use AI as much as you can basically

[21:27 - 21:29] to increase efficiency, lower costs.

[21:30 - 21:33] Um, so in terms of from executive buy-in, it was,

[21:33 - 21:36] it was mandated so it was easy to get buy-in there.

[21:37 - 21:40] Um, we don't, you might find it ironic,

[21:40 - 21:43] but we don't like have a formal AI use policy.

[21:43 - 21:44] I've seen those floating around.

[21:45 - 21:48] Um, in fact, I find it funny that like, uh, uh,

[21:49 - 21:51] default form one on Westlaw itself,

[21:51 - 21:54] practical law includes Jasper.

[21:54 - 21:55] It's one of the recommended tools.

[21:55 - 21:57] I did not have any, um,

[21:57 - 21:59] input into having that shoved in there.

[21:59 - 22:01] But you know, I think it's good if you're,

[22:01 - 22:03] especially if you're a big organization

[22:03 - 22:07] or one that regularly handles sensitive data like,

[22:07 - 22:09] like FinTech industry or finance industry

[22:09 - 22:12] or biotech to implement some type

[22:12 - 22:13] of internal company policy.

[22:13 - 22:16] But if you're not, um, as long

[22:16 - 22:18] as like there's some like general agreement within the

[22:18 - 22:19] organization that you're going

[22:19 - 22:21] to either have enterprise accounts

[22:21 - 22:23] that have agreements in place not to train

[22:23 - 22:27] the models on your data that you input into it, um,

[22:28 - 22:30] or just in your personal accounts that you have on these,

[22:30 - 22:33] most of those include settings now as long as you're paying

[22:33 - 22:34] for the, but not just on the free models that allow you

[22:34 - 22:35] to go in and talk with that on

[22:35 - 22:39] and off from a legal specific standpoint, one

[22:39 - 22:43] of the guardrails that my team, uh, is a bare minimum is

[22:43 - 22:46] that if we're using a public tool like chat GPT

[22:46 - 22:50] or anthropic to always, um,

[22:50 - 22:54] obs obfuscate the like client or the company information.

[22:54 - 22:57] So use Acme Co instead of Jasper.

[22:58 - 23:00] Uh, the tools like White Shoe

[23:00 - 23:03] and GC AI do this naturally.

[23:03 - 23:06] They like encrypt data in transit at rest

[23:06 - 23:09] and white shoe even like hashes it so

[23:09 - 23:11] that the LILM isn't even seeing like

[23:11 - 23:12] only the user's able to see it.

[23:12 - 23:16] Um, so those types of things get me comfortable that one,

[23:16 - 23:18] you're not sacrificing attorney-client privilege,

[23:18 - 23:21] but then two, like the only person who's ever gonna see the

[23:21 - 23:25] actual company information is, um, is yourself.

**[Speaker 2]**


[23:26 - 23:28] And will you, um, will you explain

[23:28 - 23:32] to the audience why you wouldn't want the the models

[23:32 - 23:33] to train on that data?

**[Speaker 3]**


[23:33 - 23:35] Definitely, yeah. So this,

[23:36 - 23:39] this become is becoming actually more and more of a problem

[23:39 - 23:42] because the big model providers, uh, believe it

[23:42 - 23:45] or not, are running out of quality information to,

[23:45 - 23:47] to train their models on that basically legally

[23:47 - 23:49] or illegally, whatever your stance is on that,

[23:49 - 23:51] scraped the internet of any good written content

[23:51 - 23:53] to train the models from a base case.

[23:53 - 23:56] So they're now beginning to rely on continual user

[23:57 - 24:00] involvement in the models to determine what types

[24:00 - 24:01] of prompts and outputs are good.

[24:02 - 24:04] And then they'll ingest that information.

[24:04 - 24:06] So if you submit a question about Jasper

[24:07 - 24:09] and you're asking it like a bunch of detailed legal

[24:09 - 24:12] and financial data and you don't have the setting turned off

[24:12 - 24:15] or not to train on your models, um,

[24:15 - 24:17] in theory they could be storing

[24:17 - 24:19] that information in some database or table

[24:20 - 24:22] and in a future iteration che GT five

[24:22 - 24:26] or something, it could come out and Jason could then log on

[24:26 - 24:27] and be asking it a question

[24:27 - 24:31] and unintentionally it could output information about Jasper

[24:31 - 24:33] or our finances or anything like that.

[24:34 - 24:36] Uh, which is obviously a pretty big red flag.

**[Speaker 2]**


[24:37 - 24:41] So the, the chat's going wild, talking about, uh, g gca,

[24:41 - 24:44] AI's ability to, um, come up with the prompts.

[24:44 - 24:47] And we're gonna do, uh, a little bit of that sort

[24:47 - 24:48] of in real time.

[24:48 - 24:52] So, um, Jason, do you wanna talk through, uh,

[24:52 - 24:54] a super prompt that you created?

**[Speaker 3]**


[24:55 - 24:57] Oh yeah, sure. So let me share my screen.

[24:58 - 25:01] Uh, super prompt is a bit of a misnomer.

[25:01 - 25:04] I created this in preparation for this panel.

[25:05 - 25:07] I didn't put the most effort into it.

[25:07 - 25:10] So generally speaking, I tried to create a prompt

[25:11 - 25:14] that provides as much generally applicable context

[25:14 - 25:18] as possible, organizes how the response should be laid out,

[25:19 - 25:22] as you can see here, tells it how I want it to think

[25:23 - 25:27] and when applicable tells it how to research.

[25:27 - 25:30] 'cause sometimes there are, sometimes it executes brief

[25:30 - 25:33] searches, but a lot of times with these deeper

[25:33 - 25:35] research projects, that is not what you want.

[25:35 - 25:39] So you, I don't recommend just using this for everything.

[25:39 - 25:42] This is more of just an exercise in thinking how

[25:42 - 25:43] to pull these prompts together.

[25:43 - 25:46] And, uh, I guess furthermore, this is probably more tailored

[25:46 - 25:50] to more basic tools and less deep reasoning models

[25:50 - 25:54] because as I understand it a lot, a lot of models now do

[25:54 - 25:56] some of these steps by themselves.

[25:57 - 26:01] But y this is here, if anyone finds it helpful,

[26:01 - 26:03] and I understand this is

[26:03 - 26:06] or will be soon circulated to both here.

**[Speaker 2]**


[26:08 - 26:09] It it has already been.

[26:09 - 26:14] And I guess staying on the, the topic here, Jason, what,

[26:14 - 26:17] what does auditing look like, um, for you and your team?

[26:18 - 26:20] Do you actually audit what people use for prompts?

[26:20 - 26:21] Do you have a library and,

[26:21 - 26:24] and do you, do you, uh, do you ever look at what,

[26:24 - 26:26] what's being used as prompts?

**[Speaker 3]**


[26:28 - 26:30] Uh, so we don't audit.

[26:30 - 26:33] I think generally as a team, we like to come together

[26:33 - 26:35] and discuss best practices.

[26:35 - 26:37] This works, this doesn't,

[26:37 - 26:39] but our policies are pretty trust based.

[26:39 - 26:44] We do have a usage policy like Alex was mentioning, um,

[26:44 - 26:48] that, but that mostly says if you're using a tool,

[26:48 - 26:51] you shouldn't be using tools that don't go through InfoSec.

[26:51 - 26:54] But if you are, don't give it confidential information.

[26:55 - 26:56] No matter what tool you're using,

[26:56 - 26:57] you are responsible for outcomes.

[26:57 - 27:01] And it's basically just saying treat these vendors like

[27:01 - 27:02] any other vendors.

[27:03 - 27:06] But no, we're not telling people when they're allowed

[27:06 - 27:07] to prompt or how they're allowed to prompt

[27:07 - 27:10] because to me that kind of seems like telling somebody how

[27:10 - 27:11] to think or how to Google

[27:11 - 27:15] or use any other tool that we'd trust them to use.

**[Speaker 2]**


[27:17 - 27:20] And I know we, we haven't talked about agents,

[27:20 - 27:22] but we did get a question in the chat.

[27:23 - 27:26] Um, Jason and, and Alex, please fill in to chime in right

[27:26 - 27:29] after, are either of you creating agents?

**[Speaker 3]**


[27:30 - 27:32] We are, our our company is doing it.

[27:32 - 27:34] Our legal department is, is not.

[27:34 - 27:37] So it's not something that has yet entered my workflow.

[27:38 - 27:40] I it sounds like Alex has a more useful answer.

[27:42 - 27:44] Yeah, I was just gonna say that ironically,

[27:44 - 27:48] two weeks ago we made our first agent for internal,

[27:48 - 27:50] internal, uh, legal use cases.

[27:50 - 27:52] Just we had like a offsite hackathon

[27:52 - 27:54] for our legal team and finance team.

[27:54 - 27:57] And, um, one of the tools

[27:57 - 28:00] or work workflows we used was, uh, through

[28:01 - 28:03] Zapier we created a Zap, which it's like a,

[28:04 - 28:07] Zapier is like a pretty inexpensive automation platform

[28:07 - 28:08] if you're not familiar with it.

[28:08 - 28:10] It's, it's pretty user friendly.

[28:10 - 28:13] You might have to have some technical experience with it,

[28:13 - 28:16] but, uh, it's kind of drag and drop and,

[28:16 - 28:21] and using, um, our Slack API keys that we're able

[28:21 - 28:22] to link, uh, to it

[28:22 - 28:27] and then open AI's models through their API keys and Zapier.

[28:28 - 28:31] We created a kind of a triage chat bot

[28:31 - 28:32] for our deal desk Slack channel.

[28:33 - 28:35] And when new messages come in from the sales team

[28:35 - 28:38] or our customer success team, it'll, you know,

[28:38 - 28:41] reference a knowledge base that we created and uploaded

[28:41 - 28:44] and then accurately route those questions

[28:44 - 28:45] to the right internal stakeholder

[28:45 - 28:47] for approvals or for review.

[28:47 - 28:50] Um, we have not yet allowed it

[28:50 - 28:52] to straight up answer legal questions.

[28:52 - 28:54] I'm not super comfortable with end users being able

[28:54 - 28:56] to receive that without an attorney input.

[28:57 - 29:01] But basic like billing finance questions, it does answer

[29:01 - 29:02] and it's, it's pretty accurate.

[29:02 - 29:05] Um, and one of the things we did to save us time

[29:05 - 29:08] as well is we like downloaded, we used the Slack API

[29:08 - 29:11] and scanned the last year of messages in this channel

[29:12 - 29:14] and directed OpenAI

[29:14 - 29:17] or chat JT to figure out like

[29:17 - 29:19] what the most common questions were,

[29:19 - 29:21] who they were most commonly routed to,

[29:21 - 29:22] what the responses were.

[29:22 - 29:26] So we grounded the, um, chat bot's responses in

[29:26 - 29:28] that knowledge from the last year's context as well.

[29:29 - 29:31] And it's been live now

[29:31 - 29:32] for a couple weeks and it's pretty great.

[29:32 - 29:35] That's the first like agentic use case. We've, we've

**[Speaker 2]**


[29:35 - 29:40] Done, we use a lot of Zaps at, uh, at law trades

[29:40 - 29:41] and they're pretty awesome.

[29:41 - 29:44] But I think, yeah, probably the general consensus is folks

[29:44 - 29:47] wanting a human to stay in the loop on, on questions.

[29:48 - 29:51] Um, we, we got a question about, uh, being comfortable

[29:51 - 29:55] with inputting sensitive client data into, um,

[29:55 - 29:56] enterprise accounts.

[29:56 - 29:58] Say for example, OpenAI, I think we touched on

[29:58 - 30:02] that a little, um, which is about systems

[30:02 - 30:04] that encrypt things, you know, and

[30:04 - 30:07] or anonymizing, like, like for example, Alex,

[30:08 - 30:10] you said making something Acme not your company.

[30:10 - 30:13] Um, are those the best practices for, for not, uh,

[30:13 - 30:16] putting client data into these models? Yeah,

**[Speaker 3]**


[30:16 - 30:21] I think, um, for the general purpose models like open AI

[30:21 - 30:23] and philanthropic, it's, if you're wanting

[30:23 - 30:26] to be extra cautious, you can always just use

[30:26 - 30:27] Acme or something like that.

[30:28 - 30:31] Um, that requires a bit more of a manual lift.

[30:31 - 30:33] It might be slower and inefficient

[30:33 - 30:34] because you're having to do that every time,

[30:34 - 30:36] especially if you're uploading documents to it,

[30:36 - 30:38] you're having to, you know, find

[30:38 - 30:40] and replace any usage of, uh,

[30:40 - 30:42] confidential company information to do that.

[30:43 - 30:46] Um, but yeah, like honestly,

[30:46 - 30:48] the easy answer is you'll probably just want

[30:48 - 30:50] to use a tool like White Shoe

[30:50 - 30:52] or GCI where it allows you to go in

[30:52 - 30:54] and create a company profile

[30:55 - 30:57] or client profiles if you need more than one.

[30:57 - 30:59] And you enter all this information

[30:59 - 31:02] and then the M'S responses throughout the platform

[31:02 - 31:05] automatically incorporate that information

[31:05 - 31:08] and it's encrypted and like remains secure too,

[31:08 - 31:11] which is useful and speeds up processes

[31:11 - 31:13] and makes it more accurate, all that stuff.

[31:13 - 31:15] Yeah, I guess just to add on to that,

[31:16 - 31:18] my view has always been if the,

[31:18 - 31:19] if your team has gotten comfortable

[31:19 - 31:21] that the InfoSec protections are there

[31:22 - 31:24] and you're comfortable that the legal protections are there,

[31:24 - 31:27] then I, I treat these things like any other vendor.

[31:27 - 31:30] There's of course gonna be incremental risk anytime you

[31:30 - 31:32] expand your circle of trust at all.

[31:33 - 31:35] But I, I don't think that these things are

[31:35 - 31:38] that different from any other vendors is my takeaway.

**[Speaker 2]**


[31:38 - 31:41] Okay. So we've been through prompts,

[31:41 - 31:43] we touched on agents very quickly.

[31:43 - 31:44] We talked about guardrails.

[31:45 - 31:48] There are a lot of people trying to discern in the chat,

[31:48 - 31:50] which is the right tool for them.

[31:50 - 31:54] So let's take them through tool selection

[31:55 - 32:00] when it comes to oversight, tool selection,

[32:00 - 32:04] what you do, Jason, like what can you take people

[32:04 - 32:07] through on, on, on human oversight?

[32:07 - 32:10] Um, you know, any advice on like

[32:11 - 32:12] what they can do there?

**[Speaker 3]**


[32:14 - 32:16] Yeah, I'll just regurgitate some

[32:16 - 32:17] of the other things I've said already,

[32:18 - 32:20] but I think you need to have, you need, you want

[32:20 - 32:23] to have a BS meter on the subjects you're asking it about.

[32:23 - 32:26] If you do not, then you should instead be using it to

[32:27 - 32:29] figure out what you don't know

[32:29 - 32:33] and frame a more intelligent question to somebody who does,

[32:33 - 32:35] uh, when you can do that.

[32:35 - 32:38] Or I suppose even if you can, you should try

[32:38 - 32:41] to ask questions that allow you to spot check the outputs

[32:41 - 32:45] as well, and that helps you to falsify responses.

[32:45 - 32:48] But I suppose the, the general point is that

[32:49 - 32:54] our job as AI augmented attorneys is knowing what

[32:54 - 32:56] to ask when and how,

[32:56 - 33:00] and that job itself cannot be yet replicated

[33:01 - 33:02] by ai. So yeah.

**[Speaker 2]**


[33:03 - 33:07] Fantastic. And Alex, um,

[33:08 - 33:11] uh, uh, hopefully like you, you know,

[33:11 - 33:12] you've touched on this a little bit,

[33:12 - 33:15] but do you have any further insight on

[33:15 - 33:19] how you decide which AI platform to do for, for which task?

[33:20 - 33:21] Any, any magic there?

**[Speaker 3]**


[33:22 - 33:27] Yeah, so I would say the default program nowadays we use

[33:27 - 33:30] for contract redlining is Ivo

[33:31 - 33:35] and essentially everything else, it's uh, white,

[33:35 - 33:37] it's been a white shoe ai and that's largely

[33:37 - 33:41] because it just like, one, it's super cost effective, um,

[33:42 - 33:45] but two, it does a lot

[33:45 - 33:47] of this stuff we're talking about on the backend without you

[33:47 - 33:49] having to really like know coding

[33:49 - 33:52] or how to prompt specifically, it'll enhance your prompts.

[33:52 - 33:56] Um, if you go into like their chat bot for instance,

[33:56 - 33:58] you can, there's a dropdown of like the

[33:59 - 34:01] practice area you want it to be an expert in.

[34:01 - 34:03] So I know if I'm asking it about a term sheet

[34:03 - 34:05] for some financing, I can go in

[34:05 - 34:08] and select the, just like a law firm, the emerging companies

[34:08 - 34:09] and venture capital practice group.

[34:09 - 34:11] And it's actually like adjusted

[34:11 - 34:12] and it's a fine tuned model for that.

[34:12 - 34:15] And that's like substantially better responses than if I

[34:15 - 34:18] just go into chat GPT and ask a question.

[34:18 - 34:19] Um, so there's a bit of that.

[34:20 - 34:23] And then I think internally, just like budget wise,

[34:23 - 34:27] we're super cost conscious, so we don't want tool creep,

[34:27 - 34:28] we don't want a ton of tools that do the same thing.

[34:29 - 34:31] Um, quite frankly, by the end of this year,

[34:31 - 34:34] we're probably gonna churn from either GCI or Ivo

[34:34 - 34:36] because they're both starting to cross paths

[34:36 - 34:39] and like do the same thing as the, as each other

[34:39 - 34:42] and we're just gonna have to determine which one's the best

[34:42 - 34:44] at doing it and save eight grand a year or whatever.

**[Speaker 2]**


[34:45 - 34:48] Interesting question. Um, does anyone have

[34:50 - 34:52] walled off instances by department?

[34:53 - 34:57] For example, HR or legal or any other department?

[34:57 - 34:58] I've never heard of that, but that's

[34:58 - 34:59] an interesting question we got.

**[Speaker 3]**


[35:00 - 35:03] I think I'd probably have to ask a follow-up question

[35:03 - 35:05] to ever asked it by what they mean by walled off.

[35:05 - 35:08] If it's like a private instance of a, you know,

[35:09 - 35:12] cloud hosted model just on your internal workspace at your

[35:12 - 35:15] company that only certain lawyers

[35:15 - 35:16] or finance people can access.

[35:17 - 35:20] If that's the question, we certainly don't, that would be

[35:20 - 35:23] really expensive, difficult to implement.

[35:23 - 35:26] But with that being said, I'm sure there are

[35:27 - 35:28] large legal departments

[35:28 - 35:30] and really sophisticated companies,

[35:30 - 35:32] probably Fortune 20 companies

[35:32 - 35:34] that prioritize that type of use case.

[35:34 - 35:37] For most of us on this call though, it's probably

[35:38 - 35:40] too cumbersome to implement something like that.

[35:41 - 35:44] And tool selection itself probably helps with that.

[35:44 - 35:46] Like Jasper is a marketing AI tool

[35:46 - 35:48] and like as much as I'd love to say it's great

[35:48 - 35:50] for lawyers, it it's horrible.

[35:50 - 35:52] Um, so like I don't ever use our own product,

[35:52 - 35:54] but like our marketing team uses it like crazy

[35:55 - 35:57] and like similarly they're not gonna ever use

[35:58 - 35:59] GC AI or White Shoe.

[35:59 - 36:02] It's like that kind of helps wall it off itself,

[36:02 - 36:05] but they're certainly not like privately hosted models

[36:05 - 36:08] that only Jasper has access to.

[36:09 - 36:13] Yeah. Uh, I'm likely speaking well over my skis here,

[36:13 - 36:17] but I think the only tool that most

[36:17 - 36:20] of my company has access to is chat GPT

[36:20 - 36:24] and I, I believe that that is relatively segregated by

[36:25 - 36:26] specific individual account,

[36:26 - 36:29] but if if that's not the case, then I'm just wrong.

[36:29 - 36:31] So there's that.

**[Speaker 2]**


[36:32 - 36:35] So I am going to bring us, um,

[36:36 - 36:38] to perhaps like the most exciting part.

[36:39 - 36:43] Uh, let's talk about how utilizing AI

[36:44 - 36:46] can actually save us time.

[36:47 - 36:49] Um, does anyone, uh, uh, actually,

[36:49 - 36:51] sorry Alex, let's start with you.

[36:52 - 36:55] Can you talk about how much time you're spending

[36:55 - 36:58] and saving by utilizing these tools

[36:58 - 37:02] and uh, have you been able to not outsource to someone

[37:03 - 37:05] and you can say you have tangible numbers.

**[Speaker 3]**


[37:06 - 37:10] Yeah, definitely. So I joined Jasper three years ago, um,

[37:11 - 37:15] before chat GBT became publicly available, uh, which

[37:15 - 37:18] partially obliterated our downmarket business at

[37:18 - 37:20] Jasper, but that's okay.

[37:20 - 37:23] Um, we pivoted, but before then,

[37:23 - 37:26] and probably for the six months thereafter, chat, GBT

[37:26 - 37:30] and the generally available tools were pretty horrendous

[37:30 - 37:31] at doing legal work.

[37:31 - 37:33] Like I think whenever they test him on the bar,

[37:33 - 37:36] they were hardly passing or like not passing.

[37:37 - 37:40] Since then, like over the last 18 months to 24 months,

[37:41 - 37:43] the general tools have become super useful

[37:43 - 37:46] and then there's all these legal AI startups

[37:46 - 37:47] that have spr it up with specific tools.

[37:48 - 37:50] And beginning about two years ago we started like heavily

[37:50 - 37:53] implementing, um, tool usage

[37:53 - 37:56] for AI within our legal department.

[37:56 - 37:59] And over that two year period, our

[37:59 - 38:02] outside counsel spend has decreased 93%.

[38:03 - 38:06] So we we're saving like $200,000 a year.

[38:07 - 38:09] And that our outside council firms probably aren't real,

[38:09 - 38:12] but like we go to AI as like a

[38:12 - 38:14] what you would treat like a junior

[38:14 - 38:15] or even mid-level associate.

[38:15 - 38:18] Some of these firms, which it blows my mind nowadays when

[38:18 - 38:20] you get bills for junior associates

[38:20 - 38:21] that are seven 50 bucks an hour.

[38:22 - 38:25] Um, so like we, we use that largely

[38:25 - 38:27] for like high stake stuff, obviously,

[38:27 - 38:29] like if it's a financing

[38:29 - 38:31] or an acquisition, we're still gonna use

[38:31 - 38:32] like real outside firms.

[38:32 - 38:34] But for the day-to-day stuff that most

[38:34 - 38:38] of us like at L Suite in-house departments, um, we just need

[38:38 - 38:40] to like expand our reach and speed as quickly

[38:40 - 38:42] and as cheaply as possible.

[38:42 - 38:46] And AI has in my mind, revolutionized the practice of law

[38:46 - 38:47] by being able to do that.

[38:48 - 38:50] So yeah, we've saved 92% over two years.

[38:50 - 38:52] And then in terms of like time saved,

[38:52 - 38:54] I'm sure I could like get, get an accurate

[38:54 - 38:57] or close to accurate hours per week saved.

[38:58 - 39:00] But I think the better metric is that

[39:01 - 39:05] given our like legal intake volume,

[39:05 - 39:06] our sales contract review volume

[39:06 - 39:09] and all that, we should be ending this year

[39:09 - 39:11] with five or six attorneys.

[39:11 - 39:14] We should currently have four, we only have two

[39:14 - 39:16] and we're not like crazy overworked

[39:16 - 39:17] or not more than anyone else

[39:17 - 39:19] and we don't plan on adding head

[39:19 - 39:20] count by the end of the year.

[39:20 - 39:22] So if you take that for what it's worth,

[39:22 - 39:24] it's like essentially one lawyer is doing the work

[39:24 - 39:26] of three by using AI Now

**[Speaker 2]**


[39:26 - 39:30] That, that is like quite a win.

[39:31 - 39:32] Uh, Jason, how about you?

**[Speaker 3]**


[39:34 - 39:37] I don't have, uh, specific figures like Alex does,

[39:37 - 39:39] but I suppose more anecdotally,

[39:40 - 39:43] I recently maybe two months ago closed an m

[39:43 - 39:46] and a transaction just by myself using AI tools

[39:47 - 39:49] opposite a full Kirkland and Alice bench.

[39:49 - 39:53] So that is not something I could do unassisted by ai.

[39:53 - 39:56] I probably saved, it wasn't the biggest transaction,

[39:56 - 39:59] it might have cost $30,000 through big law

[39:59 - 40:03] or $15,000 through medium law service providers,

[40:03 - 40:05] but it's really nice to be able

[40:05 - 40:07] to just internalize things like that.

[40:09 - 40:10] AI assisted,

**[Speaker 2]**


[40:11 - 40:13] No, I think, I think you're not

[40:13 - 40:14] giving yourself enough credit.

[40:14 - 40:15] That's really impressive.

[40:16 - 40:17] I mean, if we got to a world

[40:17 - 40:21] where this could assist in lobbing off like huge m

[40:21 - 40:24] and a expenses, because obviously law firms have been using

[40:24 - 40:25] this sort of tooling for a really long

[40:25 - 40:26] time to do this, right?

[40:27 - 40:31] Um, and so if we're able to do that in-house, um,

[40:31 - 40:33] a little bit more independently,

[40:33 - 40:34] that's really very impressive.

[40:35 - 40:39] There's, there's some, uh, excitement in the chat. Okay.

[40:40 - 40:43] Um, before we close Jason,

[40:44 - 40:46] what is one piece of advice you would give someone

[40:47 - 40:51] who just started looking at these tools, prompting, um,

[40:52 - 40:55] getting comfortable, wants to give their team,

[40:55 - 40:57] you know, a speech about it.

[40:57 - 40:59] What kind of advice do you wanna give to someone?

**[Speaker 3]**


[41:00 - 41:02] Uh, pick your tools wisely.

[41:03 - 41:05] I'm definitely, I'm probably not the best at that,

[41:05 - 41:08] but I, I like what I have and I'd found success with it.

[41:09 - 41:12] Uh, be smart about how you ask questions.

[41:12 - 41:15] I won't go into the whole spiel I've recycled a few times

[41:15 - 41:17] already, but that is very important.

[41:17 - 41:21] And don't trust outputs. Verify them,

**[Speaker 2]**


[41:23 - 41:24] Trust them, verify.

[41:25 - 41:27] Alex, what about you? What advice would you give somebody?

**[Speaker 3]**


[41:29 - 41:33] Yeah, I'm once again just gonna rip from Ethan Malik's

[41:33 - 41:35] book, which I'd recommend anyone read.

[41:35 - 41:39] It's incredible. But I'd say first like, treat AI

[41:39 - 41:40] as a co intelligence.

[41:40 - 41:42] Um, he projects

[41:42 - 41:46] that like within five years humans will become cyborgs,

[41:46 - 41:48] meaning like we're almost everything we do in work

[41:49 - 41:52] is augmented to some degree by degree an ai.

[41:52 - 41:55] Um, and that's certainly been come the case in my own

[41:56 - 41:58] work life and I found it incredibly useful.

[41:58 - 42:01] So I think treating it as a co co intelligence

[42:01 - 42:03] and just helping you think, even if you like,

[42:03 - 42:06] are most certain, you know, the answer to something like,

[42:06 - 42:08] you know, we all, we all have like implicit biases

[42:09 - 42:11] and having it critique those things to um,

[42:12 - 42:15] like re refine our reasoning is always useful.

[42:16 - 42:20] Um, and then I'd also just be comfortable

[42:20 - 42:23] with like good enough responses from ai.

[42:23 - 42:24] That's probably my second point.

[42:24 - 42:27] It's like, at first I was like, oh, you know,

[42:27 - 42:30] it's not passing the bar at a 99% pass rate,

[42:30 - 42:32] but most lawyers aren't either.

[42:33 - 42:36] Um, most lawyers like I, if I'm hiring someone,

[42:36 - 42:38] I'm happy if they're consistently outputting 80

[42:38 - 42:40] to 85% results.

[42:40 - 42:43] Now I could say human, it's like if the AI's doing that,

[42:43 - 42:46] but for 20 bucks a month it's pretty incredible

[42:46 - 42:49] and like I can improve the other 20% to make it better.

[42:50 - 42:52] And then three, I think like the more

[42:52 - 42:55] that you can ingest kind of like the geeky, nerdy AI stuff

[42:55 - 42:58] through newsletters or videos or whatever, the better.

[42:58 - 43:01] Like, uh, a few weeks ago Sam Altman had like a really

[43:02 - 43:03] interesting interview on a panel he was on.

[43:04 - 43:07] Um, and uh, the interviewer asked him

[43:07 - 43:11] what they've noticed at Open AI about different generations

[43:11 - 43:13] and how they use ai

[43:13 - 43:18] and he commented how like the older generations are using,

[43:18 - 43:21] um, AI as you know, the memes that we used

[43:21 - 43:25] to see 20 years ago from our grandparents asking questions

[43:25 - 43:26] to Google that like didn't make any sense.

[43:27 - 43:28] But like ironically now, like

[43:28 - 43:31] that's actually like a pretty ideal way to use AI

[43:31 - 43:32] for someone who doesn't need it

[43:32 - 43:33] for some specialized use case.

[43:33 - 43:34] It's just like treating like another

[43:34 - 43:36] human asking it questions.

[43:36 - 43:37] They're using it like that.

[43:37 - 43:39] The people who are like, you know, in the market

[43:40 - 43:43] and have integrated this into their work over the last two

[43:43 - 43:46] years are using it largely how it's intended to be using,

[43:46 - 43:50] asking it to act in a role, trying to verify outputs, having

[43:50 - 43:52] to critique reasoning that that sort

[43:52 - 43:53] of stuff refined writing.

[43:54 - 43:57] Um, but then he found the most interesting was

[43:57 - 43:59] that younger generations, like people in high school

[43:59 - 44:04] and college are using AI as like a new operating system.

[44:04 - 44:06] Like rather than going to their computer

[44:06 - 44:10] or their phone as like their main source of computation

[44:10 - 44:13] and operating system, these people are just starting

[44:13 - 44:14] to use like ai, um,

[44:14 - 44:16] because they've grown up with it, it's intuitive for them.

[44:16 - 44:21] So things like keeping like a eternal thread on chat GBT

[44:21 - 44:24] and having it store to do tasks and calendaring.

[44:24 - 44:26] I'd rather than using like Gmail calendar,

[44:27 - 44:28] they just use this now

[44:28 - 44:31] and they'll ask like every morning, tell me

[44:31 - 44:32] what I need to do today.

[44:32 - 44:34] It's like that type of stuff that most

[44:34 - 44:36] of us wouldn't intuitively think

[44:36 - 44:37] 'cause we're so used to using other tools.

[44:38 - 44:41] Um, and I think staying current on like best AI use cases

[44:41 - 44:44] and whatnot, even if it's sometimes nerdy

[44:44 - 44:46] and even if they get into like the technical jargon,

[44:46 - 44:47] it's still interesting to hear

[44:47 - 44:50] how like the most cutting edge people are starting to use it

[44:50 - 44:51] so that we can try and adapt that

[44:51 - 44:53] for like our legal use cases.

**[Speaker 2]**


[44:54 - 44:56] I have started to ask chat

[44:57 - 44:58] questions that I used to Google.

[44:58 - 45:00] Um, like it, it's become, and

[45:00 - 45:04] and that's actually a big thing now is like SEO optimization

[45:04 - 45:07] inside of the responses that say like,

[45:07 - 45:09] chat will give you a cloud we'll give you.

[45:09 - 45:12] Um, but yeah, that's been my go-to recently

[45:12 - 45:15] and so I've even seen my own, uh, behavior shift.

[45:16 - 45:17] Uh, we, I'm very excited.

[45:17 - 45:20] We have a lot of really, uh, really great questions.

[45:20 - 45:24] Let me ans let me ask one, uh, that just came up Jason.

[45:25 - 45:29] Um, specifically what tool did you use for, for that m

[45:29 - 45:31] and a um, uh, support?

**[Speaker 3]**


[45:31 - 45:34] Yeah, I should have provided some more details.

[45:34 - 45:37] So again, I'm not the expert in which tool to pick.

[45:37 - 45:40] I use GCAI, it helped

[45:40 - 45:42] that I am an m and a attorney by training.

[45:42 - 45:43] I've run lots of deals, so

[45:44 - 45:47] give me most pretty decent tools

[45:47 - 45:49] and I can run with my little robot minions

[45:49 - 45:52] and close deals so that, that may not be the best approach,

[45:52 - 45:54] but it worked very well

[45:54 - 45:56] for me is all I can say from my anecdote.

**[Speaker 2]**


[45:57 - 45:58] Well, and I think you're overlaying it

[45:58 - 46:01] with what's important, which is you had the expertise

[46:01 - 46:04] to be able to see that the outputs like, like

[46:04 - 46:05] that domain expertise.

[46:05 - 46:07] So someone who maybe doesn't have it,

[46:07 - 46:09] that may be like you might have that edge,

[46:09 - 46:12] which is I think extremely fair in a lot of

[46:12 - 46:13] what we've been talking about today.

**[Speaker 3]**


[46:13 - 46:16] Certainly if you don't have the expertise to run

[46:16 - 46:18] a certain kind of transaction

[46:18 - 46:21] or process, AI won't give you that expertise,

[46:21 - 46:24] but if you do, it's a very good resource.

[46:24 - 46:26] That's right. And we've all been saying, yeah.

**[Speaker 2]**


[46:27 - 46:31] So, um, Alex, this, this goes back to something you said,

[46:31 - 46:34] uh, a little bit earlier, like on note taking for example,

[46:35 - 46:38] I think we're all sort of running Zoom AI or granola

[46:38 - 46:42] or some flavor of, of, uh, an automated note taker.

[46:42 - 46:46] Um, when you're utilizing a tool like that, how do both

[46:46 - 46:49] of you get comfortable with preserving privilege

[46:49 - 46:50] and confidentiality?

**[Speaker 3]**


[46:51 - 46:53] Yeah, the easy answer is I don't get comfortable

[46:53 - 46:55] and I haven't, we, we've honestly been trying

[46:55 - 46:58] to restrict the Zoom recording

[46:58 - 47:01] or gran, we use granola internally.

[47:01 - 47:05] Granola currently doesn't have a feature to like auto delete

[47:06 - 47:08] some period, like a retention timeline basically.

[47:08 - 47:11] I wish it did. Um, so we just try

[47:11 - 47:13] to coach our people like not to use

[47:13 - 47:15] that in a board meeting obviously,

[47:15 - 47:19] or like anything even slightly lower stakes than that.

[47:19 - 47:21] Um, but with that being said,

[47:21 - 47:24] it's like we're certainly not taking a restrictive stance

[47:24 - 47:25] saying you can't use this because the fact

[47:25 - 47:28] of the matter is it's, it's saving people tons of time.

[47:28 - 47:32] It's a more accurate note taker than humans certainly are.

[47:32 - 47:35] It allows people to focus on the human being across the

[47:35 - 47:37] screen from them in a meeting rather than

[47:37 - 47:38] focus on taking notes.

[47:38 - 47:42] It's like those things in my mind far outweigh the risks

[47:42 - 47:44] as long as you're like being careful.

[47:44 - 47:47] Like if, you know, we haven't had a data breach,

[47:47 - 47:49] but if I'm on the phone and we're talking about a data

[47:49 - 47:51] breach with my ciso,

[47:51 - 47:54] I'm not gonna have granola recording, uh, the message there.

[47:54 - 47:57] Or if I do, I'm gonna immediately, I'm gonna take the notes,

[47:58 - 48:00] maybe print them out or keep them in some physical form

[48:01 - 48:03] and delete like the transcript of it from the servers.

[48:03 - 48:07] Something like that. Yeah, this is an issue we've discussed,

[48:07 - 48:08] perhaps not at length,

[48:08 - 48:10] but it's, it's come up

[48:10 - 48:13] where there are obvious discovery implications for anything

[48:13 - 48:15] that I'll use.

[48:15 - 48:17] Zoom AI as an example, just automatically saves

[48:17 - 48:21] and emails out to everybody where I master of the universe.

[48:21 - 48:26] I would make it so that you can ask it questions based on

[48:26 - 48:28] what it's sort of stored.

[48:29 - 48:31] You can get the answers and then you use those notes

[48:31 - 48:35] yourself rather than just these AI summarized call

[48:35 - 48:37] transcripts, which are just there forever,

[48:37 - 48:40] but may maybe that'll be a feature one day

[48:40 - 48:41] and maybe it already is and I just

[48:41 - 48:42] haven't figured out how to use it.

[48:42 - 48:44] But that, that's what I would prefer.

**[Speaker 2]**


[48:44 - 48:46] I I'm gonna pivot a little bit to CLMs.

[48:47 - 48:51] So the question is largely around like AI tools

[48:51 - 48:54] and CLMs, um, and it's it

[48:54 - 48:56] and it's, is there, is there an easier way

[48:56 - 48:58] to redline contracts, for example,

[48:59 - 49:03] utilizing like an AI word plugin versus going the full route

[49:03 - 49:05] of A CLM implementation?

[49:06 - 49:09] And this is probably largely an opinion

[49:09 - 49:11] and largely based on the size and scale

[49:11 - 49:12] and scope of your organization,

[49:13 - 49:17] but if either of you find, um, utilizing an AI tool, uh,

[49:17 - 49:21] to be maybe easier than that implementation

[49:21 - 49:22] or any insights there?

**[Speaker 3]**


[49:23 - 49:24] Yeah, I definitely have an opinion

[49:24 - 49:26] and it's not overly positive.

[49:26 - 49:29] Um, so we implemented a CLM solution.

[49:30 - 49:32] The biggest one probably that you guys are all familiar

[49:32 - 49:35] with, um, coming up on two and a half years ago

[49:35 - 49:38] and during that time had like a bake off between

[49:39 - 49:40] three of the best ones.

[49:40 - 49:44] The only one at that time that I found that was good at uh,

[49:44 - 49:46] like contract redlining was luminance,

[49:47 - 49:49] but they were so early at all the other things

[49:49 - 49:50] that we didn't actually end up using them

[49:51 - 49:54] and I didn't need a contract red liner at that point in time

[49:54 - 49:55] and it wasn't up to speed.

[49:55 - 49:58] Like it wasn't as good as the current ones are,

[49:58 - 49:59] like Ivo or GC ai.

[50:00 - 50:04] Um, but like the large legacy CLM solutions I have found

[50:04 - 50:05] to be very weak.

[50:06 - 50:08] Like you can, it almost seems like they're just bolting on

[50:08 - 50:10] AI so that they can market themselves as AI companies.

[50:11 - 50:13] Um, ironclad link squares these people

[50:13 - 50:15] and the redline tools aren't good.

[50:15 - 50:17] If I was them, I would just acquire one

[50:17 - 50:19] of these startups honestly and integrate it.

[50:19 - 50:22] Um, but uh, hope hopefully they get there

[50:22 - 50:24] because it'd certainly be easier to just have a one-stop

[50:24 - 50:26] shop where like all your contracts are

[50:26 - 50:28] negotiated and redlined.

[50:28 - 50:31] I just haven't found the tools nearly as good

[50:31 - 50:33] as the third party products currently are.

[50:33 - 50:37] Yeah, we don't dabble much in either of those areas.

[50:37 - 50:40] We haven't found, we, we don't,

[50:40 - 50:42] we're not scaled in certain areas sufficiently

[50:42 - 50:44] to I think need CLM

[50:44 - 50:46] and those areas, which it would be super helpful.

[50:46 - 50:50] It would be probably better for us to just find a way

[50:50 - 50:53] to build the tool or hire contractors to do that for us.

[50:53 - 50:56] So we're not in CLM redlining software.

[50:56 - 50:59] I've experimented with, it has been eight or so months,

[50:59 - 51:03] but when I was sort of dipping my toes in the water there,

[51:03 - 51:05] I wasn't very impressed at what I saw.

[51:05 - 51:06] I found that I had to,

[51:07 - 51:11] at a very granular level review the agreements anyway in a

[51:11 - 51:14] way that it didn't really reduce the time

[51:14 - 51:15] spent per contract.

[51:15 - 51:18] I'm sure that is not always the case for everybody

[51:18 - 51:20] and I'm sure the tools have gotten better, so I'll I'll need

[51:20 - 51:22] to reevaluate that likely soon.

**[Speaker 2]**


[51:24 - 51:25] Yeah, it's an interesting space

[51:25 - 51:29] for sure when every product has its own ai, right?

[51:29 - 51:33] Like, and also then there's the AI products

[51:33 - 51:35] that also are dedicated to that space

[51:35 - 51:38] and like trying to navigate through like who, who wins

[51:38 - 51:40] that sort of arms race

[51:40 - 51:43] and who's giving the best output is gonna be something

[51:43 - 51:44] that I think we navigate over the next few years.

[51:45 - 51:49] Absolutely. Uh, we got something that's very,

[51:49 - 51:52] very highly upvoted, so I have to ask it.

[51:52 - 51:55] Do the GCI users find much difference between using

[51:55 - 51:58] that platform or just a paid GPT?

[51:59 - 52:01] Um, I think we covered a lot of this

[52:01 - 52:03] and what's very unique about GPT

[52:03 - 52:07] and that it's, it's, you know, giving in, uh, GCI rather in

[52:07 - 52:12] that it's giving you, um, prompt, you know, recommendations

[52:12 - 52:15] and that it does have like, that we're built on for redline.

[52:15 - 52:17] So it sounds like there's a bit of uniqueness there,

[52:17 - 52:19] but it was uploaded highly.

[52:19 - 52:22] Anything else to overlay on why you might pick a tool

[52:22 - 52:26] that is tailor, uh, purpose built for, for legal?

**[Speaker 3]**


[52:27 - 52:30] Uh, GC AI is kind of just awesome.

[52:31 - 52:34] So the precision and the responses is very impressive.

[52:35 - 52:38] Cecilia sort of demoed it to me herself

[52:39 - 52:42] and she was explaining to me that the types of, uh,

[52:42 - 52:46] like quotes and end quotes even like have to be specific

[52:46 - 52:48] or they consider that a miss in their internal testing.

[52:49 - 52:51] It also, I'm, I'm speaking

[52:51 - 52:53] to the one tool I use the most obviously,

[52:53 - 52:55] but it also knows which parts of which prompt to send

[52:55 - 52:59] to which underlying models, which is hugely helpful,

[52:59 - 53:04] particularly if you're less tech savvy such

[53:04 - 53:07] as myself, where I'm, I'm not breaking apart tasks,

[53:07 - 53:10] sending them to different machines

[53:10 - 53:11] and then aggregating that at the end.

[53:11 - 53:15] So it's, it's really, it's a nice one stop shop if you can't

[53:15 - 53:18] be bothered to get too much into the AI weeds.

**[Speaker 2]**


[53:18 - 53:19] Oh, that's impressive.

[53:19 - 53:21] Yeah, and, and for folks who may not know,

[53:21 - 53:25] like some certain like AI models are better than others,

[53:25 - 53:28] like say at tests or doing contracts, right?

[53:28 - 53:31] Like, and so I I, if GCAI is doing

[53:31 - 53:33] that all in the background kind of automatically,

[53:33 - 53:36] like I think that that is a pretty good value add.

[53:36 - 53:39] Wow, that is, that is something I did not know.

[53:39 - 53:41] Thank you Jason. All right, I think we're down

[53:41 - 53:43] to like the last one or two.

[53:44 - 53:47] Um, Alex, uh,

[53:48 - 53:53] can you talk us through, um, the like, uh,

[53:55 - 53:57] AI replicating legal tasks.

[53:57 - 53:59] So how do you think about the future

[54:00 - 54:03] of in-house legal work given the increased sophistication

[54:03 - 54:05] of legal AI tools, for example,

[54:05 - 54:07] what do you see it looking like in one year,

[54:07 - 54:08] two years, three years?

**[Speaker 3]**


[54:09 - 54:14] Yeah, so I am an ai, uh, optimist.

[54:14 - 54:15] You haven't already been able to tell.

[54:16 - 54:18] There are, there are the doomers that think it's gonna like

[54:19 - 54:21] end all legal practice or whatnot.

[54:21 - 54:24] I think it's just gonna really augment our legal practice

[54:24 - 54:26] and make us hopefully make our lives better.

[54:27 - 54:31] Um, but more likely just make us be able to be

[54:32 - 54:33] more efficient, quicker

[54:33 - 54:36] and with cheaper services, especially in-house

[54:36 - 54:37] that since we're not billing that helps.

[54:38 - 54:42] Um, with that being said, like

[54:42 - 54:45] G PT five has been on the back burner for a while now

[54:46 - 54:48] and the rumors are that like, when that comes out,

[54:49 - 54:52] it could like wipe the slight clean of a ton

[54:52 - 54:54] of these startups that have started over the last 12

[54:54 - 54:57] to 18 months because it could be

[54:57 - 55:00] so good at knowing user intent that like,

[55:01 - 55:02] you don't remotely have to be good at prompting.

[55:02 - 55:06] You don't need any of these hacks or tweaks or models.

[55:06 - 55:08] It might just be so good at doing that right off the bat

[55:08 - 55:10] that it knows this is a lawyer asking me a

[55:10 - 55:11] question, I should act as a lawyer.

[55:12 - 55:13] I need to, you know,

[55:13 - 55:15] keep all this con information confidential.

[55:15 - 55:18] That stuff, who knows what that actually looks like,

[55:18 - 55:20] but rumors are that that's the case.

[55:20 - 55:22] So yeah, a year from now it could totally revolutionize it,

[55:22 - 55:25] but I think like a quick, an even if that doesn't happen,

[55:26 - 55:29] a quick anecdote using like existing technology,

[55:29 - 55:33] it's like we two months ago faced, um, you know,

[55:33 - 55:36] like a pretty regular claim from a departing of employee

[55:37 - 55:41] that, uh, was like workplace discrimination type stuff

[55:41 - 55:43] basically to keep it as general as possible.

[55:44 - 55:47] And it was going through the EEOC resolution process

[55:48 - 55:50] and as part of that, we would've typically

[55:50 - 55:51] before had like, you know,

[55:51 - 55:54] either either leveraged panel counsel provided by an insure

[55:54 - 55:56] or just regular outside counsel

[55:56 - 55:59] because I'm certainly not like an employment law expert,

[56:00 - 56:03] but like using a workflow process, mixing some

[56:03 - 56:06] of these different models, uh, allowed me

[56:06 - 56:09] to essentially like entirely redraft

[56:09 - 56:13] and draft a, a very, very good responsive brief to the EOC

[56:13 - 56:16] in three hours, which like I had calculated would probably

[56:16 - 56:20] have taken one, one worth before.

[56:23 - 56:26] Like I went to perplexity deep research function

[56:26 - 56:28] and had it like drum up all the law in Texas

[56:28 - 56:31] for this specific claim and I quickly site checked it

[56:31 - 56:34] and it was accurate and then I like exported that

[56:34 - 56:37] as like a PDF and uploaded that to, uh, white Shoe

[56:37 - 56:39] and also chat GPT

[56:39 - 56:42] and had like two drafts of a brief telling it to like act

[56:42 - 56:45] as an employment law attorney in this area of law, law and o

[56:45 - 56:48] and like telling it only to reference this case law so

[56:48 - 56:50] that it's not going out making up sites.

[56:50 - 56:53] It's like this is the, this is the base of knowledge I have

[56:53 - 56:55] to reference in order to craft this brief

[56:55 - 56:57] and then told it to like, you know, use Iraq

[56:58 - 56:59] and structure it like that.

[56:59 - 57:02] Essentially within three hours I had like a pretty

[57:02 - 57:05] incredible brief that would've taken a week to a week

[57:05 - 57:08] and a half and probably thousands of dollars of

[57:08 - 57:09] outside counsel spent.

[57:10 - 57:12] Um, so like that is currently possible

[57:13 - 57:14] and these tools are only gonna get better.

[57:15 - 57:16] I think that's good news for lawyers.

**[Speaker 2]**


[57:17 - 57:19] That is so impressive.

[57:19 - 57:20] Um, I wanna say

[57:20 - 57:23] that this conversation today has made it abundantly clear

[57:24 - 57:25] that these tools are here to stay.

[57:26 - 57:28] Uh, prompting is no longer a niche skill.

[57:29 - 57:32] All of these, uh, you know, concept tools, um,

[57:32 - 57:34] skills are becoming table stakes.

[57:34 - 57:38] And so I wanna give a huge thank you to Alex

[57:38 - 57:40] and Jason for giving us their expertise.

[57:40 - 57:43] There's a lot of takeaways for everyone to have.

[57:43 - 57:45] We hope you're leaving, feeling inspired

[57:45 - 57:48] and maybe you'll even try out a few new prompts.

[57:48 - 57:49] Thank you everybody.

**[Speaker 1]**


[57:50 - 57:54] Thanks Tommy, Jason, and Alex for, um, sharing your time

[57:54 - 57:56] and your expertise with our group today

[57:56 - 57:59] and, uh, to launch rates for making this event possible.

[57:59 - 58:01] Alright, with that everyone, thanks so much for joining

[58:01 - 58:02] and we hope to see you next time.