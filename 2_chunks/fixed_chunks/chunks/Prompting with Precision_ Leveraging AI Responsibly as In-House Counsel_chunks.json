[
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_1",
    "text": "Welcome everybody. Um, my name is Heather Wallinger, event host here at the L Suite. Our panel today will focus on prompting with precision leveraging AI responsibly as in-house counsel. We have a really great set of speakers for here today. I'm pleased to welcome Tommy Tavares Ferrera, chief Strategy Officer at Law Trades. We have, we have Jason Satoma, general Counsel at Tiffin Ag in Access, and we have Alex Rendells, general counsel at Jasper ai, a really big thank you to our sponsor for today's session, uh, law Trades for making this event possible. So that is it for me, Tommy. I will hand it over to you to get us started. Thank you. Hi everybody. I am Tommy Avara Spira. I'm the Chief Strategy Officer at Law Trades, as Heather just said. And for those who haven't worked with us yet, law Trades is, uh, a marketplace for on demand legal talent. We're the go-to partner for companies that need vetted high caliber lawyers, legal ops, pros, contract managers or paralegals. Think of this as the legal team behind your legal team. Later on in today's session, we'll launch a call with a, an offer unique to L Suite members. If you're interested in a free legal operation strategy session, followed by a personalized assessment and roadmap customized to your team, you'll have a chance to opt in. And with that, I'd love to pass it to Jason and Alex to introduce themselves. Hi, I'm Jason. I am a general counsel of a collection of software startups, predominantly in FinTech ai. Alex, over to you. Yep. I'm Alex. Uh, I'm the general counsel of Jasper ai. We're a marketing AI company for enterprises. Um, so pretty familiar with developing and deploying AI and then using it personally in our legal workflows in-house as well. Excellent. Thank you both. So before we dive in, let me set the stage. AI is moving way faster than a lot of legal teams are comfortable with, and prompting is the tip of that very powerful momentum. Um, if you've ever had a sales team ping legal with a question like, can we just use this vendor's paper, um, without context, without details, or maybe even without a link to that contract, then you know that feeling of what it's like when you don't get a good question, every answer feels wrong. And that's kind of what prompting with AI is exactly like, so we wanna get really good at asking the right question and give the right context and details. So now that AI is answering questions at scale, the stakes are really big and that's why today is about how we ask those questions better. So, um, we wanna use these tools, smart and safe. Um, let's get into it. Jason, can you share a case where sharpening a prompt, um, led to a materially better output? Yeah, sure. So I guess to preface this, this was early AI days. I was probably using chat GPT and didn't have a ton of practice, but one time I was trying to recall the present consent to future events rules in Delaware. So I asked chat GPT, basically just that the output was predictably awful",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 4.715,
    "cue_end": 203.421,
    "chunk_index": 1,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_2",
    "text": ". Yep. I'm Alex. Uh, I'm the general counsel of Jasper ai. We're a marketing AI company for enterprises. Um, so pretty familiar with developing and deploying AI and then using it personally in our legal workflows in-house as well. Excellent. Thank you both. So before we dive in, let me set the stage. AI is moving way faster than a lot of legal teams are comfortable with, and prompting is the tip of that very powerful momentum. Um, if you've ever had a sales team ping legal with a question like, can we just use this vendor's paper, um, without context, without details, or maybe even without a link to that contract, then you know that feeling of what it's like when you don't get a good question, every answer feels wrong. And that's kind of what prompting with AI is exactly like, so we wanna get really good at asking the right question and give the right context and details. So now that AI is answering questions at scale, the stakes are really big and that's why today is about how we ask those questions better. So, um, we wanna use these tools, smart and safe. Um, let's get into it. Jason, can you share a case where sharpening a prompt, um, led to a materially better output? Yeah, sure. So I guess to preface this, this was early AI days. I was probably using chat GPT and didn't have a ton of practice, but one time I was trying to recall the present consent to future events rules in Delaware. So I asked chat GPT, basically just that the output was predictably awful. Uh, going back I tried to sharpen it up a bit and I asked how many days in advance the prospective action can a board or stockholders' consent to those future actions? I told it to assume Delaware law site to statutes or clarifying case law. It, uh, oh. And I also told it to discuss the full chain of reasoning prior to concluding. 'cause sometimes you can get sharper responses 'cause it's, it's not thinking, it's just reasoning through words in real time. Uh, answer wound up being 60 days in case anyone's interested. And I think the takeaway is that you can get pretty far with even basic context. Also worth mentioning that the cited law was wrong. It gave me a correct quote, but the wrong law. So that just further highlights the need to verify all the odd outputs. And Jason, I'll ask a a quick follow up before I go over to Alex. Um, when, when you're in that instance where the citation is wrong, if you don't have expertise, how do, how do you know what's wrong? That's somewhat that, that, that's a big problem. If you don't have a bit of a BS meter on the topic in question, you can't really know it's wrong. So you have to view it as sort of a Google something that helps you figure out what you don't know. And if it's important enough or risky enough, you'd then have to escalate it to somebody who does Trust but verify Trust, but verify Just to verify. Excellent. And Alex, what criteria are you using to know that a prompt is hitting the mark",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 94.243,
    "cue_end": 299.023,
    "chunk_index": 2,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_3",
    "text": ". Uh, going back I tried to sharpen it up a bit and I asked how many days in advance the prospective action can a board or stockholders' consent to those future actions? I told it to assume Delaware law site to statutes or clarifying case law. It, uh, oh. And I also told it to discuss the full chain of reasoning prior to concluding. 'cause sometimes you can get sharper responses 'cause it's, it's not thinking, it's just reasoning through words in real time. Uh, answer wound up being 60 days in case anyone's interested. And I think the takeaway is that you can get pretty far with even basic context. Also worth mentioning that the cited law was wrong. It gave me a correct quote, but the wrong law. So that just further highlights the need to verify all the odd outputs. And Jason, I'll ask a a quick follow up before I go over to Alex. Um, when, when you're in that instance where the citation is wrong, if you don't have expertise, how do, how do you know what's wrong? That's somewhat that, that, that's a big problem. If you don't have a bit of a BS meter on the topic in question, you can't really know it's wrong. So you have to view it as sort of a Google something that helps you figure out what you don't know. And if it's important enough or risky enough, you'd then have to escalate it to somebody who does Trust but verify Trust, but verify Just to verify. Excellent. And Alex, what criteria are you using to know that a prompt is hitting the mark? Yeah, I think the most recent models that have come out from OpenAI, Google philanthropic, um, have become better and better at getting pretty close to a perfect answer. Honestly, like I've found, um, the legal reasoning for most questions I ask are now 85 to 90% accurate. But one thing to be continually conscious of is that if you're asking it to cite sources, it will still at times hallucinate those sources. There's a, there's ways you can improve that, especially if you're using a model from one of the model providers that allows, um, live search grounding using Google or perplexity as like a deep research function. And that gets a little better to the mark in terms of citing accurate sources. You still have to be careful about that, but I still find that it might give you, you know, like accurate elements of breach of contract in Massachusetts and it's, it's dead accurate. And then the sources it cite might not be, um, the best sources to cite or might some might be inaccurate, but that is getting better and better. Do you have any sort of methodology to what you do when you do come up with a good prompt and you want to save it or share it? Yeah, definitely. So there are plenty of tools that would do this for you nowadays. I'm sure people on the call use them or aware of them. You can also, like, for a long time I just kept a note file with prompts that I would copy and paste into chat GPT. That's pretty good",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 203.493,
    "cue_end": 394.299,
    "chunk_index": 3,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_4",
    "text": "? Yeah, I think the most recent models that have come out from OpenAI, Google philanthropic, um, have become better and better at getting pretty close to a perfect answer. Honestly, like I've found, um, the legal reasoning for most questions I ask are now 85 to 90% accurate. But one thing to be continually conscious of is that if you're asking it to cite sources, it will still at times hallucinate those sources. There's a, there's ways you can improve that, especially if you're using a model from one of the model providers that allows, um, live search grounding using Google or perplexity as like a deep research function. And that gets a little better to the mark in terms of citing accurate sources. You still have to be careful about that, but I still find that it might give you, you know, like accurate elements of breach of contract in Massachusetts and it's, it's dead accurate. And then the sources it cite might not be, um, the best sources to cite or might some might be inaccurate, but that is getting better and better. Do you have any sort of methodology to what you do when you do come up with a good prompt and you want to save it or share it? Yeah, definitely. So there are plenty of tools that would do this for you nowadays. I'm sure people on the call use them or aware of them. You can also, like, for a long time I just kept a note file with prompts that I would copy and paste into chat GPT. That's pretty good. The framework I think about for creating prompts is entirely stolen from, um, a book that came out last year by Ethan Molik, he's a researcher at, and the book's title co intelligence. Um, and it's pretty short and easy to get your hands on. I think it's less than 200 pages. But one of the things he talks about in terms of crafting good prompts to have the best re responses from AI is to give it first a role to play. So in the legal context, um, having it, telling it to act as an attorney and not just any attorney, but trying to narrow down on the specific expertise you're wanting it to have. Um, and that substantially improves prompts and you can just put that in the beginning of the prompt or, or bury it in the system prompt Once again, there are plenty of tools out there nowadays that will do this for you so you don't have to know what you're doing. Um, but that helps a lot in the get go. And before I, I I pivot to Jason a quick follow. Um, it used to be that the order of where you were asking the question was important. For example, if you put it first and then you put context later, or if you put context in the question, do you find there's any magic to whether you're putting the question then loading in the context or not, doesn't matter anymore? Um, that's a, that's a great point. I still put it before in chat gt even you, if you have their plus plan, I believe you can create custom GPTs that allow you to bury it in the system prompts so that any question you ask it automatically is incorporating that context. That's helpful",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 299.074,
    "cue_end": 488.312,
    "chunk_index": 4,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_5",
    "text": ". Um, and it's pretty short and easy to get your hands on. I think it's less than 200 pages. But one of the things he talks about in terms of crafting good prompts to have the best re responses from AI is to give it first a role to play. So in the legal context, um, having it, telling it to act as an attorney and not just any attorney, but trying to narrow down on the specific expertise you're wanting it to have. Um, and that substantially improves prompts and you can just put that in the beginning of the prompt or, or bury it in the system prompt Once again, there are plenty of tools out there nowadays that will do this for you so you don't have to know what you're doing. Um, but that helps a lot in the get go. And before I, I I pivot to Jason a quick follow. Um, it used to be that the order of where you were asking the question was important. For example, if you put it first and then you put context later, or if you put context in the question, do you find there's any magic to whether you're putting the question then loading in the context or not, doesn't matter anymore? Um, that's a, that's a great point. I still put it before in chat gt even you, if you have their plus plan, I believe you can create custom GPTs that allow you to bury it in the system prompts so that any question you ask it automatically is incorporating that context. That's helpful. Um, but quite frankly, I think the models are keep, keep getting better and better at this. And you can probably include it anywhere. Uh, you could attach a file, like if you have notes for prompts you want to use in a Word doc, you could just attach that. Um, the, the models themselves are getting very good at understanding user intent. You can have grammatical errors, you can totally misstate the mark on like what even law you're trying to research. And it'll typically do a pretty good job of figuring out what you mean Does catch my reads right through my typo. Um, so Jason, what, what tools are you leaning on for prompting, I guess, uh, I don't have to think too hard. Thankfully I use GC ai. There's a lot of tools that like it and you ask it what you're thinking, you provide some context, you click the magic, fix my prompt button and it blows it up into this multi-paragraph beautiful wonder prompt. So I don't have to think about it that hard. When I used to, I don't know if this is still the case, but at one point in time, Claude was better at writing like the human, so I would use Claude to create a really good prompt and then I would plug that into chat GPT or another model and go from there with pretty good results. Also, I think a pro tip is if you are really not getting outputs that are helpful, and if, and if it keeps missing the mark in the response, um, you can ask, um, for, for whatever tool you're using, can you help me to write a better prompt here? And I think again, like the more context you can add, the better that the, the prompt's going to be, right",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 407.027,
    "cue_end": 587.453,
    "chunk_index": 5,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_6",
    "text": ". Uh, you could attach a file, like if you have notes for prompts you want to use in a Word doc, you could just attach that. Um, the, the models themselves are getting very good at understanding user intent. You can have grammatical errors, you can totally misstate the mark on like what even law you're trying to research. And it'll typically do a pretty good job of figuring out what you mean Does catch my reads right through my typo. Um, so Jason, what, what tools are you leaning on for prompting, I guess, uh, I don't have to think too hard. Thankfully I use GC ai. There's a lot of tools that like it and you ask it what you're thinking, you provide some context, you click the magic, fix my prompt button and it blows it up into this multi-paragraph beautiful wonder prompt. So I don't have to think about it that hard. When I used to, I don't know if this is still the case, but at one point in time, Claude was better at writing like the human, so I would use Claude to create a really good prompt and then I would plug that into chat GPT or another model and go from there with pretty good results. Also, I think a pro tip is if you are really not getting outputs that are helpful, and if, and if it keeps missing the mark in the response, um, you can ask, um, for, for whatever tool you're using, can you help me to write a better prompt here? And I think again, like the more context you can add, the better that the, the prompt's going to be, right? Um, but, but as we said, like even even that like relying on the tool to give you that, um, is gonna help you. So Jason, now let's talk about, um, some of the risks, right? Like we're we're talking about prompting, we're talking about giving context, we're talking about how you get better at asking the right question so you get the right outputs, but in reality there are still some risks. And, um, what do you think is most likely to cause something misleading or to cause a risky output? Yeah, so there's a couple different answers to that. Some of them are more technical than I'm able to provide and others are more contextual. So I think first off, a lot of people are treating these tools as if they're subject matter experts in areas that they don't understand. And I think that's inherently problematic and dangerous. I feel like a broken record, but I keep going to the, you need to be able, you need to be capable of falsifying the output in order for it to be safe for you to rely on the output with without bringing in other humans. And so I guess you, yeah, that, that's the big one. And then you need to add context and specificity to prompts and you need to specify what your outcome should be, particularly what a lot of people, myself included, occasionally you ask it leading questions such as I think this is the rule, I think this is what happens. Do you agree? And again, because these things aren't really thinking that's, that's a dangerous way to ask a question",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 494.48,
    "cue_end": 682.909,
    "chunk_index": 6,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_7",
    "text": "? Um, but, but as we said, like even even that like relying on the tool to give you that, um, is gonna help you. So Jason, now let's talk about, um, some of the risks, right? Like we're we're talking about prompting, we're talking about giving context, we're talking about how you get better at asking the right question so you get the right outputs, but in reality there are still some risks. And, um, what do you think is most likely to cause something misleading or to cause a risky output? Yeah, so there's a couple different answers to that. Some of them are more technical than I'm able to provide and others are more contextual. So I think first off, a lot of people are treating these tools as if they're subject matter experts in areas that they don't understand. And I think that's inherently problematic and dangerous. I feel like a broken record, but I keep going to the, you need to be able, you need to be capable of falsifying the output in order for it to be safe for you to rely on the output with without bringing in other humans. And so I guess you, yeah, that, that's the big one. And then you need to add context and specificity to prompts and you need to specify what your outcome should be, particularly what a lot of people, myself included, occasionally you ask it leading questions such as I think this is the rule, I think this is what happens. Do you agree? And again, because these things aren't really thinking that's, that's a dangerous way to ask a question. I find it helpful to provide a lot of context, but then have the actual executable question be more open-ended to try and avoid influencing the outcome. I'm not sure, did I, did I answer the question? Yeah, and, and I'll, I'll add onto that is sometimes when I've been stuck with not loving the outputs, I actually will refresh and start a whole new prompt. Like, 'cause there's something about the memory that helps. And when I do that refresh, sometimes I'll actually start by asking kind of like leading the witness questions, like, Hey, are you familiar with Ontario Canada? And then like, Hey, are you like, are you familiar with the languages that they speak there? And like I I actually start building like, like a world, if you will, and then I get into the, the heart of what I wanna ask. Maybe I wanna ask about restaurants in that town or something, but if I'm really getting frustrated, I might start like world building with it first and then I find it ha it feels like it knows a little bit better 'cause I was leading the witness. Um, Alex, how do you do a critical evaluation of like what, what came out, um, of your prompt? Yeah, definitely leading, asking, leading questions is, is tough even if you're using it for personal use cases, not legal. And that's be like the, the system prompts that the model providers use are largely proprietary",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 587.509,
    "cue_end": 765.35,
    "chunk_index": 7,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_8",
    "text": ". Do you agree? And again, because these things aren't really thinking that's, that's a dangerous way to ask a question. I find it helpful to provide a lot of context, but then have the actual executable question be more open-ended to try and avoid influencing the outcome. I'm not sure, did I, did I answer the question? Yeah, and, and I'll, I'll add onto that is sometimes when I've been stuck with not loving the outputs, I actually will refresh and start a whole new prompt. Like, 'cause there's something about the memory that helps. And when I do that refresh, sometimes I'll actually start by asking kind of like leading the witness questions, like, Hey, are you familiar with Ontario Canada? And then like, Hey, are you like, are you familiar with the languages that they speak there? And like I I actually start building like, like a world, if you will, and then I get into the, the heart of what I wanna ask. Maybe I wanna ask about restaurants in that town or something, but if I'm really getting frustrated, I might start like world building with it first and then I find it ha it feels like it knows a little bit better 'cause I was leading the witness. Um, Alex, how do you do a critical evaluation of like what, what came out, um, of your prompt? Yeah, definitely leading, asking, leading questions is, is tough even if you're using it for personal use cases, not legal. And that's be like the, the system prompts that the model providers use are largely proprietary. But if you, like, if your company is developing AI itself and you go into your, um, your instance of like open AI's playground, you can see how your company's developing prompts and open AI suggests system prompts and they almost always begin with act as a helpful assistant that is friendly and polite and the AI hears that. And when we're just going into chat GBT and asking legal questions, it's really wanting to please us more than anything else. Um, so you have to work your way around that a bit. One of the ways that I do it is force it to show its thinking. So some of the new reasoning models, Gemini 2.5 Pro will do this automatically and it provides a little dropdown box that shows you how the system was thinking itself. But you can also just include in your prompt after you tell it to act like an attorney to, um, write out its reasoning in like Iraq format, like we were taught to do in law school for exams, uh, which seems brutal, but like it gets that immediately. I don't even have to spell out like issue rule analysis, conclusion it know what IRAC is and it'll, it'll structure its response that way and then at least you can go through, you're like, did it catch the question that I was even asking to spot the issue? What rules it actually setting or is it way off the mark? And then from there you can, if it is making mistakes, you can figure out where those mistakes were made and have it then go back and, you know, correct its process there",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 674.936,
    "cue_end": 850.615,
    "chunk_index": 8,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_9",
    "text": ". But if you, like, if your company is developing AI itself and you go into your, um, your instance of like open AI's playground, you can see how your company's developing prompts and open AI suggests system prompts and they almost always begin with act as a helpful assistant that is friendly and polite and the AI hears that. And when we're just going into chat GBT and asking legal questions, it's really wanting to please us more than anything else. Um, so you have to work your way around that a bit. One of the ways that I do it is force it to show its thinking. So some of the new reasoning models, Gemini 2.5 Pro will do this automatically and it provides a little dropdown box that shows you how the system was thinking itself. But you can also just include in your prompt after you tell it to act like an attorney to, um, write out its reasoning in like Iraq format, like we were taught to do in law school for exams, uh, which seems brutal, but like it gets that immediately. I don't even have to spell out like issue rule analysis, conclusion it know what IRAC is and it'll, it'll structure its response that way and then at least you can go through, you're like, did it catch the question that I was even asking to spot the issue? What rules it actually setting or is it way off the mark? And then from there you can, if it is making mistakes, you can figure out where those mistakes were made and have it then go back and, you know, correct its process there. Um, another easy hack I've found is using models that are fine tuned for coding use cases that seems odd and it might not pro provide the best, um, like written English output itself, but the legal reasoning I found is the strongest not to be. I'm guessing it's because like years ago I read that the highest performers on the LSAT in a bar exam were math majors in college, which seems counterintuitive at first because you would think like English and history majors and philosophy major would be the best, but math is just like pure representational logic. Um, so those people should be able to do logical reasoning in the best and the models kind of bear that out when you're using a math heavy or coding heavy model, it seems to be able to walk through discreet, deductive logical reasoning better than just jumping into chat GBT raw and trying to uh, figure it out from there. Um, but then taking a step back, like Jason mentioned GCA ai, we use GC ai, we also used, uh, um, a tool called White Shoe ai and then we use Ivo AI and all three of those, like for somebody who doesn't want to dig in and learn all of these, uh, annoying geeky nuances, these tools do all that for you. They're selecting, most likely they're selecting the best models for you, um, when to use them and how to prompt them. And it helps a ton. I'll share in the chat those three that we use. That's great. And I feel like you touched on this a little bit, but I'll, but I'll ask it anyway 'cause it's one of the questions that we got",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 765.412,
    "cue_end": 943.925,
    "chunk_index": 9,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_10",
    "text": ". I'm guessing it's because like years ago I read that the highest performers on the LSAT in a bar exam were math majors in college, which seems counterintuitive at first because you would think like English and history majors and philosophy major would be the best, but math is just like pure representational logic. Um, so those people should be able to do logical reasoning in the best and the models kind of bear that out when you're using a math heavy or coding heavy model, it seems to be able to walk through discreet, deductive logical reasoning better than just jumping into chat GBT raw and trying to uh, figure it out from there. Um, but then taking a step back, like Jason mentioned GCA ai, we use GC ai, we also used, uh, um, a tool called White Shoe ai and then we use Ivo AI and all three of those, like for somebody who doesn't want to dig in and learn all of these, uh, annoying geeky nuances, these tools do all that for you. They're selecting, most likely they're selecting the best models for you, um, when to use them and how to prompt them. And it helps a ton. I'll share in the chat those three that we use. That's great. And I feel like you touched on this a little bit, but I'll, but I'll ask it anyway 'cause it's one of the questions that we got. Do you find that the, um, the way that you're asking it to take on a persona or, or using logic-based responses, is that how you build confidence, um, in your responses or is there any other methodology? The specific question is like how do you build confidence and certainty in the response? And it sounds like you touched on that a bit, but if you have any, or Jason, if you have any other pro tips on building that confidence in the response? I think so going back to Ethan Malik's book co Intelligence, one of the things he says is, um, to begin using AI constantly and you'll, you'll start noticing where it's strong, where it's weak, and that itself will build your confidence. I'm definitely a power user of ai. There's nothing I do now at work that doesn't incorporate ai, um, like literally every single question I'm receiving and responding to, unless it's live on a call like this where I can't. And even even then we use transcribing notes, um, notes through these tools that, you know, we'll do speech to text nowadays, which are pretty good. Um, but the more you use it, I think the more comfortable you'll get. And even if it seems like something that, ah, I don't need to use this, I know this, um, like the back of my hand, it's useful for you to build up the confidence to use the tool so that then when a problem comes along that it's like really well suited for, you can use that. And then just also keep it in mind that these tools, you should treat them as like a junior associate at a law firm or like an entry level or they're pretty good and that they'll give you a lot of good content, but at the end of the day, you're still the actual human and the attorney and you should be checking it",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 869.529,
    "cue_end": 1041.529,
    "chunk_index": 10,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_11",
    "text": "? And it sounds like you touched on that a bit, but if you have any, or Jason, if you have any other pro tips on building that confidence in the response? I think so going back to Ethan Malik's book co Intelligence, one of the things he says is, um, to begin using AI constantly and you'll, you'll start noticing where it's strong, where it's weak, and that itself will build your confidence. I'm definitely a power user of ai. There's nothing I do now at work that doesn't incorporate ai, um, like literally every single question I'm receiving and responding to, unless it's live on a call like this where I can't. And even even then we use transcribing notes, um, notes through these tools that, you know, we'll do speech to text nowadays, which are pretty good. Um, but the more you use it, I think the more comfortable you'll get. And even if it seems like something that, ah, I don't need to use this, I know this, um, like the back of my hand, it's useful for you to build up the confidence to use the tool so that then when a problem comes along that it's like really well suited for, you can use that. And then just also keep it in mind that these tools, you should treat them as like a junior associate at a law firm or like an entry level or they're pretty good and that they'll give you a lot of good content, but at the end of the day, you're still the actual human and the attorney and you should be checking it. You shouldn't just be outsourcing this to ai. I think those are really good points. And then also I think that generally when I can, I try to use these tools in a narrow scope using really easily falsifiable questions and answers. So I'll, even though citations can be wrong, I make it site, I make it reason and that makes it easier for me to sort of spot check outputs and that that gives me greater confidence. Although of course when something is partially thinking for you, you can, you can never be totally a hundred percent, but it helps. And Alex, really quickly to um, to your, to your point about using Ivo GCI and then I think there was a third enterprise tool, one of the questions is, is there a reason why you're utilizing three different tools? Yeah, so I just actually responded to someone's question in the chat about what the pricing looks like. Um, GC ai, uh, and Ivo, we both, I have another attorney in house as well, we heavily leveraged those tools for contract redlining. GCAI actually just came out with a word plugin, uh, last week. I think it's still in data and it's, it's really good. And Ivo was the first, uh, contract redlining tool I found that was actually surgical and precise, it's redline and wasn't over lawyering. Um, and both of those tools you can upload you like contract redlining playbooks and that helps a ton. Um, and I had piloted essentially every single legal AI tool on the market and those two were the best for contract redlining. Uh, but they're kind of expensive, especially for a lot, uh, small legal team",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 963.252,
    "cue_end": 1141.964,
    "chunk_index": 11,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_12",
    "text": ". And then also I think that generally when I can, I try to use these tools in a narrow scope using really easily falsifiable questions and answers. So I'll, even though citations can be wrong, I make it site, I make it reason and that makes it easier for me to sort of spot check outputs and that that gives me greater confidence. Although of course when something is partially thinking for you, you can, you can never be totally a hundred percent, but it helps. And Alex, really quickly to um, to your, to your point about using Ivo GCI and then I think there was a third enterprise tool, one of the questions is, is there a reason why you're utilizing three different tools? Yeah, so I just actually responded to someone's question in the chat about what the pricing looks like. Um, GC ai, uh, and Ivo, we both, I have another attorney in house as well, we heavily leveraged those tools for contract redlining. GCAI actually just came out with a word plugin, uh, last week. I think it's still in data and it's, it's really good. And Ivo was the first, uh, contract redlining tool I found that was actually surgical and precise, it's redline and wasn't over lawyering. Um, and both of those tools you can upload you like contract redlining playbooks and that helps a ton. Um, and I had piloted essentially every single legal AI tool on the market and those two were the best for contract redlining. Uh, but they're kind of expensive, especially for a lot, uh, small legal team. Uh, we, we were given pretty generous discounts to both of them for early adopters, but they're still in the orders of five to $10,000 a year I believe. Um, white Shoe is, it came out this year, it's newer, it's kind of taking the cursor for like lawyer, if you've heard of Cursor, it's like a vibe coating startup that's blown up, but it's taking like the cursor for lawyers, uh, business model approach and it is absurdly inexpensive. I honestly dunno how they're making money. It's like the base model's like 20 bucks a month, um, and you can pay for more usage and more tools on top of that. So we honestly leverage that probably more than anything nowadays because of our limited budget. Um, but that's kind of why we mix in those three tools and we'll have 'em work against each other too. This was another point I was gonna make about having confidence in the prompt results. Um, if you're getting, if you like ask a question from one tool white chew or whatever, or just if you're in chat GPT or Anthropic and then you just copy and paste the output and say like, Hey, another AI gave me this argue against it, or does this look right? Uh, it does a pretty good job of of doing that. Um, so that's useful as well. That's excellent",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 1046.427,
    "cue_end": 1214.266,
    "chunk_index": 12,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_13",
    "text": ". Um, and I had piloted essentially every single legal AI tool on the market and those two were the best for contract redlining. Uh, but they're kind of expensive, especially for a lot, uh, small legal team. Uh, we, we were given pretty generous discounts to both of them for early adopters, but they're still in the orders of five to $10,000 a year I believe. Um, white Shoe is, it came out this year, it's newer, it's kind of taking the cursor for like lawyer, if you've heard of Cursor, it's like a vibe coating startup that's blown up, but it's taking like the cursor for lawyers, uh, business model approach and it is absurdly inexpensive. I honestly dunno how they're making money. It's like the base model's like 20 bucks a month, um, and you can pay for more usage and more tools on top of that. So we honestly leverage that probably more than anything nowadays because of our limited budget. Um, but that's kind of why we mix in those three tools and we'll have 'em work against each other too. This was another point I was gonna make about having confidence in the prompt results. Um, if you're getting, if you like ask a question from one tool white chew or whatever, or just if you're in chat GPT or Anthropic and then you just copy and paste the output and say like, Hey, another AI gave me this argue against it, or does this look right? Uh, it does a pretty good job of of doing that. Um, so that's useful as well. That's excellent. So we've taken the audience through prompting, getting them comfortable with maybe how to prompt and I see the chats going up with a ton of resources and there are some takeaways that people will have, but I think also one barrier to entry for folks and one friction point is naturally like not knowing what the best practices or guardrails are. So I think that's something we should pivot to now. Um, Alex, why don't you kick us off with talking us through internal guardrails. It sounds like you all are very comfy over there with these tools. It sounds like you all are probably like utilizing them all day long. How did you get folks comfy with it and what kind of guardrails do you put in? Definitely, yeah, so it helps that we are a company run by, um, executives who are super AI focused. I mean, we're an AI company ourselves and a lot of it is they want us to, um, like eat our own product, like what we're selling. And because of that we have like an internal mandate to, for everybody across the organization, if you're an engineer or lawyer finance, to use AI as much as you can basically to increase efficiency, lower costs. Um, so in terms of from executive buy-in, it was, it was mandated so it was easy to get buy-in there. Um, we don't, you might find it ironic, but we don't like have a formal AI use policy. I've seen those floating around. Um, in fact, I find it funny that like, uh, uh, default form one on Westlaw itself, practical law includes Jasper. It's one of the recommended tools",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 1129.38,
    "cue_end": 1315.519,
    "chunk_index": 13,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_14",
    "text": ". So I think that's something we should pivot to now. Um, Alex, why don't you kick us off with talking us through internal guardrails. It sounds like you all are very comfy over there with these tools. It sounds like you all are probably like utilizing them all day long. How did you get folks comfy with it and what kind of guardrails do you put in? Definitely, yeah, so it helps that we are a company run by, um, executives who are super AI focused. I mean, we're an AI company ourselves and a lot of it is they want us to, um, like eat our own product, like what we're selling. And because of that we have like an internal mandate to, for everybody across the organization, if you're an engineer or lawyer finance, to use AI as much as you can basically to increase efficiency, lower costs. Um, so in terms of from executive buy-in, it was, it was mandated so it was easy to get buy-in there. Um, we don't, you might find it ironic, but we don't like have a formal AI use policy. I've seen those floating around. Um, in fact, I find it funny that like, uh, uh, default form one on Westlaw itself, practical law includes Jasper. It's one of the recommended tools. I did not have any, um, input into having that shoved in there. But you know, I think it's good if you're, especially if you're a big organization or one that regularly handles sensitive data like, like FinTech industry or finance industry or biotech to implement some type of internal company policy. But if you're not, um, as long as like there's some like general agreement within the organization that you're going to either have enterprise accounts that have agreements in place not to train the models on your data that you input into it, um, or just in your personal accounts that you have on these, most of those include settings now as long as you're paying for the, but not just on the free models that allow you to go in and talk with that on and off from a legal specific standpoint, one of the guardrails that my team, uh, is a bare minimum is that if we're using a public tool like chat GPT or anthropic to always, um, obs obfuscate the like client or the company information. So use Acme Co instead of Jasper. Uh, the tools like White Shoe and GC AI do this naturally. They like encrypt data in transit at rest and white shoe even like hashes it so that the LILM isn't even seeing like only the user's able to see it. Um, so those types of things get me comfortable that one, you're not sacrificing attorney-client privilege, but then two, like the only person who's ever gonna see the actual company information is, um, is yourself. And will you, um, will you explain to the audience why you wouldn't want the the models to train on that data? Definitely, yeah",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 1237.641,
    "cue_end": 1414.828,
    "chunk_index": 14,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_15",
    "text": ". But if you're not, um, as long as like there's some like general agreement within the organization that you're going to either have enterprise accounts that have agreements in place not to train the models on your data that you input into it, um, or just in your personal accounts that you have on these, most of those include settings now as long as you're paying for the, but not just on the free models that allow you to go in and talk with that on and off from a legal specific standpoint, one of the guardrails that my team, uh, is a bare minimum is that if we're using a public tool like chat GPT or anthropic to always, um, obs obfuscate the like client or the company information. So use Acme Co instead of Jasper. Uh, the tools like White Shoe and GC AI do this naturally. They like encrypt data in transit at rest and white shoe even like hashes it so that the LILM isn't even seeing like only the user's able to see it. Um, so those types of things get me comfortable that one, you're not sacrificing attorney-client privilege, but then two, like the only person who's ever gonna see the actual company information is, um, is yourself. And will you, um, will you explain to the audience why you wouldn't want the the models to train on that data? Definitely, yeah. So this, this become is becoming actually more and more of a problem because the big model providers, uh, believe it or not, are running out of quality information to, to train their models on that basically legally or illegally, whatever your stance is on that, scraped the internet of any good written content to train the models from a base case. So they're now beginning to rely on continual user involvement in the models to determine what types of prompts and outputs are good. And then they'll ingest that information. So if you submit a question about Jasper and you're asking it like a bunch of detailed legal and financial data and you don't have the setting turned off or not to train on your models, um, in theory they could be storing that information in some database or table and in a future iteration che GT five or something, it could come out and Jason could then log on and be asking it a question and unintentionally it could output information about Jasper or our finances or anything like that. Uh, which is obviously a pretty big red flag. So the, the chat's going wild, talking about, uh, g gca, AI's ability to, um, come up with the prompts. And we're gonna do, uh, a little bit of that sort of in real time. So, um, Jason, do you wanna talk through, uh, a super prompt that you created? Oh yeah, sure. So let me share my screen. Uh, super prompt is a bit of a misnomer. I created this in preparation for this panel. I didn't put the most effort into it",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 1333.306,
    "cue_end": 1506.971,
    "chunk_index": 15,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_16",
    "text": "? Definitely, yeah. So this, this become is becoming actually more and more of a problem because the big model providers, uh, believe it or not, are running out of quality information to, to train their models on that basically legally or illegally, whatever your stance is on that, scraped the internet of any good written content to train the models from a base case. So they're now beginning to rely on continual user involvement in the models to determine what types of prompts and outputs are good. And then they'll ingest that information. So if you submit a question about Jasper and you're asking it like a bunch of detailed legal and financial data and you don't have the setting turned off or not to train on your models, um, in theory they could be storing that information in some database or table and in a future iteration che GT five or something, it could come out and Jason could then log on and be asking it a question and unintentionally it could output information about Jasper or our finances or anything like that. Uh, which is obviously a pretty big red flag. So the, the chat's going wild, talking about, uh, g gca, AI's ability to, um, come up with the prompts. And we're gonna do, uh, a little bit of that sort of in real time. So, um, Jason, do you wanna talk through, uh, a super prompt that you created? Oh yeah, sure. So let me share my screen. Uh, super prompt is a bit of a misnomer. I created this in preparation for this panel. I didn't put the most effort into it. So generally speaking, I tried to create a prompt that provides as much generally applicable context as possible, organizes how the response should be laid out, as you can see here, tells it how I want it to think and when applicable tells it how to research. 'cause sometimes there are, sometimes it executes brief searches, but a lot of times with these deeper research projects, that is not what you want. So you, I don't recommend just using this for everything. This is more of just an exercise in thinking how to pull these prompts together. And, uh, I guess furthermore, this is probably more tailored to more basic tools and less deep reasoning models because as I understand it a lot, a lot of models now do some of these steps by themselves. But y this is here, if anyone finds it helpful, and I understand this is or will be soon circulated to both here. It it has already been. And I guess staying on the, the topic here, Jason, what, what does auditing look like, um, for you and your team? Do you actually audit what people use for prompts? Do you have a library and, and do you, do you, uh, do you ever look at what, what's being used as prompts? Uh, so we don't audit. I think generally as a team, we like to come together and discuss best practices. This works, this doesn't, but our policies are pretty trust based. We do have a usage policy like Alex was mentioning, um, that, but that mostly says if you're using a tool, you shouldn't be using tools that don't go through InfoSec",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 1413.305,
    "cue_end": 1611.294,
    "chunk_index": 16,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_17",
    "text": ". 'cause sometimes there are, sometimes it executes brief searches, but a lot of times with these deeper research projects, that is not what you want. So you, I don't recommend just using this for everything. This is more of just an exercise in thinking how to pull these prompts together. And, uh, I guess furthermore, this is probably more tailored to more basic tools and less deep reasoning models because as I understand it a lot, a lot of models now do some of these steps by themselves. But y this is here, if anyone finds it helpful, and I understand this is or will be soon circulated to both here. It it has already been. And I guess staying on the, the topic here, Jason, what, what does auditing look like, um, for you and your team? Do you actually audit what people use for prompts? Do you have a library and, and do you, do you, uh, do you ever look at what, what's being used as prompts? Uh, so we don't audit. I think generally as a team, we like to come together and discuss best practices. This works, this doesn't, but our policies are pretty trust based. We do have a usage policy like Alex was mentioning, um, that, but that mostly says if you're using a tool, you shouldn't be using tools that don't go through InfoSec. But if you are, don't give it confidential information. No matter what tool you're using, you are responsible for outcomes. And it's basically just saying treat these vendors like any other vendors. But no, we're not telling people when they're allowed to prompt or how they're allowed to prompt because to me that kind of seems like telling somebody how to think or how to Google or use any other tool that we'd trust them to use. And I know we, we haven't talked about agents, but we did get a question in the chat. Um, Jason and, and Alex, please fill in to chime in right after, are either of you creating agents? We are, our our company is doing it. Our legal department is, is not. So it's not something that has yet entered my workflow. I it sounds like Alex has a more useful answer. Yeah, I was just gonna say that ironically, two weeks ago we made our first agent for internal, internal, uh, legal use cases. Just we had like a offsite hackathon for our legal team and finance team. And, um, one of the tools or work workflows we used was, uh, through Zapier we created a Zap, which it's like a, Zapier is like a pretty inexpensive automation platform if you're not familiar with it. It's, it's pretty user friendly. You might have to have some technical experience with it, but, uh, it's kind of drag and drop and, and using, um, our Slack API keys that we're able to link, uh, to it and then open AI's models through their API keys and Zapier. We created a kind of a triage chat bot for our deal desk Slack channel",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 1527.415,
    "cue_end": 1712.56,
    "chunk_index": 17,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_18",
    "text": ". No matter what tool you're using, you are responsible for outcomes. And it's basically just saying treat these vendors like any other vendors. But no, we're not telling people when they're allowed to prompt or how they're allowed to prompt because to me that kind of seems like telling somebody how to think or how to Google or use any other tool that we'd trust them to use. And I know we, we haven't talked about agents, but we did get a question in the chat. Um, Jason and, and Alex, please fill in to chime in right after, are either of you creating agents? We are, our our company is doing it. Our legal department is, is not. So it's not something that has yet entered my workflow. I it sounds like Alex has a more useful answer. Yeah, I was just gonna say that ironically, two weeks ago we made our first agent for internal, internal, uh, legal use cases. Just we had like a offsite hackathon for our legal team and finance team. And, um, one of the tools or work workflows we used was, uh, through Zapier we created a Zap, which it's like a, Zapier is like a pretty inexpensive automation platform if you're not familiar with it. It's, it's pretty user friendly. You might have to have some technical experience with it, but, uh, it's kind of drag and drop and, and using, um, our Slack API keys that we're able to link, uh, to it and then open AI's models through their API keys and Zapier. We created a kind of a triage chat bot for our deal desk Slack channel. And when new messages come in from the sales team or our customer success team, it'll, you know, reference a knowledge base that we created and uploaded and then accurately route those questions to the right internal stakeholder for approvals or for review. Um, we have not yet allowed it to straight up answer legal questions. I'm not super comfortable with end users being able to receive that without an attorney input. But basic like billing finance questions, it does answer and it's, it's pretty accurate. Um, and one of the things we did to save us time as well is we like downloaded, we used the Slack API and scanned the last year of messages in this channel and directed OpenAI or chat JT to figure out like what the most common questions were, who they were most commonly routed to, what the responses were. So we grounded the, um, chat bot's responses in that knowledge from the last year's context as well. And it's been live now for a couple weeks and it's pretty great. That's the first like agentic use case. We've, we've Done, we use a lot of Zaps at, uh, at law trades and they're pretty awesome. But I think, yeah, probably the general consensus is folks wanting a human to stay in the loop on, on questions. Um, we, we got a question about, uh, being comfortable with inputting sensitive client data into, um, enterprise accounts",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 1614.595,
    "cue_end": 1796.025,
    "chunk_index": 18,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_19",
    "text": ". We created a kind of a triage chat bot for our deal desk Slack channel. And when new messages come in from the sales team or our customer success team, it'll, you know, reference a knowledge base that we created and uploaded and then accurately route those questions to the right internal stakeholder for approvals or for review. Um, we have not yet allowed it to straight up answer legal questions. I'm not super comfortable with end users being able to receive that without an attorney input. But basic like billing finance questions, it does answer and it's, it's pretty accurate. Um, and one of the things we did to save us time as well is we like downloaded, we used the Slack API and scanned the last year of messages in this channel and directed OpenAI or chat JT to figure out like what the most common questions were, who they were most commonly routed to, what the responses were. So we grounded the, um, chat bot's responses in that knowledge from the last year's context as well. And it's been live now for a couple weeks and it's pretty great. That's the first like agentic use case. We've, we've Done, we use a lot of Zaps at, uh, at law trades and they're pretty awesome. But I think, yeah, probably the general consensus is folks wanting a human to stay in the loop on, on questions. Um, we, we got a question about, uh, being comfortable with inputting sensitive client data into, um, enterprise accounts. Say for example, OpenAI, I think we touched on that a little, um, which is about systems that encrypt things, you know, and or anonymizing, like, like for example, Alex, you said making something Acme not your company. Um, are those the best practices for, for not, uh, putting client data into these models? Yeah, I think, um, for the general purpose models like open AI and philanthropic, it's, if you're wanting to be extra cautious, you can always just use Acme or something like that. Um, that requires a bit more of a manual lift. It might be slower and inefficient because you're having to do that every time, especially if you're uploading documents to it, you're having to, you know, find and replace any usage of, uh, confidential company information to do that. Um, but yeah, like honestly, the easy answer is you'll probably just want to use a tool like White Shoe or GCI where it allows you to go in and create a company profile or client profiles if you need more than one. And you enter all this information and then the M'S responses throughout the platform automatically incorporate that information and it's encrypted and like remains secure too, which is useful and speeds up processes and makes it more accurate, all that stuff. Yeah, I guess just to add on to that, my view has always been if the, if your team has gotten comfortable that the InfoSec protections are there and you're comfortable that the legal protections are there, then I, I treat these things like any other vendor",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 1707.813,
    "cue_end": 1887.501,
    "chunk_index": 19,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_20",
    "text": ". Um, are those the best practices for, for not, uh, putting client data into these models? Yeah, I think, um, for the general purpose models like open AI and philanthropic, it's, if you're wanting to be extra cautious, you can always just use Acme or something like that. Um, that requires a bit more of a manual lift. It might be slower and inefficient because you're having to do that every time, especially if you're uploading documents to it, you're having to, you know, find and replace any usage of, uh, confidential company information to do that. Um, but yeah, like honestly, the easy answer is you'll probably just want to use a tool like White Shoe or GCI where it allows you to go in and create a company profile or client profiles if you need more than one. And you enter all this information and then the M'S responses throughout the platform automatically incorporate that information and it's encrypted and like remains secure too, which is useful and speeds up processes and makes it more accurate, all that stuff. Yeah, I guess just to add on to that, my view has always been if the, if your team has gotten comfortable that the InfoSec protections are there and you're comfortable that the legal protections are there, then I, I treat these things like any other vendor. There's of course gonna be incremental risk anytime you expand your circle of trust at all. But I, I don't think that these things are that different from any other vendors is my takeaway. Okay. So we've been through prompts, we touched on agents very quickly. We talked about guardrails. There are a lot of people trying to discern in the chat, which is the right tool for them. So let's take them through tool selection when it comes to oversight, tool selection, what you do, Jason, like what can you take people through on, on, on human oversight? Um, you know, any advice on like what they can do there? Yeah, I'll just regurgitate some of the other things I've said already, but I think you need to have, you need, you want to have a BS meter on the subjects you're asking it about. If you do not, then you should instead be using it to figure out what you don't know and frame a more intelligent question to somebody who does, uh, when you can do that. Or I suppose even if you can, you should try to ask questions that allow you to spot check the outputs as well, and that helps you to falsify responses. But I suppose the, the general point is that our job as AI augmented attorneys is knowing what to ask when and how, and that job itself cannot be yet replicated by ai. So yeah. Fantastic. And Alex, um, uh, uh, hopefully like you, you know, you've touched on this a little bit, but do you have any further insight on how you decide which AI platform to do for, for which task? Any, any magic there",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 1810.081,
    "cue_end": 2001.279,
    "chunk_index": 20,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_21",
    "text": ". But I, I don't think that these things are that different from any other vendors is my takeaway. Okay. So we've been through prompts, we touched on agents very quickly. We talked about guardrails. There are a lot of people trying to discern in the chat, which is the right tool for them. So let's take them through tool selection when it comes to oversight, tool selection, what you do, Jason, like what can you take people through on, on, on human oversight? Um, you know, any advice on like what they can do there? Yeah, I'll just regurgitate some of the other things I've said already, but I think you need to have, you need, you want to have a BS meter on the subjects you're asking it about. If you do not, then you should instead be using it to figure out what you don't know and frame a more intelligent question to somebody who does, uh, when you can do that. Or I suppose even if you can, you should try to ask questions that allow you to spot check the outputs as well, and that helps you to falsify responses. But I suppose the, the general point is that our job as AI augmented attorneys is knowing what to ask when and how, and that job itself cannot be yet replicated by ai. So yeah. Fantastic. And Alex, um, uh, uh, hopefully like you, you know, you've touched on this a little bit, but do you have any further insight on how you decide which AI platform to do for, for which task? Any, any magic there? Yeah, so I would say the default program nowadays we use for contract redlining is Ivo and essentially everything else, it's uh, white, it's been a white shoe ai and that's largely because it just like, one, it's super cost effective, um, but two, it does a lot of this stuff we're talking about on the backend without you having to really like know coding or how to prompt specifically, it'll enhance your prompts. Um, if you go into like their chat bot for instance, you can, there's a dropdown of like the practice area you want it to be an expert in. So I know if I'm asking it about a term sheet for some financing, I can go in and select the, just like a law firm, the emerging companies and venture capital practice group. And it's actually like adjusted and it's a fine tuned model for that. And that's like substantially better responses than if I just go into chat GPT and ask a question. Um, so there's a bit of that. And then I think internally, just like budget wise, we're super cost conscious, so we don't want tool creep, we don't want a ton of tools that do the same thing. Um, quite frankly, by the end of this year, we're probably gonna churn from either GCI or Ivo because they're both starting to cross paths and like do the same thing as the, as each other and we're just gonna have to determine which one's the best at doing it and save eight grand a year or whatever. Interesting question. Um, does anyone have walled off instances by department? For example, HR or legal or any other department",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 1892.767,
    "cue_end": 2097.36,
    "chunk_index": 21,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_22",
    "text": ". Um, if you go into like their chat bot for instance, you can, there's a dropdown of like the practice area you want it to be an expert in. So I know if I'm asking it about a term sheet for some financing, I can go in and select the, just like a law firm, the emerging companies and venture capital practice group. And it's actually like adjusted and it's a fine tuned model for that. And that's like substantially better responses than if I just go into chat GPT and ask a question. Um, so there's a bit of that. And then I think internally, just like budget wise, we're super cost conscious, so we don't want tool creep, we don't want a ton of tools that do the same thing. Um, quite frankly, by the end of this year, we're probably gonna churn from either GCI or Ivo because they're both starting to cross paths and like do the same thing as the, as each other and we're just gonna have to determine which one's the best at doing it and save eight grand a year or whatever. Interesting question. Um, does anyone have walled off instances by department? For example, HR or legal or any other department? I've never heard of that, but that's an interesting question we got. I think I'd probably have to ask a follow-up question to ever asked it by what they mean by walled off. If it's like a private instance of a, you know, cloud hosted model just on your internal workspace at your company that only certain lawyers or finance people can access. If that's the question, we certainly don't, that would be really expensive, difficult to implement. But with that being said, I'm sure there are large legal departments and really sophisticated companies, probably Fortune 20 companies that prioritize that type of use case. For most of us on this call though, it's probably too cumbersome to implement something like that. And tool selection itself probably helps with that. Like Jasper is a marketing AI tool and like as much as I'd love to say it's great for lawyers, it it's horrible. Um, so like I don't ever use our own product, but like our marketing team uses it like crazy and like similarly they're not gonna ever use GC AI or White Shoe. It's like that kind of helps wall it off itself, but they're certainly not like privately hosted models that only Jasper has access to. Yeah. Uh, I'm likely speaking well over my skis here, but I think the only tool that most of my company has access to is chat GPT and I, I believe that that is relatively segregated by specific individual account, but if if that's not the case, then I'm just wrong. So there's that. So I am going to bring us, um, to perhaps like the most exciting part. Uh, let's talk about how utilizing AI can actually save us time. Um, does anyone, uh, uh, actually, sorry Alex, let's start with you. Can you talk about how much time you're spending and saving by utilizing these tools and uh, have you been able to not outsource to someone and you can say you have tangible numbers. Yeah, definitely",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 2032.143,
    "cue_end": 2227.35,
    "chunk_index": 22,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_23",
    "text": ". But with that being said, I'm sure there are large legal departments and really sophisticated companies, probably Fortune 20 companies that prioritize that type of use case. For most of us on this call though, it's probably too cumbersome to implement something like that. And tool selection itself probably helps with that. Like Jasper is a marketing AI tool and like as much as I'd love to say it's great for lawyers, it it's horrible. Um, so like I don't ever use our own product, but like our marketing team uses it like crazy and like similarly they're not gonna ever use GC AI or White Shoe. It's like that kind of helps wall it off itself, but they're certainly not like privately hosted models that only Jasper has access to. Yeah. Uh, I'm likely speaking well over my skis here, but I think the only tool that most of my company has access to is chat GPT and I, I believe that that is relatively segregated by specific individual account, but if if that's not the case, then I'm just wrong. So there's that. So I am going to bring us, um, to perhaps like the most exciting part. Uh, let's talk about how utilizing AI can actually save us time. Um, does anyone, uh, uh, actually, sorry Alex, let's start with you. Can you talk about how much time you're spending and saving by utilizing these tools and uh, have you been able to not outsource to someone and you can say you have tangible numbers. Yeah, definitely. So I joined Jasper three years ago, um, before chat GBT became publicly available, uh, which partially obliterated our downmarket business at Jasper, but that's okay. Um, we pivoted, but before then, and probably for the six months thereafter, chat, GBT and the generally available tools were pretty horrendous at doing legal work. Like I think whenever they test him on the bar, they were hardly passing or like not passing. Since then, like over the last 18 months to 24 months, the general tools have become super useful and then there's all these legal AI startups that have spr it up with specific tools. And beginning about two years ago we started like heavily implementing, um, tool usage for AI within our legal department. And over that two year period, our outside counsel spend has decreased 93%. So we we're saving like $200,000 a year. And that our outside council firms probably aren't real, but like we go to AI as like a what you would treat like a junior or even mid-level associate. Some of these firms, which it blows my mind nowadays when you get bills for junior associates that are seven 50 bucks an hour. Um, so like we, we use that largely for like high stake stuff, obviously, like if it's a financing or an acquisition, we're still gonna use like real outside firms. But for the day-to-day stuff that most of us like at L Suite in-house departments, um, we just need to like expand our reach and speed as quickly and as cheaply as possible. And AI has in my mind, revolutionized the practice of law by being able to do that",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 2123.08,
    "cue_end": 2327.52,
    "chunk_index": 23,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_24",
    "text": ". Um, we pivoted, but before then, and probably for the six months thereafter, chat, GBT and the generally available tools were pretty horrendous at doing legal work. Like I think whenever they test him on the bar, they were hardly passing or like not passing. Since then, like over the last 18 months to 24 months, the general tools have become super useful and then there's all these legal AI startups that have spr it up with specific tools. And beginning about two years ago we started like heavily implementing, um, tool usage for AI within our legal department. And over that two year period, our outside counsel spend has decreased 93%. So we we're saving like $200,000 a year. And that our outside council firms probably aren't real, but like we go to AI as like a what you would treat like a junior or even mid-level associate. Some of these firms, which it blows my mind nowadays when you get bills for junior associates that are seven 50 bucks an hour. Um, so like we, we use that largely for like high stake stuff, obviously, like if it's a financing or an acquisition, we're still gonna use like real outside firms. But for the day-to-day stuff that most of us like at L Suite in-house departments, um, we just need to like expand our reach and speed as quickly and as cheaply as possible. And AI has in my mind, revolutionized the practice of law by being able to do that. So yeah, we've saved 92% over two years. And then in terms of like time saved, I'm sure I could like get, get an accurate or close to accurate hours per week saved. But I think the better metric is that given our like legal intake volume, our sales contract review volume and all that, we should be ending this year with five or six attorneys. We should currently have four, we only have two and we're not like crazy overworked or not more than anyone else and we don't plan on adding head count by the end of the year. So if you take that for what it's worth, it's like essentially one lawyer is doing the work of three by using AI Now That, that is like quite a win. Uh, Jason, how about you? I don't have, uh, specific figures like Alex does, but I suppose more anecdotally, I recently maybe two months ago closed an m and a transaction just by myself using AI tools opposite a full Kirkland and Alice bench. So that is not something I could do unassisted by ai. I probably saved, it wasn't the biggest transaction, it might have cost $30,000 through big law or $15,000 through medium law service providers, but it's really nice to be able to just internalize things like that. AI assisted, No, I think, I think you're not giving yourself enough credit. That's really impressive. I mean, if we got to a world where this could assist in lobbing off like huge m and a expenses, because obviously law firms have been using this sort of tooling for a really long time to do this, right? Um, and so if we're able to do that in-house, um, a little bit more independently, that's really very impressive",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 2240.218,
    "cue_end": 2434.763,
    "chunk_index": 24,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_25",
    "text": ". But I think the better metric is that given our like legal intake volume, our sales contract review volume and all that, we should be ending this year with five or six attorneys. We should currently have four, we only have two and we're not like crazy overworked or not more than anyone else and we don't plan on adding head count by the end of the year. So if you take that for what it's worth, it's like essentially one lawyer is doing the work of three by using AI Now That, that is like quite a win. Uh, Jason, how about you? I don't have, uh, specific figures like Alex does, but I suppose more anecdotally, I recently maybe two months ago closed an m and a transaction just by myself using AI tools opposite a full Kirkland and Alice bench. So that is not something I could do unassisted by ai. I probably saved, it wasn't the biggest transaction, it might have cost $30,000 through big law or $15,000 through medium law service providers, but it's really nice to be able to just internalize things like that. AI assisted, No, I think, I think you're not giving yourself enough credit. That's really impressive. I mean, if we got to a world where this could assist in lobbing off like huge m and a expenses, because obviously law firms have been using this sort of tooling for a really long time to do this, right? Um, and so if we're able to do that in-house, um, a little bit more independently, that's really very impressive. There's, there's some, uh, excitement in the chat. Okay. Um, before we close Jason, what is one piece of advice you would give someone who just started looking at these tools, prompting, um, getting comfortable, wants to give their team, you know, a speech about it. What kind of advice do you wanna give to someone? Uh, pick your tools wisely. I'm definitely, I'm probably not the best at that, but I, I like what I have and I'd found success with it. Uh, be smart about how you ask questions. I won't go into the whole spiel I've recycled a few times already, but that is very important. And don't trust outputs. Verify them, Trust them, verify. Alex, what about you? What advice would you give somebody? Yeah, I'm once again just gonna rip from Ethan Malik's book, which I'd recommend anyone read. It's incredible. But I'd say first like, treat AI as a co intelligence. Um, he projects that like within five years humans will become cyborgs, meaning like we're almost everything we do in work is augmented to some degree by degree an ai. Um, and that's certainly been come the case in my own work life and I found it incredibly useful. So I think treating it as a co co intelligence and just helping you think, even if you like, are most certain, you know, the answer to something like, you know, we all, we all have like implicit biases and having it critique those things to um, like re refine our reasoning is always useful. Um, and then I'd also just be comfortable with like good enough responses from ai. That's probably my second point",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 2337.493,
    "cue_end": 2544.037,
    "chunk_index": 25,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_26",
    "text": ". Okay. Um, before we close Jason, what is one piece of advice you would give someone who just started looking at these tools, prompting, um, getting comfortable, wants to give their team, you know, a speech about it. What kind of advice do you wanna give to someone? Uh, pick your tools wisely. I'm definitely, I'm probably not the best at that, but I, I like what I have and I'd found success with it. Uh, be smart about how you ask questions. I won't go into the whole spiel I've recycled a few times already, but that is very important. And don't trust outputs. Verify them, Trust them, verify. Alex, what about you? What advice would you give somebody? Yeah, I'm once again just gonna rip from Ethan Malik's book, which I'd recommend anyone read. It's incredible. But I'd say first like, treat AI as a co intelligence. Um, he projects that like within five years humans will become cyborgs, meaning like we're almost everything we do in work is augmented to some degree by degree an ai. Um, and that's certainly been come the case in my own work life and I found it incredibly useful. So I think treating it as a co co intelligence and just helping you think, even if you like, are most certain, you know, the answer to something like, you know, we all, we all have like implicit biases and having it critique those things to um, like re refine our reasoning is always useful. Um, and then I'd also just be comfortable with like good enough responses from ai. That's probably my second point. It's like, at first I was like, oh, you know, it's not passing the bar at a 99% pass rate, but most lawyers aren't either. Um, most lawyers like I, if I'm hiring someone, I'm happy if they're consistently outputting 80 to 85% results. Now I could say human, it's like if the AI's doing that, but for 20 bucks a month it's pretty incredible and like I can improve the other 20% to make it better. And then three, I think like the more that you can ingest kind of like the geeky, nerdy AI stuff through newsletters or videos or whatever, the better. Like, uh, a few weeks ago Sam Altman had like a really interesting interview on a panel he was on. Um, and uh, the interviewer asked him what they've noticed at Open AI about different generations and how they use ai and he commented how like the older generations are using, um, AI as you know, the memes that we used to see 20 years ago from our grandparents asking questions to Google that like didn't make any sense. But like ironically now, like that's actually like a pretty ideal way to use AI for someone who doesn't need it for some specialized use case. It's just like treating like another human asking it questions. They're using it like that. The people who are like, you know, in the market and have integrated this into their work over the last two years are using it largely how it's intended to be using, asking it to act in a role, trying to verify outputs, having to critique reasoning that that sort of stuff refined writing",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 2438.964,
    "cue_end": 2633.815,
    "chunk_index": 26,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_27",
    "text": ". It's like, at first I was like, oh, you know, it's not passing the bar at a 99% pass rate, but most lawyers aren't either. Um, most lawyers like I, if I'm hiring someone, I'm happy if they're consistently outputting 80 to 85% results. Now I could say human, it's like if the AI's doing that, but for 20 bucks a month it's pretty incredible and like I can improve the other 20% to make it better. And then three, I think like the more that you can ingest kind of like the geeky, nerdy AI stuff through newsletters or videos or whatever, the better. Like, uh, a few weeks ago Sam Altman had like a really interesting interview on a panel he was on. Um, and uh, the interviewer asked him what they've noticed at Open AI about different generations and how they use ai and he commented how like the older generations are using, um, AI as you know, the memes that we used to see 20 years ago from our grandparents asking questions to Google that like didn't make any sense. But like ironically now, like that's actually like a pretty ideal way to use AI for someone who doesn't need it for some specialized use case. It's just like treating like another human asking it questions. They're using it like that. The people who are like, you know, in the market and have integrated this into their work over the last two years are using it largely how it's intended to be using, asking it to act in a role, trying to verify outputs, having to critique reasoning that that sort of stuff refined writing. Um, but then he found the most interesting was that younger generations, like people in high school and college are using AI as like a new operating system. Like rather than going to their computer or their phone as like their main source of computation and operating system, these people are just starting to use like ai, um, because they've grown up with it, it's intuitive for them. So things like keeping like a eternal thread on chat GBT and having it store to do tasks and calendaring. I'd rather than using like Gmail calendar, they just use this now and they'll ask like every morning, tell me what I need to do today. It's like that type of stuff that most of us wouldn't intuitively think 'cause we're so used to using other tools. Um, and I think staying current on like best AI use cases and whatnot, even if it's sometimes nerdy and even if they get into like the technical jargon, it's still interesting to hear how like the most cutting edge people are starting to use it so that we can try and adapt that for like our legal use cases. I have started to ask chat questions that I used to Google. Um, like it, it's become, and and that's actually a big thing now is like SEO optimization inside of the responses that say like, chat will give you a cloud we'll give you. Um, but yeah, that's been my go-to recently and so I've even seen my own, uh, behavior shift. Uh, we, I'm very excited. We have a lot of really, uh, really great questions",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 2544.071,
    "cue_end": 2720.497,
    "chunk_index": 27,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_28",
    "text": ". Um, but then he found the most interesting was that younger generations, like people in high school and college are using AI as like a new operating system. Like rather than going to their computer or their phone as like their main source of computation and operating system, these people are just starting to use like ai, um, because they've grown up with it, it's intuitive for them. So things like keeping like a eternal thread on chat GBT and having it store to do tasks and calendaring. I'd rather than using like Gmail calendar, they just use this now and they'll ask like every morning, tell me what I need to do today. It's like that type of stuff that most of us wouldn't intuitively think 'cause we're so used to using other tools. Um, and I think staying current on like best AI use cases and whatnot, even if it's sometimes nerdy and even if they get into like the technical jargon, it's still interesting to hear how like the most cutting edge people are starting to use it so that we can try and adapt that for like our legal use cases. I have started to ask chat questions that I used to Google. Um, like it, it's become, and and that's actually a big thing now is like SEO optimization inside of the responses that say like, chat will give you a cloud we'll give you. Um, but yeah, that's been my go-to recently and so I've even seen my own, uh, behavior shift. Uh, we, I'm very excited. We have a lot of really, uh, really great questions. Let me ans let me ask one, uh, that just came up Jason. Um, specifically what tool did you use for, for that m and a um, uh, support? Yeah, I should have provided some more details. So again, I'm not the expert in which tool to pick. I use GCAI, it helped that I am an m and a attorney by training. I've run lots of deals, so give me most pretty decent tools and I can run with my little robot minions and close deals so that, that may not be the best approach, but it worked very well for me is all I can say from my anecdote. Well, and I think you're overlaying it with what's important, which is you had the expertise to be able to see that the outputs like, like that domain expertise. So someone who maybe doesn't have it, that may be like you might have that edge, which is I think extremely fair in a lot of what we've been talking about today. Certainly if you don't have the expertise to run a certain kind of transaction or process, AI won't give you that expertise, but if you do, it's a very good resource. That's right. And we've all been saying, yeah. So, um, Alex, this, this goes back to something you said, uh, a little bit earlier, like on note taking for example, I think we're all sort of running Zoom AI or granola or some flavor of, of, uh, an automated note taker. Um, when you're utilizing a tool like that, how do both of you get comfortable with preserving privilege and confidentiality",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 2633.855,
    "cue_end": 2810.115,
    "chunk_index": 28,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_29",
    "text": ". Uh, we, I'm very excited. We have a lot of really, uh, really great questions. Let me ans let me ask one, uh, that just came up Jason. Um, specifically what tool did you use for, for that m and a um, uh, support? Yeah, I should have provided some more details. So again, I'm not the expert in which tool to pick. I use GCAI, it helped that I am an m and a attorney by training. I've run lots of deals, so give me most pretty decent tools and I can run with my little robot minions and close deals so that, that may not be the best approach, but it worked very well for me is all I can say from my anecdote. Well, and I think you're overlaying it with what's important, which is you had the expertise to be able to see that the outputs like, like that domain expertise. So someone who maybe doesn't have it, that may be like you might have that edge, which is I think extremely fair in a lot of what we've been talking about today. Certainly if you don't have the expertise to run a certain kind of transaction or process, AI won't give you that expertise, but if you do, it's a very good resource. That's right. And we've all been saying, yeah. So, um, Alex, this, this goes back to something you said, uh, a little bit earlier, like on note taking for example, I think we're all sort of running Zoom AI or granola or some flavor of, of, uh, an automated note taker. Um, when you're utilizing a tool like that, how do both of you get comfortable with preserving privilege and confidentiality? Yeah, the easy answer is I don't get comfortable and I haven't, we, we've honestly been trying to restrict the Zoom recording or gran, we use granola internally. Granola currently doesn't have a feature to like auto delete some period, like a retention timeline basically. I wish it did. Um, so we just try to coach our people like not to use that in a board meeting obviously, or like anything even slightly lower stakes than that. Um, but with that being said, it's like we're certainly not taking a restrictive stance saying you can't use this because the fact of the matter is it's, it's saving people tons of time. It's a more accurate note taker than humans certainly are. It allows people to focus on the human being across the screen from them in a meeting rather than focus on taking notes. It's like those things in my mind far outweigh the risks as long as you're like being careful. Like if, you know, we haven't had a data breach, but if I'm on the phone and we're talking about a data breach with my ciso, I'm not gonna have granola recording, uh, the message there. Or if I do, I'm gonna immediately, I'm gonna take the notes, maybe print them out or keep them in some physical form and delete like the transcript of it from the servers. Something like that. Yeah, this is an issue we've discussed, perhaps not at length, but it's, it's come up where there are obvious discovery implications for anything that I'll use",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 2715.575,
    "cue_end": 2895.032,
    "chunk_index": 29,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_30",
    "text": "? Yeah, the easy answer is I don't get comfortable and I haven't, we, we've honestly been trying to restrict the Zoom recording or gran, we use granola internally. Granola currently doesn't have a feature to like auto delete some period, like a retention timeline basically. I wish it did. Um, so we just try to coach our people like not to use that in a board meeting obviously, or like anything even slightly lower stakes than that. Um, but with that being said, it's like we're certainly not taking a restrictive stance saying you can't use this because the fact of the matter is it's, it's saving people tons of time. It's a more accurate note taker than humans certainly are. It allows people to focus on the human being across the screen from them in a meeting rather than focus on taking notes. It's like those things in my mind far outweigh the risks as long as you're like being careful. Like if, you know, we haven't had a data breach, but if I'm on the phone and we're talking about a data breach with my ciso, I'm not gonna have granola recording, uh, the message there. Or if I do, I'm gonna immediately, I'm gonna take the notes, maybe print them out or keep them in some physical form and delete like the transcript of it from the servers. Something like that. Yeah, this is an issue we've discussed, perhaps not at length, but it's, it's come up where there are obvious discovery implications for anything that I'll use. Zoom AI as an example, just automatically saves and emails out to everybody where I master of the universe. I would make it so that you can ask it questions based on what it's sort of stored. You can get the answers and then you use those notes yourself rather than just these AI summarized call transcripts, which are just there forever, but may maybe that'll be a feature one day and maybe it already is and I just haven't figured out how to use it. But that, that's what I would prefer. I I'm gonna pivot a little bit to CLMs. So the question is largely around like AI tools and CLMs, um, and it's it and it's, is there, is there an easier way to redline contracts, for example, utilizing like an AI word plugin versus going the full route of A CLM implementation? And this is probably largely an opinion and largely based on the size and scale and scope of your organization, but if either of you find, um, utilizing an AI tool, uh, to be maybe easier than that implementation or any insights there? Yeah, I definitely have an opinion and it's not overly positive. Um, so we implemented a CLM solution. The biggest one probably that you guys are all familiar with, um, coming up on two and a half years ago and during that time had like a bake off between three of the best ones. The only one at that time that I found that was good at uh, like contract redlining was luminance, but they were so early at all the other things that we didn't actually end up using them and I didn't need a contract red liner at that point in time and it wasn't up to speed",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 2810.165,
    "cue_end": 2995.116,
    "chunk_index": 30,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_31",
    "text": ". I would make it so that you can ask it questions based on what it's sort of stored. You can get the answers and then you use those notes yourself rather than just these AI summarized call transcripts, which are just there forever, but may maybe that'll be a feature one day and maybe it already is and I just haven't figured out how to use it. But that, that's what I would prefer. I I'm gonna pivot a little bit to CLMs. So the question is largely around like AI tools and CLMs, um, and it's it and it's, is there, is there an easier way to redline contracts, for example, utilizing like an AI word plugin versus going the full route of A CLM implementation? And this is probably largely an opinion and largely based on the size and scale and scope of your organization, but if either of you find, um, utilizing an AI tool, uh, to be maybe easier than that implementation or any insights there? Yeah, I definitely have an opinion and it's not overly positive. Um, so we implemented a CLM solution. The biggest one probably that you guys are all familiar with, um, coming up on two and a half years ago and during that time had like a bake off between three of the best ones. The only one at that time that I found that was good at uh, like contract redlining was luminance, but they were so early at all the other things that we didn't actually end up using them and I didn't need a contract red liner at that point in time and it wasn't up to speed. Like it wasn't as good as the current ones are, like Ivo or GC ai. Um, but like the large legacy CLM solutions I have found to be very weak. Like you can, it almost seems like they're just bolting on AI so that they can market themselves as AI companies. Um, ironclad link squares these people and the redline tools aren't good. If I was them, I would just acquire one of these startups honestly and integrate it. Um, but uh, hope hopefully they get there because it'd certainly be easier to just have a one-stop shop where like all your contracts are negotiated and redlined. I just haven't found the tools nearly as good as the third party products currently are. Yeah, we don't dabble much in either of those areas. We haven't found, we, we don't, we're not scaled in certain areas sufficiently to I think need CLM and those areas, which it would be super helpful. It would be probably better for us to just find a way to build the tool or hire contractors to do that for us. So we're not in CLM redlining software. I've experimented with, it has been eight or so months, but when I was sort of dipping my toes in the water there, I wasn't very impressed at what I saw. I found that I had to, at a very granular level review the agreements anyway in a way that it didn't really reduce the time spent per contract. I'm sure that is not always the case for everybody and I'm sure the tools have gotten better, so I'll I'll need to reevaluate that likely soon. Yeah, it's an interesting space for sure when every product has its own ai, right",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 2901.62,
    "cue_end": 3089.305,
    "chunk_index": 31,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_32",
    "text": ". Um, but like the large legacy CLM solutions I have found to be very weak. Like you can, it almost seems like they're just bolting on AI so that they can market themselves as AI companies. Um, ironclad link squares these people and the redline tools aren't good. If I was them, I would just acquire one of these startups honestly and integrate it. Um, but uh, hope hopefully they get there because it'd certainly be easier to just have a one-stop shop where like all your contracts are negotiated and redlined. I just haven't found the tools nearly as good as the third party products currently are. Yeah, we don't dabble much in either of those areas. We haven't found, we, we don't, we're not scaled in certain areas sufficiently to I think need CLM and those areas, which it would be super helpful. It would be probably better for us to just find a way to build the tool or hire contractors to do that for us. So we're not in CLM redlining software. I've experimented with, it has been eight or so months, but when I was sort of dipping my toes in the water there, I wasn't very impressed at what I saw. I found that I had to, at a very granular level review the agreements anyway in a way that it didn't really reduce the time spent per contract. I'm sure that is not always the case for everybody and I'm sure the tools have gotten better, so I'll I'll need to reevaluate that likely soon. Yeah, it's an interesting space for sure when every product has its own ai, right? Like, and also then there's the AI products that also are dedicated to that space and like trying to navigate through like who, who wins that sort of arms race and who's giving the best output is gonna be something that I think we navigate over the next few years. Absolutely. Uh, we got something that's very, very highly upvoted, so I have to ask it. Do the GCI users find much difference between using that platform or just a paid GPT? Um, I think we covered a lot of this and what's very unique about GPT and that it's, it's, you know, giving in, uh, GCI rather in that it's giving you, um, prompt, you know, recommendations and that it does have like, that we're built on for redline. So it sounds like there's a bit of uniqueness there, but it was uploaded highly. Anything else to overlay on why you might pick a tool that is tailor, uh, purpose built for, for legal? Uh, GC AI is kind of just awesome. So the precision and the responses is very impressive. Cecilia sort of demoed it to me herself and she was explaining to me that the types of, uh, like quotes and end quotes even like have to be specific or they consider that a miss in their internal testing. It also, I'm, I'm speaking to the one tool I use the most obviously, but it also knows which parts of which prompt to send to which underlying models, which is hugely helpful, particularly if you're less tech savvy such as myself, where I'm, I'm not breaking apart tasks, sending them to different machines and then aggregating that at the end",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 2999.609,
    "cue_end": 3191.427,
    "chunk_index": 32,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_33",
    "text": ". Absolutely. Uh, we got something that's very, very highly upvoted, so I have to ask it. Do the GCI users find much difference between using that platform or just a paid GPT? Um, I think we covered a lot of this and what's very unique about GPT and that it's, it's, you know, giving in, uh, GCI rather in that it's giving you, um, prompt, you know, recommendations and that it does have like, that we're built on for redline. So it sounds like there's a bit of uniqueness there, but it was uploaded highly. Anything else to overlay on why you might pick a tool that is tailor, uh, purpose built for, for legal? Uh, GC AI is kind of just awesome. So the precision and the responses is very impressive. Cecilia sort of demoed it to me herself and she was explaining to me that the types of, uh, like quotes and end quotes even like have to be specific or they consider that a miss in their internal testing. It also, I'm, I'm speaking to the one tool I use the most obviously, but it also knows which parts of which prompt to send to which underlying models, which is hugely helpful, particularly if you're less tech savvy such as myself, where I'm, I'm not breaking apart tasks, sending them to different machines and then aggregating that at the end. So it's, it's really, it's a nice one stop shop if you can't be bothered to get too much into the AI weeds. Oh, that's impressive. Yeah, and, and for folks who may not know, like some certain like AI models are better than others, like say at tests or doing contracts, right? Like, and so I I, if GCAI is doing that all in the background kind of automatically, like I think that that is a pretty good value add. Wow, that is, that is something I did not know. Thank you Jason. All right, I think we're down to like the last one or two. Um, Alex, uh, can you talk us through, um, the like, uh, AI replicating legal tasks. So how do you think about the future of in-house legal work given the increased sophistication of legal AI tools, for example, what do you see it looking like in one year, two years, three years? Yeah, so I am an ai, uh, optimist. You haven't already been able to tell. There are, there are the doomers that think it's gonna like end all legal practice or whatnot. I think it's just gonna really augment our legal practice and make us hopefully make our lives better. Um, but more likely just make us be able to be more efficient, quicker and with cheaper services, especially in-house that since we're not billing that helps. Um, with that being said, like G PT five has been on the back burner for a while now and the rumors are that like, when that comes out, it could like wipe the slight clean of a ton of these startups that have started over the last 12 to 18 months because it could be so good at knowing user intent that like, you don't remotely have to be good at prompting. You don't need any of these hacks or tweaks or models",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 3104.935,
    "cue_end": 3306.168,
    "chunk_index": 33,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_34",
    "text": "? Like, and so I I, if GCAI is doing that all in the background kind of automatically, like I think that that is a pretty good value add. Wow, that is, that is something I did not know. Thank you Jason. All right, I think we're down to like the last one or two. Um, Alex, uh, can you talk us through, um, the like, uh, AI replicating legal tasks. So how do you think about the future of in-house legal work given the increased sophistication of legal AI tools, for example, what do you see it looking like in one year, two years, three years? Yeah, so I am an ai, uh, optimist. You haven't already been able to tell. There are, there are the doomers that think it's gonna like end all legal practice or whatnot. I think it's just gonna really augment our legal practice and make us hopefully make our lives better. Um, but more likely just make us be able to be more efficient, quicker and with cheaper services, especially in-house that since we're not billing that helps. Um, with that being said, like G PT five has been on the back burner for a while now and the rumors are that like, when that comes out, it could like wipe the slight clean of a ton of these startups that have started over the last 12 to 18 months because it could be so good at knowing user intent that like, you don't remotely have to be good at prompting. You don't need any of these hacks or tweaks or models. It might just be so good at doing that right off the bat that it knows this is a lawyer asking me a question, I should act as a lawyer. I need to, you know, keep all this con information confidential. That stuff, who knows what that actually looks like, but rumors are that that's the case. So yeah, a year from now it could totally revolutionize it, but I think like a quick, an even if that doesn't happen, a quick anecdote using like existing technology, it's like we two months ago faced, um, you know, like a pretty regular claim from a departing of employee that, uh, was like workplace discrimination type stuff basically to keep it as general as possible. And it was going through the EEOC resolution process and as part of that, we would've typically before had like, you know, either either leveraged panel counsel provided by an insure or just regular outside counsel because I'm certainly not like an employment law expert, but like using a workflow process, mixing some of these different models, uh, allowed me to essentially like entirely redraft and draft a, a very, very good responsive brief to the EOC in three hours, which like I had calculated would probably have taken one, one worth before",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 3207.946,
    "cue_end": 3380.417,
    "chunk_index": 34,
    "total_chunks": 35
  },
  {
    "chunk_id": "Prompting_with_Precision_Leveraging_AI_Responsibly_as_In_House_Counsel_chunk_35",
    "text": ". You don't need any of these hacks or tweaks or models. It might just be so good at doing that right off the bat that it knows this is a lawyer asking me a question, I should act as a lawyer. I need to, you know, keep all this con information confidential. That stuff, who knows what that actually looks like, but rumors are that that's the case. So yeah, a year from now it could totally revolutionize it, but I think like a quick, an even if that doesn't happen, a quick anecdote using like existing technology, it's like we two months ago faced, um, you know, like a pretty regular claim from a departing of employee that, uh, was like workplace discrimination type stuff basically to keep it as general as possible. And it was going through the EEOC resolution process and as part of that, we would've typically before had like, you know, either either leveraged panel counsel provided by an insure or just regular outside counsel because I'm certainly not like an employment law expert, but like using a workflow process, mixing some of these different models, uh, allowed me to essentially like entirely redraft and draft a, a very, very good responsive brief to the EOC in three hours, which like I had calculated would probably have taken one, one worth before. Like I went to perplexity deep research function and had it like drum up all the law in Texas for this specific claim and I quickly site checked it and it was accurate and then I like exported that as like a PDF and uploaded that to, uh, white Shoe and also chat GPT and had like two drafts of a brief telling it to like act as an employment law attorney in this area of law, law and o and like telling it only to reference this case law so that it's not going out making up sites. It's like this is the, this is the base of knowledge I have to reference in order to craft this brief and then told it to like, you know, use Iraq and structure it like that. Essentially within three hours I had like a pretty incredible brief that would've taken a week to a week and a half and probably thousands of dollars of outside counsel spent. Um, so like that is currently possible and these tools are only gonna get better. I think that's good news for lawyers. That is so impressive. Um, I wanna say that this conversation today has made it abundantly clear that these tools are here to stay. Uh, prompting is no longer a niche skill. All of these, uh, you know, concept tools, um, skills are becoming table stakes. And so I wanna give a huge thank you to Alex and Jason for giving us their expertise. There's a lot of takeaways for everyone to have. We hope you're leaving, feeling inspired and maybe you'll even try out a few new prompts. Thank you everybody. Thanks Tommy, Jason, and Alex for, um, sharing your time and your expertise with our group today and, uh, to launch rates for making this event possible. Alright, with that everyone, thanks so much for joining and we hope to see you next time.",
    "title": "Prompting with Precision: Leveraging AI Responsibly as In-House Counsel",
    "cue_start": 3302.82,
    "cue_end": 3482.579,
    "chunk_index": 35,
    "total_chunks": 35
  }
]